{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "def load_audio_to_spectrogram(file_path, n_fft=2048, hop_length=512):\n",
    "    # 오디오 파일 로드\n",
    "    y, sr = librosa.load(file_path)\n",
    "    # 스펙트로그램 생성\n",
    "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_DB = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "    return S_DB\n",
    "\n",
    "def plot_spectrogram(S_DB):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# GoogleNet(Inception v1)의 간략한 구현 (여기서는 간소화된 버전으로 제공됩니다)\n",
    "def inception_module(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_5x5,\n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n",
    "\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n",
    "\n",
    "    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
    "\n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n",
    "    \n",
    "    return output\n",
    "\n",
    "# GoogleNet 모델 구성\n",
    "def create_googlenet(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # 이 부분에서는 실제 GoogleNet의 구조를 간소화하여 구현합니다.\n",
    "    # 실제 구현 시 더 많은 Inception 모듈과 깊이를 추가해야 할 수 있습니다.\n",
    "    \n",
    "    x = inception_module(input_layer, 64, 96, 128, 16, 32, 32)\n",
    "    x = AveragePooling2D((5, 5), strides=3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(10, activation='softmax')(x)  # 10개의 분류 클래스 가정\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x, name='inception_v1')\n",
    "    return model\n",
    "\n",
    "# 모델 생성 및 컴파일\n",
    "model = create_googlenet(input_shape=(224, 224, 3))  # 스펙트로그램 이미지 크기와 채널에 맞게 조정 필요\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약 출력\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_spectrogram(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel', fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('spectrogram.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 로드\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# 글로벌 평균 풀링 레이어 추가\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 완전 연결 레이어 추가\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# 분류 레이어 추가 (클래스 개수에 맞게 조정)\n",
    "predictions = Dense(<클래스_개수>, activation='softmax')(x)\n",
    "\n",
    "# 최종 모델\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 첫 번째: 기본 모델의 모든 레이어를 고정하고 새로운 레이어만 학습\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 컴파일\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# 모델 학습\n",
    "# model.fit(...) 이 부분에 데이터셋에 맞춰 코드를 작성하시면 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### melspectogram and mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def save_mel_spectrogram(file_path, save_path, file_name):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.savefig(f\"{save_path}/{file_name}_mel.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_mfcc(file_path, save_path, file_name):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfcc, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.savefig(f\"{save_path}/{file_name}_mfcc.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'path_to_train_dir',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'path_to_validation_dir',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# 모델 로드 및 커스터마이징\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 첫 번째: 기본 모델의 모든 레이어를 고정하고 새로운 레이어만 학습\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3 mels and mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def create_spectrogram_and_mfcc(file_path, save_dir, file_name):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    \n",
    "    # Mel Spectrogram 생성\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'{file_name} Mel Spectrogram')\n",
    "    plt.savefig(os.path.join(save_dir, f'{file_name}_mel.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # MFCC 생성\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfcc, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'{file_name} MFCC')\n",
    "    plt.savefig(os.path.join(save_dir, f'{file_name}_mfcc.png'))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ImageDataGenerator 초기화\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# train 및 validation 데이터셋 로드\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'path/to/train/directory',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'path/to/validation/directory',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# InceptionV3 모델 로드\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# 여기서는 예시로 클래스 수를 10으로 두었습니다. 실제 데이터에 맞게 조정해야 합니다.\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 모든 레이어를 재학습하지 않고, 상위 레이어만 학습\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.inception_v4 import InceptionV4\n",
    "from keras.applications.inception_v4 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def audio_to_image(path, save_dir, labels, sr=8000, n_mels=200, n_mfcc=30):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        audio, _ = librosa.load(os.path.join(path, file), sr=sr)\n",
    "        S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "        mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=n_mfcc)\n",
    "        n_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(n_mfcc, sr=sr, x_axis='time')\n",
    "        plt.savefig(os.path.join(save_dir, file[:-4] + '.png'))\n",
    "\n",
    "        labels.append(file.split('_')[0])  # Assuming label is the first part of file name\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(img_path, labels):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        img_path,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "    \n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        img_path,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "    \n",
    "    labels = to_categorical(labels)\n",
    "    \n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(train_generator, validation_generator, num_classes):\n",
    "    base_model = InceptionV4(weights='imagenet', include_top=False)\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='max')\n",
    "    \n",
    "    model.fit(train_generator,\n",
    "              epochs=100,\n",
    "              validation_data=validation_generator,\n",
    "              callbacks=[checkpoint, early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "audio_path = 'path_to_audio_files'\n",
    "image_path = 'path_to_save_images'\n",
    "labels = []\n",
    "labels = audio_to_image(audio_path, image_path, labels)\n",
    "train_generator, validation_generator = load_data(image_path, labels)\n",
    "num_classes = len(np.unique(labels))\n",
    "train_model(train_generator, validation_generator, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image load amd classification use V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir = 'path/to/train/directory'  # 훈련 데이터 디렉토리 경로\n",
    "validation_dir = 'path/to/validation/directory'  # 검증 데이터 디렉토리 경로\n",
    "\n",
    "# ImageDataGenerator를 사용하여 데이터 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "# InceptionV3 모델 로드 및 커스터마이징\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # 이진 분류를 위한 sigmoid 활성화 함수 사용\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 상위 레이어를 제외한 나머지는 학습되지 않도록 설정\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size)\n",
    "\n",
    "# 모델 성능 평가\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix 및 Classification Report\n",
    "predictions = model.predict(validation_generator)\n",
    "predicted_classes = np.where(predictions > 0.5, 1, 0)\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
