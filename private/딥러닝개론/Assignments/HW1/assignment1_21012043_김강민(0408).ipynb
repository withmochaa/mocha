{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=np.float32)\n",
    "    x = data[:, 0:-2]\n",
    "    y = data[:, [-1]] # after 3 months (-2) and 6 months (-1)\n",
    "    return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target to fix code\n",
    "\n",
    "\n",
    "class EnhancedFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EnhancedFNN, self).__init__()\n",
    "        # 첫 번째 레이어\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ELU(),  # ReLU 활성화 함수 사용\n",
    "            #nn.BatchNorm1d(hidden_size)  # 배치 정규화 추가\n",
    "        )\n",
    "        # 두 번째 레이어: 더 깊은 신경망 구조\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),  # ReLU 활성화 함수 사용\n",
    "            nn.BatchNo1d(hidden_size)  # 배치 정규화 추가\n",
    "        )\n",
    "        # 세 번째 레이어: 출력층\n",
    "        self.layer3 = nn.Linear(hidden_size, output_size,nn.sigmoid())\n",
    "        \n",
    "        # 드롭아웃 추가: 과적합 방지\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.dropout(x)  # 드롭아웃 적용\n",
    "        x = self.layer3(x)\n",
    "        #x = self.dropout(x)  # 드롭아웃 적용\n",
    "        #x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_training_dataset.csv')\n",
    "x_test, y_test = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.2000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.3000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 0.7000, 0.6111, 1.0000, 0.1652, 0.4800],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 1.0000, 0.7222, 0.0000, 0.1739, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.2609, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.0556, 0.0000, 0.3043, 0.7500],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.0556, 0.0000, 0.1739, 0.0000],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.4783, 0.0000],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.3043, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.1739, 0.7500],\n",
       "        [0.0000, 1.0000, 0.1507, 0.0000, 0.2500, 0.7273, 0.2335, 0.3750, 0.2633,\n",
       "         0.2788, 0.9000, 0.2778, 1.0000, 0.3913, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.1739, 0.7500]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103, 15])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test) # test set에는 transform만 사용하기\n",
    "\n",
    "\n",
    "x_train=torch.Tensor(x_train)\n",
    "x_test=torch.Tensor(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(input_size=15, hidden_size=300, output_size=1)\n",
    "criterion = nn.BCELoss()\n",
    "#optimizer = optim.Adam(model.parameters(),lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0443,  0.1121, -0.1695,  ...,  0.0504, -0.2407, -0.2481],\n",
      "        [-0.2305, -0.1526,  0.1679,  ...,  0.0178,  0.2267,  0.0086],\n",
      "        [-0.1542,  0.1012, -0.0307,  ..., -0.2081, -0.0755,  0.1271],\n",
      "        ...,\n",
      "        [ 0.1137, -0.2488,  0.2277,  ...,  0.0462, -0.0759,  0.0852],\n",
      "        [-0.2546, -0.1832, -0.1816,  ..., -0.1497,  0.0279, -0.1045],\n",
      "        [-0.1988,  0.1585, -0.0208,  ..., -0.0108,  0.0903, -0.0710]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0880,  0.1352,  0.2014, -0.1323,  0.1730,  0.1185, -0.1670, -0.1356,\n",
      "         0.1507,  0.1454,  0.0962,  0.0269,  0.1529, -0.0268, -0.0226, -0.1326,\n",
      "         0.0926,  0.1435,  0.1114,  0.1953,  0.1956,  0.0765, -0.0171, -0.0864,\n",
      "         0.2455,  0.1498, -0.0181,  0.1596,  0.2567,  0.2576,  0.0408, -0.1533,\n",
      "         0.1811,  0.0335, -0.1042, -0.2478,  0.0728, -0.1482,  0.1912, -0.0336,\n",
      "        -0.1705, -0.0614,  0.2541, -0.0027, -0.1797, -0.2074, -0.1438, -0.2012,\n",
      "        -0.2108,  0.1701,  0.1987, -0.2449,  0.1251, -0.1105, -0.2534,  0.0029,\n",
      "         0.2543, -0.2202,  0.1568,  0.0342, -0.0527, -0.2215, -0.0922,  0.0335,\n",
      "        -0.0289,  0.1103,  0.2086,  0.0044,  0.0762, -0.1358, -0.1371, -0.1145,\n",
      "        -0.0544, -0.2411,  0.0129,  0.0199, -0.1120,  0.0372, -0.1662, -0.0679,\n",
      "        -0.2543, -0.1567,  0.0830, -0.1785, -0.2087,  0.1628,  0.1295, -0.1371,\n",
      "         0.1899, -0.0353,  0.2028,  0.2363,  0.1703, -0.1334,  0.1700, -0.1590,\n",
      "        -0.0785, -0.1993, -0.0768,  0.2470, -0.1941, -0.1701,  0.1450, -0.1602,\n",
      "         0.2308, -0.0900,  0.1520, -0.0097, -0.1053,  0.2220,  0.1504,  0.2215,\n",
      "        -0.0376,  0.1889, -0.0468, -0.1515,  0.0443, -0.1818, -0.0845, -0.1080,\n",
      "         0.1943,  0.2369,  0.0499,  0.1016,  0.0481,  0.1281,  0.0824, -0.0543,\n",
      "         0.2394,  0.1125, -0.1566,  0.0071, -0.0331, -0.1069,  0.1727, -0.2400,\n",
      "        -0.0546,  0.1677,  0.0565,  0.1541,  0.0190, -0.1468,  0.2018,  0.1793,\n",
      "         0.0743, -0.1165,  0.0421,  0.1480, -0.1881,  0.0664,  0.1875, -0.1609,\n",
      "        -0.1579,  0.0199,  0.1018, -0.0212, -0.1853, -0.1222, -0.1963,  0.1706,\n",
      "         0.2430,  0.1090, -0.0734, -0.0456, -0.0096, -0.0541,  0.0962,  0.2392,\n",
      "        -0.2439,  0.0665, -0.0868, -0.0620,  0.2327,  0.1569,  0.1275,  0.2094,\n",
      "         0.0160, -0.0293,  0.0549, -0.2164, -0.1609, -0.2512,  0.0653, -0.0159,\n",
      "         0.1137,  0.0340, -0.2260, -0.0379,  0.0496, -0.2507, -0.1062, -0.1842,\n",
      "         0.0898,  0.0246,  0.1653,  0.0228, -0.2203, -0.1895,  0.1836, -0.1619,\n",
      "         0.2194,  0.0338, -0.1268, -0.1289, -0.2024, -0.1196, -0.1955,  0.0707,\n",
      "        -0.0041, -0.0962,  0.0126,  0.1696, -0.0418, -0.1425,  0.0412, -0.0168,\n",
      "        -0.1338, -0.2169, -0.0951, -0.0166, -0.2255, -0.0735,  0.0657,  0.1608,\n",
      "        -0.2450, -0.0807,  0.0199,  0.1981, -0.0156,  0.0134,  0.0105, -0.0490,\n",
      "         0.1078,  0.1734, -0.2173, -0.0533, -0.2299, -0.1130,  0.1715, -0.0638,\n",
      "         0.0299, -0.2533,  0.0071, -0.1559, -0.0582,  0.1330,  0.2192,  0.0739,\n",
      "        -0.1404,  0.2252, -0.0318,  0.0788,  0.0531,  0.2290, -0.1100,  0.0650,\n",
      "         0.2447, -0.2506,  0.1786, -0.0645,  0.0542,  0.0438,  0.0180, -0.1467,\n",
      "         0.1921, -0.2230,  0.2435,  0.0824, -0.1275,  0.0662, -0.0061, -0.2191,\n",
      "         0.2267, -0.2312, -0.0770, -0.0948, -0.2135, -0.2015,  0.1847, -0.0338,\n",
      "         0.1305, -0.0025,  0.1504, -0.1548, -0.0647, -0.2188,  0.0750, -0.1861,\n",
      "        -0.1575,  0.0462, -0.0284,  0.2139, -0.2219,  0.0841, -0.2229, -0.2455,\n",
      "         0.0307, -0.1370,  0.1204,  0.0361], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-9.7583e-03, -2.9039e-02, -4.7964e-02, -2.6809e-02,  3.2492e-02,\n",
      "         -3.7195e-03,  1.0312e-02, -1.3581e-02,  4.5764e-02,  5.5099e-02,\n",
      "          4.0942e-02, -3.6112e-02, -2.7136e-02,  4.4007e-02, -3.8600e-02,\n",
      "         -4.5541e-02,  4.7399e-02, -2.4084e-02, -5.2324e-02, -2.6782e-02,\n",
      "          1.7156e-02, -6.5878e-03, -9.8781e-03, -3.9634e-02,  5.0370e-03,\n",
      "          4.5781e-02, -2.5660e-02,  2.8325e-02, -3.0019e-03,  2.1525e-02,\n",
      "          4.1471e-02,  4.6500e-02, -5.6854e-03, -3.1243e-02, -5.3586e-02,\n",
      "          1.4963e-02,  2.3462e-02,  4.3820e-02,  8.6629e-03, -2.9639e-02,\n",
      "          1.5506e-02, -2.3421e-02,  4.6707e-02,  4.0568e-02,  4.6107e-02,\n",
      "         -3.5963e-02,  5.0455e-02, -1.1041e-02, -4.1035e-02,  5.6418e-02,\n",
      "         -4.7319e-03, -3.8188e-02, -5.2072e-02, -2.8783e-02, -7.7934e-03,\n",
      "         -5.4243e-02, -2.6389e-02, -6.3515e-03,  4.9475e-02, -4.2641e-02,\n",
      "          4.8284e-02, -4.3976e-03, -4.9365e-02,  7.0950e-03, -3.2218e-02,\n",
      "         -4.1857e-02, -4.9028e-02, -3.9481e-02, -5.2687e-02,  4.9677e-02,\n",
      "         -5.0621e-02,  1.7031e-02, -3.3218e-02, -2.7695e-02, -5.6817e-02,\n",
      "          2.8946e-02, -3.4507e-02, -3.0449e-02, -5.5702e-02, -5.5068e-02,\n",
      "         -5.2556e-02, -3.3390e-02,  3.0053e-02, -5.6522e-02, -5.4691e-02,\n",
      "         -4.8150e-02, -2.7197e-02,  4.3211e-02, -5.6345e-02,  3.8869e-02,\n",
      "          5.4459e-02, -2.9598e-02, -4.7359e-03,  5.1247e-05,  2.8489e-02,\n",
      "         -2.8409e-02, -4.1164e-02,  5.2100e-02,  1.7440e-02, -4.5271e-02,\n",
      "         -3.8686e-02, -1.8902e-02,  2.1738e-02, -4.3804e-02,  4.8400e-02,\n",
      "         -2.2851e-02,  4.9664e-03, -3.1269e-02, -2.3050e-02, -3.7200e-02,\n",
      "          1.4325e-02,  5.3583e-02,  1.5441e-02, -2.0630e-02, -2.5041e-02,\n",
      "          3.2808e-02,  3.7621e-03, -3.8065e-02,  6.9014e-03,  5.6418e-02,\n",
      "          2.6672e-02,  4.6003e-02,  3.6397e-03,  3.1973e-02, -3.7241e-02,\n",
      "         -2.4289e-02, -3.7142e-03, -2.8300e-02, -1.6666e-02,  1.1714e-02,\n",
      "         -1.3521e-02, -2.5362e-02, -5.6206e-02,  6.5970e-03,  4.4738e-02,\n",
      "         -2.3703e-02, -5.3844e-02,  4.3135e-02, -1.8627e-02, -2.6665e-02,\n",
      "          4.1334e-02,  1.5238e-03, -3.5368e-02,  7.0801e-04,  3.9303e-02,\n",
      "          1.4760e-02,  2.1484e-02, -5.6119e-02,  3.0194e-02,  5.0474e-02,\n",
      "          6.0418e-04,  3.6046e-02,  5.2462e-02, -1.0535e-02,  3.8163e-02,\n",
      "          4.7155e-02, -2.6923e-03, -1.5688e-02, -5.6484e-02,  4.3925e-02,\n",
      "         -3.4016e-02, -3.7342e-02,  4.3016e-02, -1.9088e-02,  3.8024e-02,\n",
      "         -2.5604e-02, -5.0552e-02,  1.1946e-02,  3.0104e-02, -2.4872e-02,\n",
      "          9.3403e-05,  3.4855e-02,  5.8595e-03,  1.2280e-02, -4.7784e-02,\n",
      "         -4.4437e-02, -4.2038e-02, -1.0427e-02,  5.3214e-02, -1.8137e-02,\n",
      "         -3.2441e-02, -2.6485e-02,  1.6646e-02,  7.0563e-03, -5.3121e-02,\n",
      "          8.0925e-03,  4.7933e-02, -5.5787e-02,  3.6150e-02,  2.6827e-02,\n",
      "          4.0615e-02,  1.0876e-02,  3.1216e-02, -5.3024e-02, -5.3998e-03,\n",
      "         -3.9828e-02,  3.6955e-02,  3.9501e-02, -1.4076e-02,  5.1982e-02,\n",
      "         -5.1962e-02,  3.7977e-02,  2.0362e-02, -3.3157e-02,  3.2756e-02,\n",
      "          6.7758e-03,  1.8954e-02, -1.0050e-02,  2.9301e-02, -3.6348e-02,\n",
      "          2.6871e-02, -5.2490e-02,  3.1859e-03,  2.6646e-02, -3.1210e-02,\n",
      "          4.0056e-03, -3.8462e-02, -1.6784e-02,  2.3869e-02,  1.4873e-02,\n",
      "         -2.5735e-02,  3.2744e-02, -4.0717e-02, -2.0442e-02,  4.2808e-02,\n",
      "          5.2418e-02,  4.1641e-02,  5.1312e-02, -4.1593e-02,  2.3857e-02,\n",
      "         -5.1390e-02,  5.4162e-03, -4.7160e-02,  3.0222e-02,  3.4597e-02,\n",
      "          2.3089e-02,  1.0025e-02, -9.6164e-03,  2.4655e-02,  1.8336e-02,\n",
      "         -2.2182e-02,  3.3157e-02,  4.0645e-02,  1.7213e-02,  5.5547e-02,\n",
      "         -1.9628e-02, -3.7316e-02,  2.0353e-02, -4.2957e-02, -8.0186e-03,\n",
      "         -2.1819e-02,  3.7543e-02, -4.1196e-03,  2.7509e-02, -2.8150e-02,\n",
      "         -1.8298e-02,  4.0099e-02,  4.2424e-02, -3.5475e-02, -2.7930e-02,\n",
      "          5.1829e-02,  1.1214e-02, -1.4288e-03,  3.6571e-02,  1.5403e-02,\n",
      "          3.9155e-02, -3.5843e-02, -7.5818e-03, -4.1489e-03, -2.5344e-02,\n",
      "          5.3677e-02,  2.6577e-02, -2.4949e-02, -4.3251e-03, -1.2064e-02,\n",
      "         -5.6017e-02, -4.0582e-02, -8.2154e-04, -4.7407e-02,  7.1971e-03,\n",
      "          1.2013e-02, -1.0023e-02,  5.3483e-02, -5.0533e-02,  2.7618e-02,\n",
      "         -5.1472e-02, -3.1565e-02,  2.3934e-02,  5.0415e-02,  4.1787e-02,\n",
      "         -1.5799e-02,  2.6670e-02, -3.3154e-02,  2.8887e-02, -4.2585e-02,\n",
      "         -3.8154e-02,  4.4116e-02,  3.0729e-02,  1.0605e-02,  2.1329e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0204], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming y is torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1001], Loss: 0.6904\n",
      "Epoch [200/1001], Loss: 0.0093\n",
      "Epoch [400/1001], Loss: 0.0010\n",
      "Epoch [600/1001], Loss: 0.0013\n",
      "Epoch [800/1001], Loss: 0.0010\n",
      "Epoch [1000/1001], Loss: 0.0024\n",
      "\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1001\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "\n",
    "with torch.no_grad(): \n",
    "    train_accuracy = (model(x_train).gt(0.5).float() == y_train).float().mean().item()\n",
    "    test_accuracy = (model(x_test).gt(0.5).float() == y_test).float().mean().item()\n",
    "    \n",
    "    \n",
    "\n",
    "print(f'\\nTrain Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "#Train Accuracy: 0.9709 -> start\n",
    "#Test Accuracy: 0.9000 -> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_test).gt(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_test).gt(0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
