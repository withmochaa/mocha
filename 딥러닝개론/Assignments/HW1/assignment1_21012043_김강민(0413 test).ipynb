{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=np.float32)\n",
    "    x = data[:, 0:-2]\n",
    "    y = data[:, [-1]] # after 3 months (-2) and 6 months (-1)\n",
    "    return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target to fix code\n",
    "\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size)  # 배치 정규화 추가\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),  # 추가 은닉층\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size)  # 배치 정규화 추가\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.005)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.dropout(x)  # 추가 은닉층을 위해 드롭아웃 적용\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_training_dataset.csv')\n",
    "x_test, y_test = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.2000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.3000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 0.7000, 0.6111, 1.0000, 0.1652, 0.4800],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 1.0000, 0.7222, 0.0000, 0.1739, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.2609, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.0556, 0.0000, 0.3043, 0.7500],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.0556, 0.0000, 0.1739, 0.0000],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.4783, 0.0000],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.3043, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.1739, 0.7500],\n",
       "        [0.0000, 1.0000, 0.1507, 0.0000, 0.2500, 0.7273, 0.2335, 0.3750, 0.2633,\n",
       "         0.2788, 0.9000, 0.2778, 1.0000, 0.3913, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.1739, 0.7500]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103, 15])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test) # test set에는 transform만 사용하기\n",
    "\n",
    "\n",
    "x_train=torch.Tensor(x_train)\n",
    "x_test=torch.Tensor(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(input_size=15, hidden_size=300, output_size=1)\n",
    "criterion = nn.BCELoss()\n",
    "#optimizer = optim.Adam(model.parameters(),lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1568, -0.0726, -0.2232,  ...,  0.0844, -0.1112, -0.1387],\n",
      "        [ 0.1814,  0.0192, -0.1970,  ...,  0.0630,  0.1050, -0.2128],\n",
      "        [-0.0773,  0.1341,  0.2528,  ..., -0.1986,  0.0163,  0.0339],\n",
      "        ...,\n",
      "        [-0.2451,  0.1972,  0.0244,  ..., -0.0982, -0.1687,  0.1949],\n",
      "        [-0.2042,  0.0797,  0.2302,  ...,  0.2325, -0.1627, -0.1920],\n",
      "        [-0.1977,  0.2555, -0.0098,  ..., -0.0126,  0.1509, -0.1652]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2521, -0.0132, -0.1192,  0.0295, -0.0128, -0.0062,  0.1215,  0.1757,\n",
      "        -0.1484,  0.0659, -0.2459, -0.1586, -0.0161,  0.0072,  0.0256,  0.0516,\n",
      "         0.1169,  0.2292, -0.0928,  0.0512,  0.1915, -0.0099,  0.1053, -0.1512,\n",
      "         0.0377, -0.1060, -0.0546,  0.1644,  0.0399, -0.0659,  0.0243,  0.1850,\n",
      "         0.2436, -0.0108,  0.2319,  0.0467, -0.2021,  0.2274, -0.2248,  0.1089,\n",
      "         0.2007, -0.1554, -0.1254,  0.2553,  0.2399, -0.2193, -0.2487, -0.2522,\n",
      "         0.1305,  0.2491,  0.0525,  0.1320,  0.0679,  0.2472,  0.0388,  0.1367,\n",
      "         0.0991, -0.0521,  0.0592,  0.2299,  0.2153, -0.2000, -0.1145, -0.0486,\n",
      "        -0.0618, -0.2370,  0.1551, -0.1657, -0.0802,  0.1979, -0.0670,  0.1145,\n",
      "         0.0346, -0.2400,  0.1311,  0.0583, -0.0659, -0.0719, -0.2133,  0.1916,\n",
      "         0.2449,  0.2080, -0.0128,  0.1363, -0.1636,  0.1955, -0.1292, -0.1086,\n",
      "        -0.0609,  0.2518,  0.1779, -0.1137, -0.0692, -0.0703,  0.1432, -0.2576,\n",
      "         0.0399,  0.0767, -0.1352, -0.1710, -0.1562,  0.2567,  0.1506, -0.1350,\n",
      "        -0.2067,  0.0143, -0.1158,  0.1223,  0.1010,  0.0188, -0.0864, -0.2284,\n",
      "         0.0967,  0.0137,  0.0896, -0.0287, -0.2400,  0.1665,  0.0917,  0.0410,\n",
      "         0.2208, -0.2161, -0.1508,  0.1159,  0.0012,  0.0380,  0.1184, -0.0038,\n",
      "        -0.1746,  0.0016, -0.2077, -0.0223,  0.1845, -0.2185,  0.1687,  0.1229,\n",
      "        -0.2010,  0.1924,  0.1115,  0.0212, -0.0413, -0.0950,  0.0419, -0.1280,\n",
      "         0.1426, -0.2485, -0.1958, -0.1886,  0.1421,  0.2274,  0.0668, -0.1775,\n",
      "         0.1966, -0.2133, -0.2003, -0.1688,  0.0280, -0.2144,  0.1170, -0.1095,\n",
      "        -0.1861,  0.0577, -0.0493, -0.0563, -0.1501,  0.2313, -0.1043, -0.2124,\n",
      "        -0.0863, -0.1962, -0.2037,  0.2440,  0.0810,  0.0284,  0.2283, -0.0184,\n",
      "         0.1864,  0.0953, -0.1648,  0.0543, -0.0375,  0.1175,  0.0956,  0.0698,\n",
      "         0.2439,  0.2328, -0.1602,  0.1659, -0.0649,  0.2483, -0.2361, -0.1042,\n",
      "        -0.0219,  0.2147,  0.0133, -0.1890, -0.2079, -0.2479, -0.0137,  0.1057,\n",
      "        -0.0887, -0.1311,  0.0790,  0.0536, -0.1974, -0.1927, -0.0313,  0.2016,\n",
      "        -0.2565, -0.0204,  0.2163,  0.1825, -0.1198, -0.2332,  0.0301,  0.2134,\n",
      "        -0.0225, -0.1644,  0.0445, -0.2499,  0.2243, -0.0390,  0.2386,  0.0652,\n",
      "        -0.0267, -0.0155, -0.2357, -0.0419,  0.0324,  0.1612, -0.2547,  0.0670,\n",
      "        -0.2439,  0.1001, -0.1140, -0.1277, -0.0067,  0.1650, -0.0040,  0.1566,\n",
      "         0.2380, -0.1810, -0.2531,  0.1361,  0.2111, -0.0702, -0.1787, -0.2330,\n",
      "        -0.1135,  0.1577,  0.0345,  0.0582,  0.1905, -0.0876,  0.1762,  0.0892,\n",
      "         0.1688, -0.0643,  0.0391,  0.0307,  0.2550, -0.1814,  0.0190, -0.0532,\n",
      "         0.0582,  0.1615, -0.2145, -0.1922,  0.0358,  0.1135,  0.1673,  0.0264,\n",
      "         0.2317,  0.2010, -0.0553,  0.1030, -0.1474, -0.1891, -0.1587,  0.1199,\n",
      "         0.2094,  0.2135,  0.0047,  0.0149,  0.2232,  0.2189, -0.0764, -0.1544,\n",
      "         0.0768,  0.1918,  0.1273, -0.0566,  0.1403, -0.2111, -0.2006,  0.0070,\n",
      "        -0.0342, -0.0131,  0.1163,  0.0248], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0217,  0.0054,  0.0554,  ...,  0.0006,  0.0495,  0.0494],\n",
      "        [-0.0533, -0.0151,  0.0151,  ...,  0.0535,  0.0422, -0.0083],\n",
      "        [-0.0134, -0.0574, -0.0408,  ...,  0.0306, -0.0283, -0.0220],\n",
      "        ...,\n",
      "        [ 0.0357,  0.0128,  0.0196,  ...,  0.0532, -0.0120, -0.0393],\n",
      "        [-0.0449,  0.0169,  0.0511,  ..., -0.0050, -0.0008, -0.0039],\n",
      "        [ 0.0179,  0.0169,  0.0566,  ...,  0.0093, -0.0560, -0.0389]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0464,  0.0031,  0.0572, -0.0141, -0.0379, -0.0124, -0.0070, -0.0011,\n",
      "        -0.0316, -0.0288,  0.0158,  0.0374,  0.0546, -0.0050, -0.0567, -0.0173,\n",
      "        -0.0201, -0.0561,  0.0011,  0.0086,  0.0032, -0.0299,  0.0246, -0.0081,\n",
      "         0.0384, -0.0273, -0.0060, -0.0287,  0.0402, -0.0533, -0.0406, -0.0072,\n",
      "         0.0186,  0.0165,  0.0301,  0.0015, -0.0034, -0.0227,  0.0563,  0.0570,\n",
      "        -0.0317, -0.0490,  0.0393,  0.0486, -0.0345, -0.0137,  0.0313, -0.0442,\n",
      "         0.0008,  0.0309, -0.0029,  0.0408,  0.0163,  0.0404, -0.0355,  0.0564,\n",
      "         0.0331, -0.0318,  0.0565, -0.0398,  0.0215,  0.0119,  0.0409, -0.0106,\n",
      "         0.0551,  0.0368, -0.0194,  0.0396, -0.0433, -0.0308,  0.0091, -0.0404,\n",
      "        -0.0016,  0.0454, -0.0404, -0.0488,  0.0380, -0.0424,  0.0373,  0.0237,\n",
      "         0.0248,  0.0347,  0.0438,  0.0475,  0.0407,  0.0247,  0.0075, -0.0575,\n",
      "         0.0123,  0.0181, -0.0244,  0.0244, -0.0233, -0.0271, -0.0238,  0.0087,\n",
      "         0.0542,  0.0026, -0.0382, -0.0239, -0.0431,  0.0315, -0.0405,  0.0380,\n",
      "         0.0276, -0.0120,  0.0287, -0.0066, -0.0506, -0.0298,  0.0240, -0.0498,\n",
      "         0.0117,  0.0075, -0.0524, -0.0536, -0.0153, -0.0576, -0.0444, -0.0216,\n",
      "         0.0276,  0.0419,  0.0086, -0.0486, -0.0219,  0.0148, -0.0264,  0.0069,\n",
      "         0.0496, -0.0053, -0.0331, -0.0442, -0.0236, -0.0413, -0.0150,  0.0221,\n",
      "         0.0189, -0.0065,  0.0073, -0.0130,  0.0072,  0.0180, -0.0543,  0.0467,\n",
      "        -0.0288,  0.0494,  0.0195, -0.0309, -0.0453,  0.0471, -0.0005,  0.0170,\n",
      "         0.0091,  0.0125,  0.0449, -0.0017,  0.0446, -0.0326, -0.0504,  0.0048,\n",
      "        -0.0272, -0.0046,  0.0546,  0.0399,  0.0151,  0.0092, -0.0394, -0.0076,\n",
      "        -0.0243,  0.0345, -0.0200,  0.0322, -0.0107,  0.0028, -0.0304,  0.0255,\n",
      "         0.0066,  0.0042, -0.0379,  0.0268, -0.0524, -0.0106, -0.0158, -0.0389,\n",
      "        -0.0198,  0.0452,  0.0306,  0.0226, -0.0106, -0.0559, -0.0065, -0.0325,\n",
      "        -0.0417, -0.0131,  0.0555,  0.0010, -0.0106, -0.0009,  0.0270,  0.0232,\n",
      "         0.0439,  0.0004,  0.0459,  0.0066,  0.0367,  0.0066, -0.0058, -0.0164,\n",
      "        -0.0540,  0.0169,  0.0516,  0.0122, -0.0316,  0.0474,  0.0299,  0.0070,\n",
      "         0.0183,  0.0527, -0.0455,  0.0202, -0.0529,  0.0084,  0.0559,  0.0198,\n",
      "         0.0171, -0.0514,  0.0101, -0.0015, -0.0378,  0.0575, -0.0285, -0.0182,\n",
      "         0.0421,  0.0243, -0.0004, -0.0364,  0.0133, -0.0276,  0.0218, -0.0290,\n",
      "         0.0326, -0.0457,  0.0497, -0.0081,  0.0429,  0.0519,  0.0113,  0.0281,\n",
      "         0.0380, -0.0417, -0.0197, -0.0441, -0.0307, -0.0098, -0.0488, -0.0416,\n",
      "         0.0386,  0.0125,  0.0222,  0.0241,  0.0488, -0.0435,  0.0163,  0.0307,\n",
      "        -0.0355,  0.0313, -0.0371,  0.0078, -0.0277, -0.0450,  0.0377,  0.0551,\n",
      "        -0.0198, -0.0160,  0.0414,  0.0153,  0.0199, -0.0527,  0.0573,  0.0462,\n",
      "        -0.0324, -0.0430,  0.0293,  0.0526,  0.0213,  0.0127,  0.0217,  0.0188,\n",
      "        -0.0532,  0.0118,  0.0141, -0.0024, -0.0303,  0.0529, -0.0306, -0.0086,\n",
      "        -0.0224, -0.0012, -0.0336, -0.0484], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.1970e-02, -1.5900e-03, -1.5719e-02, -3.5255e-02,  5.5436e-02,\n",
      "          3.6244e-02,  2.9790e-02, -1.6954e-02, -3.3020e-02,  3.9103e-02,\n",
      "         -1.0694e-02,  2.9075e-02,  3.6662e-02, -4.7711e-03, -3.5268e-02,\n",
      "         -1.9821e-02,  1.9712e-02, -4.9613e-02, -5.8208e-03,  5.1992e-02,\n",
      "         -5.8245e-03, -1.8446e-02,  4.1976e-02,  2.7887e-02, -1.7907e-02,\n",
      "          3.8429e-02,  4.1904e-02,  3.6096e-02,  3.7477e-02,  9.2852e-03,\n",
      "          2.0051e-02,  4.0632e-02, -3.0060e-02, -5.2779e-02, -1.8957e-02,\n",
      "         -1.3177e-02, -5.5276e-02,  4.1999e-02, -3.8802e-02,  4.1922e-02,\n",
      "          4.8646e-02, -3.1503e-02,  1.0686e-02,  2.4255e-02, -5.1544e-02,\n",
      "         -5.2921e-02,  4.1398e-02,  2.3442e-02, -2.6371e-02, -2.9988e-02,\n",
      "          5.3558e-02, -2.2668e-02,  1.6925e-02, -1.4928e-02,  1.5965e-02,\n",
      "         -3.7902e-02,  4.4827e-03,  4.3739e-02, -2.1316e-02, -2.1903e-02,\n",
      "         -2.6461e-02, -4.7780e-02, -1.4753e-02, -1.9130e-02, -4.1359e-02,\n",
      "          1.5128e-02, -3.8731e-02, -1.2182e-02, -8.7916e-03,  6.5008e-03,\n",
      "         -7.0975e-03, -5.0012e-02,  9.7386e-03,  8.8613e-03,  3.9447e-02,\n",
      "          1.6384e-02,  3.9154e-02,  2.3327e-02, -3.4537e-02,  2.5379e-02,\n",
      "          3.2820e-02,  3.4129e-02,  2.3643e-02, -5.4734e-02, -1.2666e-02,\n",
      "          5.4574e-02,  3.2450e-03, -1.7540e-03, -3.5135e-02, -5.6811e-02,\n",
      "          3.2139e-02,  1.9060e-02,  4.8514e-02,  5.2663e-02,  5.4194e-02,\n",
      "          4.9588e-02,  4.4177e-02,  5.7605e-02,  1.3293e-02, -2.8335e-02,\n",
      "          3.0527e-03,  1.4820e-02, -8.6692e-03, -4.5237e-02,  6.4168e-03,\n",
      "         -2.4102e-03, -5.7206e-02,  4.0726e-02,  4.9467e-02,  5.8460e-03,\n",
      "         -1.3219e-02,  1.8545e-02,  2.3165e-02,  6.9535e-03, -5.1211e-02,\n",
      "          3.6237e-02, -5.6356e-02, -1.6914e-04,  4.1670e-02,  3.8308e-02,\n",
      "          2.4259e-02, -7.3369e-03, -1.1492e-02,  5.5078e-02, -1.7071e-02,\n",
      "          1.9534e-02, -3.8172e-02,  1.6174e-06,  2.3227e-02,  1.5842e-02,\n",
      "         -3.7268e-02, -3.5785e-02,  3.4845e-02, -5.0829e-02,  1.0024e-02,\n",
      "          3.5402e-02,  1.5411e-02,  5.6296e-02, -3.8811e-02, -5.6783e-02,\n",
      "         -9.8827e-05, -2.9075e-02, -5.3017e-02,  2.6549e-02, -2.4696e-02,\n",
      "          2.4192e-02, -5.5295e-03, -3.0405e-03,  1.3412e-02, -3.5368e-02,\n",
      "         -4.3208e-02, -5.0718e-02,  5.3461e-02,  4.7371e-02, -2.6036e-02,\n",
      "          3.2784e-02,  4.3950e-02,  4.3785e-02,  4.4807e-02, -2.1305e-02,\n",
      "          2.5570e-02, -1.8695e-02, -5.6851e-02,  4.8184e-02, -2.1401e-02,\n",
      "          5.3621e-02,  1.7664e-02,  1.7068e-02,  2.4577e-02,  3.4211e-02,\n",
      "         -1.6565e-02, -5.2972e-02,  5.5813e-02,  1.3431e-03,  3.1054e-02,\n",
      "         -4.6601e-02, -2.2961e-03, -2.0247e-02, -5.5965e-02,  3.3486e-02,\n",
      "         -2.1514e-02, -1.5073e-02, -9.7544e-03, -4.7268e-03,  2.5686e-03,\n",
      "         -4.9578e-02, -5.5577e-02,  4.8013e-02, -5.4623e-02,  1.7759e-02,\n",
      "         -3.4118e-02,  2.6788e-02,  3.5494e-02,  1.5349e-02,  3.5227e-02,\n",
      "         -4.6885e-02,  9.7484e-03,  2.4839e-02, -4.2614e-02,  5.0982e-02,\n",
      "          5.6529e-03, -4.0724e-02, -2.4066e-02, -2.2610e-03, -2.5446e-02,\n",
      "          4.8524e-02, -8.1990e-03,  5.6748e-02, -4.2668e-04, -2.9080e-02,\n",
      "          2.0029e-02, -1.5569e-02, -2.2713e-02,  3.2109e-02, -5.2084e-02,\n",
      "          5.2508e-02, -2.3471e-02, -4.4759e-02,  3.4734e-02, -1.1882e-02,\n",
      "         -5.4514e-02,  3.5500e-02, -3.8449e-02,  1.9241e-02, -2.9646e-02,\n",
      "         -3.9167e-02,  5.6149e-02, -2.8986e-02,  4.2544e-02, -5.1641e-02,\n",
      "         -4.8875e-02,  2.5440e-02,  5.1859e-02,  3.9878e-02,  5.5825e-02,\n",
      "          3.9325e-02, -3.9674e-03, -1.6932e-02,  5.2478e-02,  2.3643e-02,\n",
      "          4.7496e-02,  1.3358e-02, -6.7432e-03,  7.0508e-03,  4.4474e-02,\n",
      "         -4.4011e-03, -3.3982e-02,  4.6799e-02,  3.9676e-02,  1.1883e-02,\n",
      "          1.0903e-02, -3.5353e-02, -5.0083e-02,  4.8228e-02, -9.3150e-03,\n",
      "          4.3481e-02,  3.2296e-02, -7.3186e-03,  8.1794e-03, -7.2922e-03,\n",
      "          2.2754e-02, -3.4182e-02, -5.2028e-02,  3.0202e-02, -2.0765e-02,\n",
      "         -1.7431e-02,  2.7227e-02, -5.5096e-02,  3.1871e-02, -2.8534e-04,\n",
      "          3.8892e-02,  2.9529e-02, -2.2037e-02,  2.4759e-02, -1.6996e-02,\n",
      "          4.5196e-02, -9.5413e-03, -4.6383e-02,  9.7021e-03,  9.5175e-03,\n",
      "          5.4756e-02,  5.4507e-03, -2.3337e-02, -2.8985e-02,  3.7940e-02,\n",
      "         -8.2807e-03, -5.4433e-02,  3.3500e-02, -3.1235e-02, -3.3846e-02,\n",
      "          3.0069e-02, -4.9017e-02,  5.1043e-02, -3.5857e-02, -2.3936e-02,\n",
      "         -2.5517e-02, -1.0039e-02, -4.2923e-02, -4.9100e-02,  4.9382e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0287], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming y is torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1001], Loss: 0.7730\n",
      "Epoch [200/1001], Loss: 0.0296\n",
      "Epoch [400/1001], Loss: 0.0017\n",
      "Epoch [600/1001], Loss: 0.0853\n",
      "Epoch [800/1001], Loss: 0.0201\n",
      "Epoch [1000/1001], Loss: 0.0186\n",
      "\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1001\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "\n",
    "with torch.no_grad(): \n",
    "    train_accuracy = (model(x_train).gt(0.5).float() == y_train).float().mean().item()\n",
    "    test_accuracy = (model(x_test).gt(0.5).float() == y_test).float().mean().item()\n",
    "    \n",
    "    \n",
    "\n",
    "print(f'\\nTrain Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "#Train Accuracy: 0.9709 -> start\n",
    "#Test Accuracy: 0.9000 -> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_test).gt(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_test).gt(0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
