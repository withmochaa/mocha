{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=np.float32)\n",
    "    x = data[:, 0:-2]\n",
    "    y = data[:, [-1]] # after 3 months (-2) and 6 months (-1)\n",
    "    return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target to fix code\n",
    "\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(input_size, hidden_size), nn.Tanh())\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.layer2 = nn.Sequential(nn.Linear(hidden_size, output_size), nn.Sigmoid())\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        \n",
    "        return x # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_training_dataset.csv')\n",
    "x_test, y_test = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 1307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.2000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.3000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 0.7000, 0.6111, 1.0000, 0.1652, 0.4800],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 1.0000, 0.7222, 0.0000, 0.1739, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.2609, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.0556, 0.0000, 0.3043, 0.7500],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.0556, 0.0000, 0.1739, 0.0000],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.4783, 0.0000],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.3043, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.1739, 0.7500],\n",
       "        [0.0000, 1.0000, 0.1507, 0.0000, 0.2500, 0.7273, 0.2335, 0.3750, 0.2633,\n",
       "         0.2788, 0.9000, 0.2778, 1.0000, 0.3913, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.1739, 0.7500]])"
      ]
     },
     "execution_count": 1308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103, 15])"
      ]
     },
     "execution_count": 1309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(input_size=15, hidden_size=300, output_size=1)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2385, -0.1580,  0.1784,  ..., -0.1995, -0.0438,  0.1241],\n",
      "        [ 0.1026,  0.0332,  0.1208,  ..., -0.1943,  0.0104,  0.0672],\n",
      "        [-0.2545,  0.2027,  0.1812,  ..., -0.1771,  0.0732,  0.1212],\n",
      "        ...,\n",
      "        [-0.1951, -0.1591,  0.0539,  ..., -0.2454, -0.1110, -0.2000],\n",
      "        [ 0.0780, -0.0966, -0.1002,  ...,  0.0218,  0.1682, -0.1034],\n",
      "        [-0.2067, -0.2216,  0.0102,  ...,  0.0978,  0.0151, -0.1250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1808, -0.1898,  0.1568,  0.2124, -0.1153,  0.0586, -0.0219,  0.0393,\n",
      "         0.0528, -0.2493,  0.2112,  0.0946, -0.2116,  0.0194,  0.2522, -0.1622,\n",
      "        -0.2010, -0.1559,  0.2532, -0.1225, -0.2484,  0.0803, -0.0869, -0.0517,\n",
      "        -0.1732,  0.1801, -0.2228,  0.0680,  0.2220, -0.0129,  0.0210,  0.1925,\n",
      "        -0.0853, -0.1911,  0.0944, -0.1986,  0.2330,  0.2269, -0.2354,  0.0778,\n",
      "         0.1723, -0.1343,  0.1302,  0.1431, -0.0146, -0.2413, -0.1730,  0.1498,\n",
      "         0.0356,  0.1115, -0.1084,  0.1816,  0.0550, -0.2557, -0.2032, -0.1627,\n",
      "        -0.0393,  0.0257,  0.1521, -0.1130, -0.1913, -0.0239, -0.1968,  0.0802,\n",
      "         0.1766,  0.2244, -0.0740, -0.0958, -0.0890,  0.0511,  0.1813, -0.2053,\n",
      "        -0.0301, -0.1959, -0.0538, -0.1615, -0.1707, -0.1289,  0.2049,  0.0688,\n",
      "        -0.0773,  0.0341, -0.0573,  0.0306,  0.0938,  0.1630,  0.1443, -0.0252,\n",
      "        -0.1736,  0.0680,  0.0121, -0.0400,  0.1213, -0.0376,  0.1635,  0.1281,\n",
      "        -0.0446, -0.1573,  0.1279, -0.2357, -0.1520,  0.2119,  0.2358,  0.2161,\n",
      "        -0.1375, -0.1392, -0.1905, -0.0369, -0.0267,  0.1542, -0.0344, -0.0605,\n",
      "         0.1141,  0.0569, -0.1804, -0.1403, -0.0772,  0.0131, -0.1523, -0.1430,\n",
      "        -0.1703,  0.1101,  0.2053,  0.2327, -0.1452, -0.2166,  0.2078, -0.2211,\n",
      "         0.1957,  0.1897,  0.0601,  0.0068,  0.1672,  0.1958, -0.0021,  0.0542,\n",
      "        -0.0522,  0.1871, -0.2048, -0.2533,  0.1252,  0.0039, -0.1332, -0.1033,\n",
      "        -0.1043,  0.0462,  0.0913,  0.0987,  0.2057, -0.0120,  0.0289,  0.1209,\n",
      "         0.1062,  0.0094,  0.1836, -0.2411, -0.0637, -0.2481,  0.1061,  0.0972,\n",
      "        -0.0361, -0.0960,  0.1875,  0.2254, -0.1963, -0.1555, -0.0237,  0.0559,\n",
      "        -0.0676,  0.2483,  0.1788,  0.1748, -0.0525, -0.1491,  0.1461, -0.2391,\n",
      "        -0.0417, -0.2576, -0.0566, -0.1364,  0.1955,  0.1438, -0.1029, -0.2457,\n",
      "         0.1000,  0.1646, -0.2068, -0.1189,  0.1361, -0.1636, -0.2146,  0.1917,\n",
      "        -0.1200,  0.2166, -0.1869,  0.2555,  0.1598,  0.0836, -0.0648,  0.2240,\n",
      "         0.1402, -0.0176,  0.1276,  0.0050,  0.0999,  0.2152,  0.0632,  0.2082,\n",
      "         0.2015, -0.0158, -0.1489, -0.2160, -0.0267,  0.1159,  0.1460, -0.2104,\n",
      "        -0.2137,  0.2379, -0.2511, -0.1196,  0.0773,  0.1514, -0.1774,  0.1768,\n",
      "         0.1635, -0.0309, -0.2339, -0.1581,  0.0523, -0.0783, -0.0920, -0.1565,\n",
      "        -0.2571, -0.0595,  0.2371,  0.1955, -0.0739, -0.0955, -0.1982,  0.0963,\n",
      "         0.0320, -0.1203, -0.1231, -0.0507, -0.0184, -0.1987, -0.0259, -0.0412,\n",
      "        -0.1913, -0.0306,  0.0106,  0.1259, -0.1088, -0.2151,  0.0611, -0.2154,\n",
      "         0.0568,  0.2158, -0.1472,  0.1538,  0.2223,  0.1215,  0.0115, -0.0673,\n",
      "        -0.2225,  0.1549, -0.0242, -0.0475,  0.1596,  0.0035,  0.0494, -0.0772,\n",
      "        -0.0338, -0.2298, -0.2340,  0.1640,  0.0194, -0.1410, -0.2508,  0.0934,\n",
      "        -0.2275,  0.0543,  0.1066,  0.0031,  0.1857,  0.0826, -0.1712,  0.1389,\n",
      "         0.2403,  0.1647, -0.0438,  0.0107,  0.0966, -0.0378,  0.0591, -0.0825,\n",
      "        -0.0453, -0.1654, -0.1889, -0.0583], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0471, -0.0535,  0.0532,  0.0505,  0.0117,  0.0184,  0.0171,  0.0447,\n",
      "          0.0045, -0.0241, -0.0020, -0.0059,  0.0367, -0.0003,  0.0560,  0.0127,\n",
      "          0.0164, -0.0548,  0.0293, -0.0105, -0.0247, -0.0357,  0.0235, -0.0558,\n",
      "         -0.0199, -0.0473, -0.0471,  0.0378,  0.0493, -0.0127, -0.0449, -0.0025,\n",
      "         -0.0495,  0.0300, -0.0546, -0.0462,  0.0339, -0.0453,  0.0509,  0.0351,\n",
      "          0.0139,  0.0070,  0.0363,  0.0172, -0.0378, -0.0561,  0.0317,  0.0483,\n",
      "          0.0018,  0.0017, -0.0309, -0.0261,  0.0452,  0.0090, -0.0289, -0.0399,\n",
      "          0.0126,  0.0383,  0.0289, -0.0565, -0.0415,  0.0433, -0.0323, -0.0322,\n",
      "         -0.0034, -0.0260, -0.0260, -0.0048, -0.0354, -0.0065, -0.0038,  0.0074,\n",
      "         -0.0251, -0.0295,  0.0125, -0.0221,  0.0272, -0.0564, -0.0411,  0.0167,\n",
      "         -0.0186, -0.0407,  0.0547, -0.0131,  0.0030, -0.0037, -0.0574, -0.0017,\n",
      "          0.0314, -0.0047, -0.0243,  0.0402,  0.0126,  0.0003,  0.0477,  0.0316,\n",
      "          0.0279,  0.0401, -0.0446,  0.0450,  0.0229, -0.0549, -0.0091, -0.0458,\n",
      "         -0.0381, -0.0399,  0.0076, -0.0290, -0.0377, -0.0032, -0.0563, -0.0052,\n",
      "          0.0309, -0.0404,  0.0305, -0.0214, -0.0083,  0.0218,  0.0476,  0.0571,\n",
      "         -0.0497, -0.0531, -0.0082,  0.0559, -0.0495,  0.0398, -0.0236,  0.0190,\n",
      "          0.0316, -0.0357, -0.0439, -0.0045, -0.0358, -0.0507,  0.0236, -0.0107,\n",
      "          0.0251, -0.0561, -0.0061, -0.0106,  0.0275,  0.0039, -0.0031, -0.0161,\n",
      "          0.0449, -0.0379, -0.0468,  0.0024,  0.0375,  0.0043,  0.0415,  0.0104,\n",
      "          0.0444, -0.0481, -0.0121, -0.0247,  0.0094, -0.0419,  0.0221, -0.0523,\n",
      "          0.0401, -0.0549,  0.0434, -0.0293,  0.0115,  0.0242, -0.0364,  0.0279,\n",
      "          0.0364, -0.0259, -0.0045,  0.0519,  0.0293,  0.0557,  0.0431,  0.0003,\n",
      "          0.0373, -0.0544, -0.0496,  0.0218, -0.0556, -0.0455,  0.0374, -0.0372,\n",
      "          0.0479,  0.0545, -0.0219,  0.0437, -0.0277, -0.0247,  0.0148, -0.0294,\n",
      "         -0.0322,  0.0178, -0.0313,  0.0326, -0.0081,  0.0412, -0.0019,  0.0117,\n",
      "          0.0238,  0.0487, -0.0054, -0.0187, -0.0344,  0.0188,  0.0383,  0.0284,\n",
      "         -0.0271,  0.0111,  0.0241,  0.0111,  0.0063,  0.0467,  0.0469,  0.0498,\n",
      "          0.0577,  0.0100,  0.0515,  0.0276, -0.0305, -0.0382, -0.0319,  0.0394,\n",
      "          0.0022,  0.0478, -0.0305, -0.0222,  0.0139, -0.0226, -0.0056,  0.0202,\n",
      "          0.0453,  0.0017,  0.0422,  0.0506,  0.0205, -0.0151, -0.0374, -0.0203,\n",
      "          0.0283,  0.0135,  0.0296,  0.0323,  0.0301,  0.0194, -0.0253, -0.0043,\n",
      "         -0.0118, -0.0113, -0.0406, -0.0529,  0.0553, -0.0210, -0.0326, -0.0126,\n",
      "          0.0427, -0.0446,  0.0494,  0.0402,  0.0063, -0.0475, -0.0083,  0.0449,\n",
      "         -0.0033, -0.0529,  0.0299, -0.0530, -0.0311,  0.0532,  0.0063, -0.0035,\n",
      "          0.0116, -0.0423, -0.0052, -0.0497,  0.0508,  0.0517, -0.0300,  0.0157,\n",
      "         -0.0311,  0.0212, -0.0114,  0.0569, -0.0076,  0.0318,  0.0380,  0.0238,\n",
      "          0.0366, -0.0479,  0.0282, -0.0225, -0.0400,  0.0143, -0.0088,  0.0025,\n",
      "         -0.0406,  0.0319,  0.0276,  0.0171]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0176], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1001], Loss: 0.7135\n",
      "Epoch [200/1001], Loss: 0.0758\n",
      "Epoch [400/1001], Loss: 0.0374\n",
      "Epoch [600/1001], Loss: 0.0167\n",
      "Epoch [800/1001], Loss: 0.0139\n",
      "Epoch [1000/1001], Loss: 0.0133\n",
      "\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1001\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "\n",
    "with torch.no_grad(): \n",
    "    train_accuracy = (model(x_train).gt(0.5).float() == y_train).float().mean().item()\n",
    "    test_accuracy = (model(x_test).gt(0.5).float() == y_test).float().mean().item()\n",
    "    \n",
    "    \n",
    "\n",
    "print(f'\\nTrain Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "#Train Accuracy: 0.9709 -> start\n",
    "#Test Accuracy: 0.9000 -> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
