{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=np.float32)\n",
    "    x = data[:, 0:-2]\n",
    "    y = data[:, [-1]] # after 3 months (-2) and 6 months (-1)\n",
    "    return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target to fix code\n",
    "\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(input_size, hidden_size), nn.Tanh())\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.layer2 = nn.Sequential(nn.Linear(hidden_size, output_size), nn.Sigmoid())\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        \n",
    "        return x # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_training_dataset.csv')\n",
    "x_test, y_test = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.2000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.3000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 0.7000, 0.6111, 1.0000, 0.1652, 0.4800],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 1.0000, 0.7222, 0.0000, 0.1739, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.2609, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.0556, 0.0000, 0.3043, 0.7500],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.0556, 0.0000, 0.1739, 0.0000],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.4783, 0.0000],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.3043, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.1739, 0.7500],\n",
       "        [0.0000, 1.0000, 0.1507, 0.0000, 0.2500, 0.7273, 0.2335, 0.3750, 0.2633,\n",
       "         0.2788, 0.9000, 0.2778, 1.0000, 0.3913, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.1739, 0.7500]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103, 15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(input_size=15, hidden_size=300, output_size=1)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0482, -0.0706, -0.1688,  ...,  0.0458, -0.1822, -0.0894],\n",
      "        [ 0.0705, -0.0958,  0.0143,  ...,  0.0077,  0.0535, -0.0869],\n",
      "        [-0.2401,  0.0612, -0.0770,  ..., -0.1265, -0.2160,  0.0340],\n",
      "        ...,\n",
      "        [ 0.0079, -0.2362,  0.1197,  ...,  0.0302, -0.0480, -0.0576],\n",
      "        [ 0.1733, -0.1842,  0.0277,  ...,  0.0591, -0.2484,  0.2536],\n",
      "        [-0.1551,  0.2096,  0.0577,  ..., -0.2392,  0.1370, -0.1859]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1066, -0.0464, -0.1400,  0.1375, -0.1974, -0.2422,  0.1093,  0.2350,\n",
      "         0.1269,  0.0880, -0.0256,  0.1215,  0.0475,  0.1911,  0.2304,  0.0359,\n",
      "        -0.1889,  0.0808,  0.1407,  0.2421,  0.1519, -0.0281,  0.2105, -0.0742,\n",
      "         0.2499,  0.1180,  0.0249, -0.0702,  0.0452, -0.0764, -0.1144,  0.1308,\n",
      "        -0.1799,  0.1725, -0.1646, -0.2424,  0.0068,  0.1477,  0.0081, -0.1217,\n",
      "         0.1032, -0.0204, -0.1548, -0.0423,  0.1294, -0.1122,  0.1987, -0.0289,\n",
      "        -0.0177, -0.1624,  0.1112,  0.1363,  0.1869, -0.0090, -0.1454,  0.1914,\n",
      "        -0.2417,  0.0730, -0.2385, -0.2500, -0.1373, -0.0788,  0.0460, -0.1520,\n",
      "         0.2497, -0.0539,  0.1924, -0.2289, -0.0352, -0.1293,  0.0616,  0.2515,\n",
      "        -0.0848, -0.0343, -0.1980,  0.1580, -0.0268, -0.1291,  0.0391,  0.0439,\n",
      "        -0.2169,  0.2561, -0.2567, -0.1069, -0.2308, -0.0590, -0.0333,  0.0059,\n",
      "         0.1592,  0.0793, -0.1631,  0.0338, -0.1894, -0.0603, -0.1603,  0.0360,\n",
      "        -0.1376, -0.1931, -0.0810, -0.1471,  0.0058,  0.1080,  0.0854,  0.2532,\n",
      "         0.1414, -0.0060,  0.1707, -0.2179, -0.1556, -0.0422,  0.0168,  0.0383,\n",
      "        -0.1813,  0.1311,  0.0755,  0.1056,  0.2097, -0.0359, -0.1092,  0.1794,\n",
      "        -0.0722,  0.2180, -0.1692,  0.2030, -0.0600, -0.1333,  0.1721,  0.1596,\n",
      "        -0.0632,  0.1569,  0.0883, -0.1010,  0.0292,  0.2395, -0.0525, -0.2275,\n",
      "        -0.1929, -0.1998,  0.0177,  0.1639, -0.1610,  0.1447,  0.2536, -0.1739,\n",
      "        -0.1009, -0.2421,  0.0253,  0.0163, -0.0305, -0.1467, -0.1350, -0.0887,\n",
      "        -0.1006, -0.0867,  0.1484,  0.1352, -0.1829, -0.2517,  0.2527,  0.0887,\n",
      "         0.0717,  0.1828,  0.2015,  0.1645,  0.2143, -0.0591,  0.2139,  0.0776,\n",
      "         0.1062,  0.1742, -0.2373,  0.0113,  0.1040,  0.1254,  0.1193, -0.0656,\n",
      "        -0.2168, -0.0333, -0.0867,  0.0321,  0.2286,  0.0564,  0.1094, -0.0650,\n",
      "        -0.1122,  0.1924, -0.0805, -0.1793, -0.1075, -0.1614, -0.0990, -0.1147,\n",
      "        -0.0736,  0.2425, -0.1389, -0.2300, -0.2087,  0.0589,  0.2270, -0.0313,\n",
      "        -0.0320,  0.0714, -0.1845, -0.0741, -0.1245, -0.0930,  0.0339,  0.2451,\n",
      "        -0.1057,  0.2545, -0.0815, -0.1003, -0.2547, -0.1463, -0.1854,  0.2570,\n",
      "         0.1119, -0.1065,  0.2135, -0.1655,  0.0915,  0.0159,  0.1966, -0.0395,\n",
      "         0.0350,  0.1476,  0.1707,  0.2511, -0.1904, -0.0139,  0.1718, -0.1657,\n",
      "        -0.0630, -0.1915,  0.1293,  0.1471, -0.0514,  0.1394, -0.2165,  0.2024,\n",
      "        -0.0665,  0.1482, -0.0737, -0.1289,  0.1391, -0.0742, -0.0158,  0.1855,\n",
      "        -0.2552, -0.1735, -0.0442, -0.0222,  0.2205,  0.2433,  0.0595,  0.2530,\n",
      "         0.1004,  0.0292,  0.1362,  0.1169, -0.0326, -0.0267, -0.0046, -0.1707,\n",
      "         0.2545,  0.1934, -0.2502,  0.1471,  0.0813,  0.1132, -0.0415, -0.1740,\n",
      "        -0.0915,  0.0170, -0.1075,  0.2557,  0.0099, -0.1226,  0.0032, -0.0848,\n",
      "         0.1915,  0.1635, -0.0405,  0.2419, -0.2177,  0.2243,  0.0144, -0.1359,\n",
      "        -0.0126, -0.0654, -0.1739,  0.0986,  0.0152, -0.1386, -0.0038, -0.0232,\n",
      "         0.0992, -0.1363, -0.0101, -0.1143], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0327,  0.0519,  0.0056, -0.0424,  0.0400, -0.0098,  0.0080,  0.0289,\n",
      "          0.0227,  0.0158,  0.0346,  0.0195, -0.0100, -0.0399,  0.0399,  0.0573,\n",
      "          0.0235, -0.0167,  0.0413,  0.0172, -0.0230,  0.0183,  0.0566, -0.0323,\n",
      "          0.0402, -0.0526,  0.0388, -0.0264,  0.0205,  0.0225,  0.0389, -0.0364,\n",
      "         -0.0172, -0.0548, -0.0525, -0.0402, -0.0008, -0.0185,  0.0096,  0.0317,\n",
      "          0.0330, -0.0227,  0.0164, -0.0468, -0.0330,  0.0460,  0.0563, -0.0134,\n",
      "         -0.0352,  0.0181, -0.0463, -0.0577,  0.0359,  0.0097,  0.0167, -0.0375,\n",
      "          0.0468,  0.0209,  0.0215, -0.0098,  0.0027,  0.0449,  0.0089,  0.0077,\n",
      "          0.0515,  0.0319,  0.0053, -0.0422, -0.0444,  0.0566,  0.0559,  0.0522,\n",
      "         -0.0564, -0.0088, -0.0520, -0.0296,  0.0004,  0.0293,  0.0185,  0.0063,\n",
      "         -0.0049,  0.0173, -0.0013,  0.0290,  0.0455,  0.0504,  0.0573, -0.0148,\n",
      "          0.0010, -0.0351, -0.0353,  0.0143, -0.0515,  0.0510,  0.0220,  0.0573,\n",
      "          0.0566, -0.0167, -0.0434, -0.0388,  0.0143, -0.0292,  0.0361, -0.0570,\n",
      "          0.0113,  0.0099, -0.0059, -0.0051,  0.0500, -0.0296, -0.0341,  0.0565,\n",
      "         -0.0270, -0.0225,  0.0082, -0.0066,  0.0553,  0.0276,  0.0141,  0.0187,\n",
      "         -0.0415, -0.0077, -0.0387,  0.0070, -0.0368, -0.0168, -0.0120,  0.0037,\n",
      "         -0.0033, -0.0373,  0.0317,  0.0237,  0.0568, -0.0139,  0.0096,  0.0188,\n",
      "          0.0428, -0.0531,  0.0423, -0.0235,  0.0246,  0.0270, -0.0438, -0.0019,\n",
      "          0.0042,  0.0326, -0.0286,  0.0053,  0.0326,  0.0134,  0.0371,  0.0186,\n",
      "         -0.0512, -0.0272,  0.0019, -0.0430,  0.0121, -0.0446,  0.0036, -0.0179,\n",
      "         -0.0486,  0.0342,  0.0413, -0.0376,  0.0527,  0.0249,  0.0561,  0.0337,\n",
      "          0.0218,  0.0317, -0.0190,  0.0509, -0.0403,  0.0390, -0.0510,  0.0063,\n",
      "         -0.0553,  0.0100,  0.0377, -0.0328,  0.0397,  0.0126,  0.0452, -0.0211,\n",
      "          0.0566,  0.0465, -0.0490, -0.0337,  0.0198, -0.0413,  0.0197,  0.0506,\n",
      "         -0.0276,  0.0549, -0.0334, -0.0129,  0.0061, -0.0177, -0.0317,  0.0534,\n",
      "         -0.0311, -0.0391, -0.0550,  0.0344,  0.0346, -0.0290, -0.0474,  0.0195,\n",
      "         -0.0523, -0.0013, -0.0382,  0.0051,  0.0144, -0.0041, -0.0142, -0.0230,\n",
      "         -0.0424, -0.0539, -0.0032, -0.0106,  0.0146,  0.0270,  0.0250,  0.0151,\n",
      "         -0.0467, -0.0134,  0.0303, -0.0321,  0.0172,  0.0522,  0.0370,  0.0097,\n",
      "         -0.0388,  0.0395, -0.0377, -0.0025, -0.0457, -0.0143, -0.0149,  0.0497,\n",
      "          0.0107, -0.0185,  0.0092,  0.0189, -0.0217, -0.0135, -0.0314,  0.0367,\n",
      "          0.0527,  0.0003, -0.0491, -0.0173,  0.0406,  0.0299, -0.0351, -0.0139,\n",
      "          0.0413,  0.0002, -0.0385, -0.0526,  0.0108, -0.0217, -0.0258,  0.0173,\n",
      "          0.0125,  0.0279, -0.0004, -0.0479,  0.0201,  0.0120,  0.0417, -0.0165,\n",
      "         -0.0462, -0.0061, -0.0230,  0.0035,  0.0246,  0.0153, -0.0357, -0.0450,\n",
      "         -0.0444, -0.0187, -0.0207,  0.0336,  0.0226, -0.0280,  0.0253,  0.0073,\n",
      "          0.0319, -0.0138, -0.0136,  0.0136, -0.0535, -0.0109, -0.0113, -0.0274,\n",
      "         -0.0119, -0.0003,  0.0489,  0.0570]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0359], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1001], Loss: 0.7084\n",
      "Epoch [200/1001], Loss: 0.0480\n",
      "Epoch [400/1001], Loss: 0.0207\n",
      "Epoch [600/1001], Loss: 0.0165\n",
      "Epoch [800/1001], Loss: 0.0142\n",
      "Epoch [1000/1001], Loss: 0.0190\n",
      "\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1001\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "\n",
    "with torch.no_grad(): \n",
    "    train_accuracy = (model(x_train).gt(0.5).float() == y_train).float().mean().item()\n",
    "    test_accuracy = (model(x_test).gt(0.5).float() == y_test).float().mean().item()\n",
    "    \n",
    "    \n",
    "\n",
    "print(f'\\nTrain Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "#Train Accuracy: 0.9709 -> start\n",
    "#Test Accuracy: 0.9000 -> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
