{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=np.float32)\n",
    "    x = data[:, 0:-2]\n",
    "    y = data[:, [-1]] # after 3 months (-2) and 6 months (-1)\n",
    "    return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target to fix code\n",
    "\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(input_size, hidden_size), nn.Sigmoid())\n",
    "        self.layer2 = nn.Sequential(nn.Linear(hidden_size, output_size), nn.Sigmoid())\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        #self.layer1 = nn.Sequential(nn.Linear(input_size, hidden_size), nn.Tanh())\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        #self.dropout = nn.Dropout(0.1)\n",
    "        #self.layer2 = nn.Sequential(nn.Linear(hidden_size, output_size), nn.Sigmoid())\n",
    "        #self.dropout = nn.Dropout(0.1)\n",
    "        #self.activation = torch.nn.ReLU()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        \n",
    "        return x # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_training_dataset.csv')\n",
    "x_test, y_test = load_data('/Users/withmocha/Library/CloudStorage/OneDrive-SejongUniversity/3학년 2학기/딥러닝개론/과제/과제1/hw1_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.2000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.2474, 0.5331, 0.1690, 0.5000, 0.7500, 0.4545, 0.9561, 0.2500, 0.3926,\n",
       "         0.2303, 0.3000, 0.0556, 0.0000, 0.3043, 0.0500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 0.7000, 0.6111, 1.0000, 0.1652, 0.4800],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.3268, 0.3718, 0.3380, 0.5000, 0.5000, 0.5455, 0.5575, 0.2500, 0.3998,\n",
       "         0.2061, 1.0000, 0.7222, 0.0000, 0.1739, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.2609, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.7222, 0.0000, 0.3043, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.0556, 0.0000, 0.3043, 0.7500],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.0556, 0.0000, 0.1739, 0.0000],\n",
       "        [0.0084, 0.5389, 0.0000, 1.0000, 0.2500, 0.1818, 0.6514, 0.0000, 0.0735,\n",
       "         0.3152, 0.4000, 1.0000, 1.0000, 0.4783, 0.0000],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.4000, 0.5000, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0042, 0.4179, 0.2535, 0.5000, 0.2500, 0.2727, 0.3986, 0.0000, 0.0000,\n",
       "         0.2388, 0.6000, 0.8333, 1.0000, 0.1739, 0.7500],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.3043, 0.0000],\n",
       "        [0.3208, 0.4467, 0.2676, 0.5000, 0.7500, 0.2727, 0.7489, 0.2812, 0.3559,\n",
       "         0.1939, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.3043, 0.0000],\n",
       "        [0.2777, 0.0000, 0.5211, 0.0000, 0.3750, 0.6364, 0.4522, 0.2500, 0.2147,\n",
       "         0.1455, 1.0000, 0.7222, 0.0000, 0.1739, 0.7500],\n",
       "        [0.0000, 1.0000, 0.1507, 0.0000, 0.2500, 0.7273, 0.2335, 0.3750, 0.2633,\n",
       "         0.2788, 0.9000, 0.2778, 1.0000, 0.3913, 0.0000],\n",
       "        [0.0168, 0.7176, 0.1408, 0.5000, 0.0000, 0.0000, 0.3968, 0.0312, 0.0581,\n",
       "         0.2970, 1.0000, 0.0556, 0.0000, 0.1739, 0.7500]])"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103, 15])"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test) # test set에는 transform만 사용하기\n",
    "\n",
    "\n",
    "x_train=torch.Tensor(x_train)\n",
    "x_test=torch.Tensor(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(input_size=15, hidden_size=300, output_size=1)\n",
    "criterion = nn.BCELoss()\n",
    "#optimizer = optim.Adam(model.parameters(),lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.05, betas=(0.95, 0.999),eps=1e-08,weight_decay=0.0001) # target to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2548,  0.2214, -0.0652,  ...,  0.1002,  0.0350,  0.1458],\n",
      "        [-0.0699, -0.2316, -0.0271,  ...,  0.0864, -0.0938, -0.0259],\n",
      "        [-0.0148,  0.2240, -0.1134,  ..., -0.2210,  0.0105,  0.0634],\n",
      "        ...,\n",
      "        [-0.0017, -0.1118,  0.2150,  ...,  0.1120,  0.1505, -0.1543],\n",
      "        [-0.1563, -0.0960, -0.2115,  ...,  0.2281, -0.1814,  0.1965],\n",
      "        [ 0.0598,  0.0164, -0.0777,  ..., -0.0014, -0.2471, -0.1081]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 4.4400e-02, -2.4442e-01,  1.8260e-01, -9.3974e-02,  1.2757e-01,\n",
      "         2.4206e-01, -1.7455e-01,  2.4648e-01,  2.3671e-01, -1.3707e-01,\n",
      "        -1.6273e-01, -2.4677e-01, -1.4937e-01,  2.0342e-01,  2.2062e-01,\n",
      "         1.2486e-01, -2.0262e-01,  1.1832e-01,  9.1963e-02, -9.1221e-02,\n",
      "         1.6841e-01, -8.9864e-02, -2.1133e-01, -9.3195e-02,  1.2563e-01,\n",
      "         1.4545e-01, -4.9231e-03,  4.7382e-04, -6.1852e-02,  1.2594e-01,\n",
      "         1.4731e-01,  1.4109e-01,  2.1799e-01,  1.4251e-01,  2.3852e-01,\n",
      "        -8.7817e-02,  2.2876e-01,  4.3645e-02,  2.1819e-01, -1.9699e-01,\n",
      "         1.6796e-01, -2.1032e-01, -1.8103e-01, -3.8499e-03,  1.1189e-01,\n",
      "         1.8717e-01,  2.1020e-02, -9.2934e-02,  6.7578e-02,  2.1475e-01,\n",
      "         7.0697e-02, -2.1856e-01, -8.7834e-02,  1.3955e-01,  2.0869e-01,\n",
      "        -1.4903e-01, -2.0621e-01,  2.0053e-01, -2.2682e-01,  2.4461e-01,\n",
      "        -2.1464e-01, -2.0730e-01, -1.3521e-01, -3.0279e-02,  2.2406e-01,\n",
      "        -1.8365e-01,  1.8648e-01,  6.0172e-02,  2.1638e-01,  6.1965e-02,\n",
      "        -1.5649e-01,  4.9594e-02,  1.8802e-01, -1.7840e-01,  1.1225e-01,\n",
      "        -1.1458e-01,  1.1728e-01, -2.1084e-01, -2.0367e-01, -1.3278e-01,\n",
      "        -9.1365e-02, -7.7696e-03, -1.9533e-01,  2.4528e-01, -2.2655e-01,\n",
      "        -9.2669e-02, -5.4021e-02,  4.7960e-02, -2.5303e-02, -5.7030e-02,\n",
      "         1.0050e-01,  5.7369e-02, -2.0251e-01,  1.0192e-01, -2.1676e-01,\n",
      "        -9.3786e-02, -1.3413e-01,  1.1838e-01, -2.5291e-01, -8.5926e-02,\n",
      "         3.4398e-02, -6.4939e-02,  1.1620e-02, -8.9529e-02, -1.2789e-02,\n",
      "        -9.4478e-02, -2.2711e-01,  9.9371e-02,  6.8865e-02,  1.7662e-01,\n",
      "        -1.5733e-01, -1.4722e-01,  1.4645e-01, -8.7078e-02, -2.2895e-01,\n",
      "         5.8396e-02,  2.0852e-01,  1.7900e-01, -4.7740e-02, -1.6895e-02,\n",
      "         1.2398e-01, -1.3408e-01,  8.4586e-02, -1.4490e-01,  1.0007e-01,\n",
      "        -2.4687e-01, -9.8078e-02,  2.2477e-01, -4.6633e-02,  9.2716e-02,\n",
      "        -7.4739e-02, -1.2871e-01,  2.0821e-01, -2.1500e-02,  1.4340e-01,\n",
      "        -1.2379e-01,  6.8083e-02, -4.4481e-02, -2.0761e-01,  1.2269e-03,\n",
      "        -1.6098e-01,  1.9956e-01,  1.5322e-01, -1.2577e-01,  1.9601e-01,\n",
      "         4.0757e-03,  1.2534e-01, -2.3495e-01,  5.5704e-02,  2.1852e-01,\n",
      "        -1.5543e-01, -7.9329e-02,  1.2508e-01,  3.8431e-02,  1.4480e-01,\n",
      "        -5.6700e-03, -2.3498e-01,  1.6068e-01, -6.6985e-02, -2.3875e-01,\n",
      "         2.0551e-01,  2.4859e-01,  1.2391e-01, -2.3159e-01,  2.3384e-01,\n",
      "         1.1571e-01,  1.4493e-01,  6.7893e-02, -1.9884e-01,  3.2207e-02,\n",
      "        -2.4050e-01,  1.9422e-01,  2.0725e-01, -3.6445e-02,  1.6401e-01,\n",
      "         1.0622e-01,  1.8403e-01, -4.8326e-02, -1.9458e-01, -1.9415e-01,\n",
      "         1.9545e-01, -4.3310e-02, -2.0394e-02,  9.6883e-02,  2.3384e-01,\n",
      "         1.8935e-02, -7.9780e-02, -1.8352e-01,  3.8670e-02,  7.1056e-02,\n",
      "        -9.0554e-05,  1.9896e-01,  1.6903e-01,  2.4043e-01,  1.2317e-02,\n",
      "         1.8001e-01,  2.0029e-02, -9.4749e-02,  1.7022e-01,  2.4362e-01,\n",
      "        -2.3951e-01, -1.3419e-01,  2.1528e-01,  1.9637e-01, -1.5297e-01,\n",
      "        -9.5249e-02,  6.2318e-02,  1.4686e-01, -1.9043e-01, -3.7944e-02,\n",
      "         2.1857e-01, -1.8904e-01,  1.0329e-01, -8.9169e-05,  4.6937e-02,\n",
      "         1.6105e-01, -1.3615e-01, -1.0252e-01,  7.5325e-03, -1.5155e-01,\n",
      "         1.1663e-01, -2.1948e-01,  1.9924e-01, -2.0786e-02, -7.4203e-02,\n",
      "         2.3732e-01, -5.8204e-02, -1.5570e-02,  5.5901e-02,  1.7760e-02,\n",
      "         1.7311e-01,  1.2707e-01,  2.2009e-01,  1.7778e-01,  2.4250e-02,\n",
      "         1.3002e-01,  1.0036e-01,  3.3642e-02, -9.5746e-02, -2.3300e-01,\n",
      "         1.4140e-01, -2.2586e-01,  2.4647e-01, -1.8225e-01, -6.2883e-02,\n",
      "        -9.5056e-02,  1.4368e-01,  2.2747e-01,  1.8980e-01, -1.5335e-01,\n",
      "        -2.1348e-01, -1.1158e-02, -2.4600e-01, -4.1063e-02,  2.0221e-01,\n",
      "        -1.9508e-01, -9.8817e-02,  3.1422e-02,  9.8061e-02, -7.9508e-02,\n",
      "         2.3389e-01,  1.2923e-01, -1.6641e-01,  2.8132e-03, -7.2730e-02,\n",
      "        -9.1904e-02,  4.2184e-02, -2.4398e-01,  1.4846e-02, -3.8671e-03,\n",
      "         8.8667e-02,  1.6281e-01,  2.4090e-01,  2.1048e-01, -1.9274e-01,\n",
      "         1.1021e-01, -9.2521e-02,  1.3784e-01,  1.5840e-01, -1.7705e-01,\n",
      "         1.8772e-01, -2.3059e-02,  2.1068e-01,  2.4306e-01, -7.6366e-02,\n",
      "        -1.3511e-01,  1.8348e-01,  4.8966e-02, -2.5648e-01,  1.3446e-01,\n",
      "        -2.1879e-01, -1.3707e-01,  1.5703e-01,  6.2511e-02, -4.0438e-02,\n",
      "        -1.6304e-01, -9.1506e-02, -1.2867e-01, -3.5044e-02, -2.4919e-01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.4636e-03, -4.2805e-02, -1.2663e-02,  2.8586e-02, -3.3682e-02,\n",
      "          2.9357e-02,  5.3728e-02, -9.1342e-03,  3.4909e-02, -4.0205e-02,\n",
      "         -2.1019e-02,  3.2803e-02, -6.3058e-03, -2.3921e-02, -3.2628e-02,\n",
      "          1.5094e-02, -6.9641e-03,  2.2338e-02, -7.9683e-03,  6.3195e-03,\n",
      "         -5.6821e-02, -5.2570e-02,  5.0303e-02, -1.5967e-02,  4.7901e-02,\n",
      "          2.9615e-02,  2.1518e-02, -8.3141e-03,  1.5401e-02,  2.0109e-02,\n",
      "          4.0897e-02,  1.8870e-02, -4.9138e-02, -2.7743e-02,  4.2654e-02,\n",
      "          3.6958e-02, -2.3849e-02,  1.2625e-02,  3.0850e-02,  4.6343e-02,\n",
      "         -4.5085e-03, -3.0143e-02, -2.2914e-02, -4.4042e-02, -8.3477e-03,\n",
      "         -5.5336e-02,  5.5343e-02,  1.3255e-02,  2.1871e-02,  1.8579e-02,\n",
      "          5.3018e-02,  2.7418e-02,  5.1044e-02,  4.2246e-02,  1.7800e-02,\n",
      "         -4.6589e-02,  5.7262e-02,  5.5747e-02,  2.1186e-02,  1.4873e-03,\n",
      "          3.6256e-02,  3.8590e-02,  4.0837e-02, -9.2621e-04,  3.4994e-02,\n",
      "         -2.5041e-02,  2.3714e-02, -2.1041e-02,  1.5219e-02, -3.5551e-02,\n",
      "          2.1978e-03, -3.2152e-02,  2.0240e-02, -1.8792e-02, -5.7233e-02,\n",
      "         -1.3712e-02,  2.9225e-02, -4.4094e-02,  3.8334e-02,  4.1530e-02,\n",
      "         -4.6391e-02, -1.4834e-02, -4.4215e-02,  5.4701e-02,  7.5907e-03,\n",
      "         -5.2451e-02,  5.8021e-03, -3.7861e-02,  6.9695e-03, -1.0033e-02,\n",
      "         -3.0262e-02,  1.2735e-02,  1.7567e-02,  4.4245e-02,  5.1792e-02,\n",
      "          1.0022e-02, -3.8510e-02,  2.3360e-02, -4.9711e-02,  5.3265e-02,\n",
      "         -3.6812e-02,  4.6633e-02,  3.4224e-03,  5.7216e-02,  2.6895e-02,\n",
      "         -4.4316e-02,  5.3039e-02,  2.0595e-02, -1.1000e-02,  2.1042e-02,\n",
      "         -3.0761e-02, -4.6287e-02, -2.0867e-02, -3.5502e-02,  3.2431e-02,\n",
      "         -2.5042e-02,  2.8294e-02,  2.4208e-02,  5.3792e-02,  2.9155e-02,\n",
      "         -4.3075e-02,  3.6158e-02, -4.1832e-02,  3.3391e-02, -1.0778e-02,\n",
      "          5.7719e-02, -2.5173e-02, -4.5535e-02,  2.4152e-02, -1.9484e-03,\n",
      "         -5.4471e-02,  3.7793e-02, -4.2923e-02, -4.8581e-02,  4.5440e-02,\n",
      "          5.0483e-02, -2.9633e-02,  1.6899e-02,  1.3214e-02,  3.4058e-02,\n",
      "         -3.3071e-02,  4.2870e-02, -5.2362e-02, -4.2026e-03,  5.2526e-02,\n",
      "         -2.9339e-02, -2.5127e-02,  1.8916e-02,  1.0814e-02,  2.9082e-02,\n",
      "          5.8793e-03, -4.3357e-02, -5.0186e-02, -2.1092e-02,  6.5400e-03,\n",
      "         -5.8218e-03,  4.9991e-02,  1.7217e-02, -1.7274e-02, -1.9005e-04,\n",
      "         -2.3883e-02,  1.0235e-02,  4.9485e-02,  5.6664e-02, -1.2968e-02,\n",
      "         -2.4144e-02, -1.6423e-02,  4.4249e-02,  2.6329e-02,  6.0741e-03,\n",
      "          2.3761e-02,  2.8933e-02, -2.1881e-02, -9.6263e-04, -1.2560e-02,\n",
      "         -1.6958e-02,  1.5750e-02, -2.7960e-02,  4.1009e-02, -1.6483e-02,\n",
      "         -2.1980e-02, -5.7373e-02,  3.5083e-02,  4.9336e-02, -5.6433e-03,\n",
      "          5.1885e-02, -1.1777e-02,  2.0696e-02, -5.3045e-02, -4.6145e-03,\n",
      "         -3.3561e-02,  5.4798e-02, -4.6667e-02, -5.5092e-02, -1.1513e-02,\n",
      "          1.2210e-02,  4.0122e-02, -5.0195e-02,  1.3129e-02, -1.3747e-02,\n",
      "         -4.0520e-03,  4.5119e-02,  5.7474e-02,  1.0438e-02,  2.0897e-02,\n",
      "         -1.0023e-03,  2.8160e-02,  8.0868e-03, -1.7712e-02,  1.8854e-02,\n",
      "         -2.5918e-02, -5.3130e-02,  3.0368e-02,  2.1053e-02, -3.4648e-03,\n",
      "          4.4869e-02, -1.2122e-02, -1.9099e-02, -3.9495e-02, -3.7953e-02,\n",
      "          4.5126e-02, -1.9919e-02, -2.7899e-02, -2.7373e-02,  2.1736e-02,\n",
      "         -2.1947e-03, -4.0909e-02,  5.6481e-02, -2.5086e-02, -1.3654e-02,\n",
      "          1.7019e-02,  2.7172e-02, -1.8889e-02, -1.0126e-02, -5.4650e-02,\n",
      "         -1.7817e-02, -5.6549e-02, -9.9716e-03,  1.5824e-02,  5.4509e-02,\n",
      "         -4.1274e-04,  2.3874e-02, -5.1069e-02, -3.6292e-03, -5.3332e-02,\n",
      "         -1.7778e-02,  5.1575e-02,  1.8720e-02,  1.3620e-02, -5.9672e-03,\n",
      "          2.0134e-02,  2.7710e-02,  1.1465e-02,  4.8187e-02, -1.0786e-03,\n",
      "         -2.0601e-02, -3.9855e-02,  2.2462e-02,  6.7387e-05,  4.0572e-03,\n",
      "          3.5461e-02,  3.7958e-02,  3.7379e-02, -4.3093e-02,  1.0403e-02,\n",
      "         -3.1869e-02,  3.2836e-02, -4.0562e-02,  4.0580e-02,  4.4870e-02,\n",
      "         -5.1206e-02, -5.1578e-02, -3.1086e-02,  1.7970e-03, -2.0554e-02,\n",
      "          1.4751e-02,  2.2123e-02,  4.7636e-02,  1.5676e-02, -1.0710e-02,\n",
      "         -2.3499e-02,  2.6735e-02, -3.3204e-02, -4.5121e-02, -7.4825e-03,\n",
      "          3.6070e-02,  4.2389e-02, -7.7588e-03,  7.6145e-03, -5.6052e-02,\n",
      "         -5.1453e-02, -4.2069e-02, -2.4121e-02,  9.4674e-03, -3.2518e-02,\n",
      "         -4.9916e-02,  1.6488e-02, -2.4428e-02, -4.2216e-02, -5.5121e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0164], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming y is torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1001], Loss: 0.7107\n",
      "Epoch [200/1001], Loss: 0.1384\n",
      "Epoch [400/1001], Loss: 0.0534\n",
      "Epoch [600/1001], Loss: 0.0322\n",
      "Epoch [800/1001], Loss: 0.0242\n",
      "Epoch [1000/1001], Loss: 0.0187\n",
      "\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1001\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "\n",
    "with torch.no_grad(): \n",
    "    train_accuracy = (model(x_train).gt(0.5).float() == y_train).float().mean().item()\n",
    "    test_accuracy = (model(x_test).gt(0.5).float() == y_test).float().mean().item()\n",
    "    \n",
    "    \n",
    "\n",
    "print(f'\\nTrain Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "#Train Accuracy: 0.9709 -> start\n",
    "#Test Accuracy: 0.9000 -> start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
