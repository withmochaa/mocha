{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FORCE</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>X COORDINATE</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>FSR DATA divided mass</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A(Big toe)</td>\n",
       "      <td>B(Right)</td>\n",
       "      <td>C(Left)</td>\n",
       "      <td>D(Heel)</td>\n",
       "      <td>E(Little toe)</td>\n",
       "      <td>F(Center)</td>\n",
       "      <td>A(Big toe)</td>\n",
       "      <td>B(Right)</td>\n",
       "      <td>C(Left)</td>\n",
       "      <td>...</td>\n",
       "      <td>C(Left)</td>\n",
       "      <td>D(Heel)</td>\n",
       "      <td>E(Little toe)</td>\n",
       "      <td>F(Center)</td>\n",
       "      <td>A(Big toe)</td>\n",
       "      <td>B(Right)</td>\n",
       "      <td>C(Left)</td>\n",
       "      <td>D(Heel)</td>\n",
       "      <td>E(Little toe)</td>\n",
       "      <td>F(Center)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>201</td>\n",
       "      <td>1073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.12</td>\n",
       "      <td>4.099502</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>221</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.107843</td>\n",
       "      <td>4.042986</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.603175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>262</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.159259</td>\n",
       "      <td>4.053435</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>307</td>\n",
       "      <td>1117</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.050781</td>\n",
       "      <td>3.939739</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.68254</td>\n",
       "      <td>1.761905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.412698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5009 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       FORCE Unnamed: 2 Unnamed: 3 Unnamed: 4     Unnamed: 5  \\\n",
       "0            NaN  A(Big toe)   B(Right)    C(Left)    D(Heel)  E(Little toe)   \n",
       "1            NaN           0        100        201       1073              0   \n",
       "2            NaN           0        102        221       1067              0   \n",
       "3            NaN           0        135        262       1088              0   \n",
       "4            NaN           0        128        307       1117              0   \n",
       "...          ...         ...        ...        ...        ...            ...   \n",
       "5004         NaN           0          0          0       1176              0   \n",
       "5005         NaN           0          0          0        753              0   \n",
       "5006         NaN           0          0          0        371              0   \n",
       "5007         NaN           0          0          0        176              0   \n",
       "5008         NaN           0          0          0         51              0   \n",
       "\n",
       "     Unnamed: 6 X COORDINATE Unnamed: 8 Unnamed: 9  ... Unnamed: 29  \\\n",
       "0     F(Center)   A(Big toe)   B(Right)    C(Left)  ...     C(Left)   \n",
       "1             0          NaN       7.12   4.099502  ...          37   \n",
       "2             0          NaN   7.107843   4.042986  ...          36   \n",
       "3             0          NaN   7.159259   4.053435  ...          38   \n",
       "4             7          NaN   7.050781   3.939739  ...          43   \n",
       "...         ...          ...        ...        ...  ...         ...   \n",
       "5004          0          NaN        NaN        NaN  ...           0   \n",
       "5005          0          NaN        NaN        NaN  ...           0   \n",
       "5006          0          NaN        NaN        NaN  ...           0   \n",
       "5007          0          NaN        NaN        NaN  ...           0   \n",
       "5008          0          NaN        NaN        NaN  ...           0   \n",
       "\n",
       "     Unnamed: 30    Unnamed: 31 Unnamed: 32 FSR DATA divided mass Unnamed: 34  \\\n",
       "0        D(Heel)  E(Little toe)   F(Center)            A(Big toe)    B(Right)   \n",
       "1             99              0           0                     0           0   \n",
       "2            101              0           0                     0           0   \n",
       "3            105              0           0                     0           0   \n",
       "4            111              0           0                     0    0.698413   \n",
       "...          ...            ...         ...                   ...         ...   \n",
       "5004          89              0           0                     0           0   \n",
       "5005          69              0           0                     0           0   \n",
       "5006          56              0           0                     0           0   \n",
       "5007          49              0           0                     0           0   \n",
       "5008          47              0           0                     0           0   \n",
       "\n",
       "     Unnamed: 35 Unnamed: 36    Unnamed: 37 Unnamed: 38  \n",
       "0        C(Left)     D(Heel)  E(Little toe)   F(Center)  \n",
       "1       0.587302    1.571429              0           0  \n",
       "2       0.571429    1.603175              0           0  \n",
       "3       0.603175    1.666667              0           0  \n",
       "4        0.68254    1.761905              0           0  \n",
       "...          ...         ...            ...         ...  \n",
       "5004           0    1.412698              0           0  \n",
       "5005           0    1.095238              0           0  \n",
       "5006           0    0.888889              0           0  \n",
       "5007           0    0.777778              0           0  \n",
       "5008           0    0.746032              0           0  \n",
       "\n",
       "[5009 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_excel(\"/Users/withmocha/Desktop/TEED/data/HJI/Fittingsum.xlsx\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                5009\n",
       "FORCE                        0\n",
       "Unnamed: 2                   0\n",
       "Unnamed: 3                   0\n",
       "Unnamed: 4                   0\n",
       "Unnamed: 5                   0\n",
       "Unnamed: 6                   0\n",
       "X COORDINATE              3604\n",
       "Unnamed: 8                2387\n",
       "Unnamed: 9                 925\n",
       "Unnamed: 10               1022\n",
       "Unnamed: 11               3864\n",
       "Unnamed: 12               2320\n",
       "Y COORDINATE              3604\n",
       "Unnamed: 14               2387\n",
       "Unnamed: 15                925\n",
       "Unnamed: 16               1022\n",
       "Unnamed: 17               3864\n",
       "Unnamed: 18               2320\n",
       "COP                        162\n",
       "Unnamed: 20                162\n",
       "FSR DATA                     0\n",
       "Unnamed: 22                  0\n",
       "Unnamed: 23                  0\n",
       "Unnamed: 24                  0\n",
       "Unnamed: 25                  0\n",
       "Unnamed: 26                  0\n",
       "FSR DATA without noise       0\n",
       "Unnamed: 28                  0\n",
       "Unnamed: 29                  0\n",
       "Unnamed: 30                  0\n",
       "Unnamed: 31                  0\n",
       "Unnamed: 32                  0\n",
       "FSR DATA divided mass        0\n",
       "Unnamed: 34                  0\n",
       "Unnamed: 35                  0\n",
       "Unnamed: 36                  0\n",
       "Unnamed: 37                  0\n",
       "Unnamed: 38                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORCE</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>X COORDINATE</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>FSR DATA divided mass</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>201</td>\n",
       "      <td>1073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.12</td>\n",
       "      <td>4.099502</td>\n",
       "      <td>5.979031</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>221</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.107843</td>\n",
       "      <td>4.042986</td>\n",
       "      <td>5.973758</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.603175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>262</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.159259</td>\n",
       "      <td>4.053435</td>\n",
       "      <td>5.966452</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>307</td>\n",
       "      <td>1117</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.050781</td>\n",
       "      <td>3.939739</td>\n",
       "      <td>5.945837</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.68254</td>\n",
       "      <td>1.761905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>369</td>\n",
       "      <td>1121</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.096552</td>\n",
       "      <td>3.940379</td>\n",
       "      <td>5.929527</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.904762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.733844</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.412698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.72178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.725067</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.735795</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.901961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5008 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FORCE Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
       "1        0        100        201       1073          0          0   \n",
       "2        0        102        221       1067          0          0   \n",
       "3        0        135        262       1088          0          0   \n",
       "4        0        128        307       1117          0          7   \n",
       "5        0        145        369       1121          0          8   \n",
       "...    ...        ...        ...        ...        ...        ...   \n",
       "5004     0          0          0       1176          0          0   \n",
       "5005     0          0          0        753          0          0   \n",
       "5006     0          0          0        371          0          0   \n",
       "5007     0          0          0        176          0          0   \n",
       "5008     0          0          0         51          0          0   \n",
       "\n",
       "     X COORDINATE Unnamed: 8 Unnamed: 9 Unnamed: 10  ... Unnamed: 29  \\\n",
       "1             NaN       7.12   4.099502    5.979031  ...          37   \n",
       "2             NaN   7.107843   4.042986    5.973758  ...          36   \n",
       "3             NaN   7.159259   4.053435    5.966452  ...          38   \n",
       "4             NaN   7.050781   3.939739    5.945837  ...          43   \n",
       "5             NaN   7.096552   3.940379    5.929527  ...          49   \n",
       "...           ...        ...        ...         ...  ...         ...   \n",
       "5004          NaN        NaN        NaN    5.733844  ...           0   \n",
       "5005          NaN        NaN        NaN     5.72178  ...           0   \n",
       "5006          NaN        NaN        NaN    5.725067  ...           0   \n",
       "5007          NaN        NaN        NaN    5.735795  ...           0   \n",
       "5008          NaN        NaN        NaN    5.901961  ...           0   \n",
       "\n",
       "     Unnamed: 30 Unnamed: 31 Unnamed: 32 FSR DATA divided mass Unnamed: 34  \\\n",
       "1             99           0           0                     0           0   \n",
       "2            101           0           0                     0           0   \n",
       "3            105           0           0                     0           0   \n",
       "4            111           0           0                     0    0.698413   \n",
       "5            120           0           0                     0    0.730159   \n",
       "...          ...         ...         ...                   ...         ...   \n",
       "5004          89           0           0                     0           0   \n",
       "5005          69           0           0                     0           0   \n",
       "5006          56           0           0                     0           0   \n",
       "5007          49           0           0                     0           0   \n",
       "5008          47           0           0                     0           0   \n",
       "\n",
       "     Unnamed: 35 Unnamed: 36 Unnamed: 37 Unnamed: 38  \n",
       "1       0.587302    1.571429           0           0  \n",
       "2       0.571429    1.603175           0           0  \n",
       "3       0.603175    1.666667           0           0  \n",
       "4        0.68254    1.761905           0           0  \n",
       "5       0.777778    1.904762           0           0  \n",
       "...          ...         ...         ...         ...  \n",
       "5004           0    1.412698           0           0  \n",
       "5005           0    1.095238           0           0  \n",
       "5006           0    0.888889           0           0  \n",
       "5007           0    0.777778           0           0  \n",
       "5008           0    0.746032           0           0  \n",
       "\n",
       "[5008 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(index=[0])\n",
    "data=data.drop(columns='Unnamed: 0',axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FORCE', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5',\n",
       "       'Unnamed: 6', 'X COORDINATE', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10',\n",
       "       'Unnamed: 11', 'Unnamed: 12', 'Y COORDINATE', 'Unnamed: 14',\n",
       "       'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'COP',\n",
       "       'Unnamed: 20', 'FSR DATA', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24',\n",
       "       'Unnamed: 25', 'Unnamed: 26', 'FSR DATA without noise', 'Unnamed: 28',\n",
       "       'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32',\n",
       "       'FSR DATA divided mass', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36',\n",
       "       'Unnamed: 37', 'Unnamed: 38'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=data.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns:\n",
    "    data[i].fillna(data[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP_X=data[[\"COP\"]]\n",
    "COP_Y=data[[\"Unnamed: 20\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COP=pd.concat([COP_X,COP_Y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y_COP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns=['COP','Unnamed: 20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FORCE                     0\n",
       "Unnamed: 2                0\n",
       "Unnamed: 3                0\n",
       "Unnamed: 4                0\n",
       "Unnamed: 5                0\n",
       "Unnamed: 6                0\n",
       "X COORDINATE              0\n",
       "Unnamed: 8                0\n",
       "Unnamed: 9                0\n",
       "Unnamed: 10               0\n",
       "Unnamed: 11               0\n",
       "Unnamed: 12               0\n",
       "Y COORDINATE              0\n",
       "Unnamed: 14               0\n",
       "Unnamed: 15               0\n",
       "Unnamed: 16               0\n",
       "Unnamed: 17               0\n",
       "Unnamed: 18               0\n",
       "FSR DATA                  0\n",
       "Unnamed: 22               0\n",
       "Unnamed: 23               0\n",
       "Unnamed: 24               0\n",
       "Unnamed: 25               0\n",
       "Unnamed: 26               0\n",
       "FSR DATA without noise    0\n",
       "Unnamed: 28               0\n",
       "Unnamed: 29               0\n",
       "Unnamed: 30               0\n",
       "Unnamed: 31               0\n",
       "Unnamed: 32               0\n",
       "FSR DATA divided mass     0\n",
       "Unnamed: 34               0\n",
       "Unnamed: 35               0\n",
       "Unnamed: 36               0\n",
       "Unnamed: 37               0\n",
       "Unnamed: 38               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler= MinMaxScaler()\n",
    "\n",
    "X=pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/withmocha/opt/anaconda3/envs/conda/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans=KMeans(n_clusters=4)\n",
    "clusters=kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cluster']=clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORCE</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>X COORDINATE</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>FSR DATA divided mass</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053447</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.546488</td>\n",
       "      <td>0.559844</td>\n",
       "      <td>0.649491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043943</td>\n",
       "      <td>0.159935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054516</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.274646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.540556</td>\n",
       "      <td>0.542081</td>\n",
       "      <td>0.647484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042755</td>\n",
       "      <td>0.163166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072154</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.280051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.565644</td>\n",
       "      <td>0.545365</td>\n",
       "      <td>0.644704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045131</td>\n",
       "      <td>0.169628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068413</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.287516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.512714</td>\n",
       "      <td>0.509632</td>\n",
       "      <td>0.636858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080882</td>\n",
       "      <td>0.051069</td>\n",
       "      <td>0.179321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077499</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>0.288546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.535047</td>\n",
       "      <td>0.509834</td>\n",
       "      <td>0.630650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084559</td>\n",
       "      <td>0.058195</td>\n",
       "      <td>0.193861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.302703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.429861</td>\n",
       "      <td>0.470275</td>\n",
       "      <td>0.556176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.193822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.429861</td>\n",
       "      <td>0.470275</td>\n",
       "      <td>0.551584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.095495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.429861</td>\n",
       "      <td>0.470275</td>\n",
       "      <td>0.552836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.429861</td>\n",
       "      <td>0.470275</td>\n",
       "      <td>0.556919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483302</td>\n",
       "      <td>0.429861</td>\n",
       "      <td>0.470275</td>\n",
       "      <td>0.620159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5008 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FORCE  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \\\n",
       "0       0.0    0.053447      0.0804    0.276190         0.0    0.000000   \n",
       "1       0.0    0.054516      0.0884    0.274646         0.0    0.000000   \n",
       "2       0.0    0.072154      0.1048    0.280051         0.0    0.000000   \n",
       "3       0.0    0.068413      0.1228    0.287516         0.0    0.010638   \n",
       "4       0.0    0.077499      0.1476    0.288546         0.0    0.012158   \n",
       "...     ...         ...         ...         ...         ...         ...   \n",
       "5003    0.0    0.000000      0.0000    0.302703         0.0    0.000000   \n",
       "5004    0.0    0.000000      0.0000    0.193822         0.0    0.000000   \n",
       "5005    0.0    0.000000      0.0000    0.095495         0.0    0.000000   \n",
       "5006    0.0    0.000000      0.0000    0.045302         0.0    0.000000   \n",
       "5007    0.0    0.000000      0.0000    0.013127         0.0    0.000000   \n",
       "\n",
       "      X COORDINATE  Unnamed: 8  Unnamed: 9  Unnamed: 10  ...  Unnamed: 30  \\\n",
       "0         0.483302    0.546488    0.559844     0.649491  ...     0.159935   \n",
       "1         0.483302    0.540556    0.542081     0.647484  ...     0.163166   \n",
       "2         0.483302    0.565644    0.545365     0.644704  ...     0.169628   \n",
       "3         0.483302    0.512714    0.509632     0.636858  ...     0.179321   \n",
       "4         0.483302    0.535047    0.509834     0.630650  ...     0.193861   \n",
       "...            ...         ...         ...          ...  ...          ...   \n",
       "5003      0.483302    0.429861    0.470275     0.556176  ...     0.143780   \n",
       "5004      0.483302    0.429861    0.470275     0.551584  ...     0.111470   \n",
       "5005      0.483302    0.429861    0.470275     0.552836  ...     0.090468   \n",
       "5006      0.483302    0.429861    0.470275     0.556919  ...     0.079160   \n",
       "5007      0.483302    0.429861    0.470275     0.620159  ...     0.075929   \n",
       "\n",
       "      Unnamed: 31  Unnamed: 32  FSR DATA divided mass  Unnamed: 34  \\\n",
       "0             0.0          0.0                    0.0     0.000000   \n",
       "1             0.0          0.0                    0.0     0.000000   \n",
       "2             0.0          0.0                    0.0     0.000000   \n",
       "3             0.0          0.0                    0.0     0.080882   \n",
       "4             0.0          0.0                    0.0     0.084559   \n",
       "...           ...          ...                    ...          ...   \n",
       "5003          0.0          0.0                    0.0     0.000000   \n",
       "5004          0.0          0.0                    0.0     0.000000   \n",
       "5005          0.0          0.0                    0.0     0.000000   \n",
       "5006          0.0          0.0                    0.0     0.000000   \n",
       "5007          0.0          0.0                    0.0     0.000000   \n",
       "\n",
       "      Unnamed: 35  Unnamed: 36  Unnamed: 37  Unnamed: 38  cluster  \n",
       "0        0.043943     0.159935          0.0          0.0        0  \n",
       "1        0.042755     0.163166          0.0          0.0        0  \n",
       "2        0.045131     0.169628          0.0          0.0        0  \n",
       "3        0.051069     0.179321          0.0          0.0        0  \n",
       "4        0.058195     0.193861          0.0          0.0        0  \n",
       "...           ...          ...          ...          ...      ...  \n",
       "5003     0.000000     0.143780          0.0          0.0        0  \n",
       "5004     0.000000     0.111470          0.0          0.0        0  \n",
       "5005     0.000000     0.090468          0.0          0.0        0  \n",
       "5006     0.000000     0.079160          0.0          0.0        0  \n",
       "5007     0.000000     0.075929          0.0          0.0        0  \n",
       "\n",
       "[5008 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORCE</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>X COORDINATE</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>FSR DATA divided mass</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>...</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>...</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>...</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>...</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FORCE  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \\\n",
       "cluster                                                                      \n",
       "0         2666        2666        2666        2666        2666        2666   \n",
       "1         1143        1143        1143        1143        1143        1143   \n",
       "2          327         327         327         327         327         327   \n",
       "3          872         872         872         872         872         872   \n",
       "\n",
       "         X COORDINATE  Unnamed: 8  Unnamed: 9  Unnamed: 10  ...  Unnamed: 29  \\\n",
       "cluster                                                     ...                \n",
       "0                2666        2666        2666         2666  ...         2666   \n",
       "1                1143        1143        1143         1143  ...         1143   \n",
       "2                 327         327         327          327  ...          327   \n",
       "3                 872         872         872          872  ...          872   \n",
       "\n",
       "         Unnamed: 30  Unnamed: 31  Unnamed: 32  FSR DATA divided mass  \\\n",
       "cluster                                                                 \n",
       "0               2666         2666         2666                   2666   \n",
       "1               1143         1143         1143                   1143   \n",
       "2                327          327          327                    327   \n",
       "3                872          872          872                    872   \n",
       "\n",
       "         Unnamed: 34  Unnamed: 35  Unnamed: 36  Unnamed: 37  Unnamed: 38  \n",
       "cluster                                                                   \n",
       "0               2666         2666         2666         2666         2666  \n",
       "1               1143         1143         1143         1143         1143  \n",
       "2                327          327          327          327          327  \n",
       "3                872          872          872          872          872  \n",
       "\n",
       "[4 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.groupby('cluster').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA92UlEQVR4nO3dfXhU9Z3//9ckk2QCyQzhLiQQkRpKKwFLwWoQrZYtLlS3sPSq7Xq5Wi1fU8VvNVUQcdfq6gZ1f116p61d18ryrXp1A8guriutEBRju4ugEZGVLYrGpECKmdzOTGbO749kxplkbs5MZjLJ8fm4rrk057zP5+6cz5x3Duec2AzDMAQAAGAROdluAAAAQDqR3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBS7NluwEgLBAL68MMPVVxcLJvNlu3mAAAAEwzDUEdHh8rLy5WTE//azCcuufnwww9VUVGR7WYAAIAUvP/++5oxY0bcmE9cclNcXCypf3CcTmeWWwMAAMxwu92qqKgIncfj+cQlN8F/inI6nSQ3AACMMWZuKeGGYgAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApWX1D8aOPPqpHH31U7777riRp7ty5+tu//VstX7485jYNDQ2qra3V4cOHVV5ernXr1qmmpmaEWmzOqTPdCgQMeSV1ev1y9/jkKsxTkcOuGSXjIuIUMGRI8piM7U0QFx4rKWH8KXev5PMnjA2P6xv4hMcWO+yaPhDb3u2Vt8cnvyRfvDJN9qnlTLf6AkZEjLMwT+UTCkN1xW37wPax2pyojGA7E/V7OML3WbhEY5iJOs0cj6mWncn+ANkW67iXhj+v4pUtJf6uT0cf0lXHSMhqcjNjxgxt2rRJlZWVkqQnn3xSX/3qV3Xw4EHNnTt3SPzx48e1YsUKrVmzRlu3btX+/ft10003acqUKVq9evVINz+qU21d8hmSV9LGHU3af6wttG5J5SQ9sGqeZk4ar1NtXZLRf7L0mIgNGFJPgrhg/TL6TyK9JtsgSV0xYutWzZNDCsV51N/maLF/v2qeCnNzpL6AvOo/iUWLe3jVvP4Dz4hdb7CNH7R1qc8wtHHHmxExSz8zRZuunBt3XP5x1bz+NhvR2xwswzCk7ijrb1g8UzUXzZKM+P0OH/9UhO+HIEP94xdrDDNRp2TueEy17HjHxHD7A2RbrONeGv68ild2QObODcPpQzrrGCk2wzBip4JZMHHiRD388MO64YYbhqxbv369du7cqSNHjoSW1dTU6PXXX1djY6Op8t1ut1wul9rb29P+t6U+ONMtYyDjvXN75EEQtKRykjatnh+KSyY2UZxNUiCFcuPFPv1/LtB0V2HoZ1/A0N88+2bU2LpVVVpSOVlS/2S4K0aZL91xqek2dvT6dP+uI0Ni1n6pUlctnBG3jGA9sdqcqIx9d1yq4F8widfvJZWT9ODq+SldwQk/ZgaLN4bB8Unlt6bmgSuLsSTaJ/HqzEZ/gGyLd9wHpTqvMll2MvWko47hSub8PWr+cKbf79evf/1rdXV1qbq6OmpMY2Ojli1bFrHs8ssv1+OPPy6fz6e8vLwh23g8Hnk8ntDPbrc7vQ0P09HbF/r/aAeBJL18rC0iLpnYZMpMVxvGF9jV6fWbip3qdETExoozExNsoyFb1JgFFRNC5aRaT6Iyukz2++VjbXL39ml61LXxRdtvZutMtG0s7gzWmY3+ANlm5thN9djPZNnJ1DPW5m7Wk5umpiZVV1ert7dXRUVF2r59u84999yosa2trSotLY1YVlpaqr6+Pp0+fVplZWVDtqmrq9O9996bkbYP5u7xpTUumdiOXp+SuQZnttzOXr9ybP7EgZI8fQFT5aZjnMzUlWh9ojKS2U8dveZjU61jLNSZjf4A2Tac416Kf+xnsux01TMa527Wk5s5c+bo0KFD+uijj1RfX69rr71WDQ0NMROcwX/qPPivarH+BPqGDRtUW1sb+tntdquioiJNrY/kLBx65Wg4ccnEFjvMl5lMuUWOXNlzzD1UV2DPMVVuMuMUK18zU1ei9YnKSGY/JTv+qdQxFurMRn+AbBvOcS/FP/YzWXa66hmNczfrj4Ln5+ersrJSixYtUl1dnc477zz98Ic/jBo7bdo0tba2Riw7efKk7Ha7Jk2aFHWbgoICOZ3OiE+mFDvsKsrPVVF+rpZURm/PkspJEXHJxCaKc6ZYbrzYLk9fRFyBPSdm7El3byhuXJwyk2mjTUbUmIPvf5SwjERtTlTGeJP9XlI5SU5Har8nDN4P4Z94Yxgcn1QMPk4Gf4ZTZzb6A2RbvON+uPMqk2UnU89Ym7tZT24GMwwj4h6ZcNXV1dq9e3fEshdeeEGLFi2Ker/NSJtRMk4OSbmGdP/KeUMOhuCd5cE4hyHZTcbmm4ibHlZuXhJtcMSJne4qjIjLt9lixl5UOVmO3JyE/bJLoTITtbE43677V1YNiTnyYXvCcXEM1BOrzcEyCmKU8eT+46F2xuv3A6vmpfw4+OD9EPwUmDw2UjE9Rp1mj8dU+pOOsoHRKt5xP9xjP1HZZs4Nw+1DuuoYSVl9Wuquu+7S8uXLVVFRoY6ODj399NPatGmTnn/+eX35y1/Whg0b1NzcrC1btkjqfxS8qqpKN954o9asWaPGxkbV1NToqaeeMv0oeCaflgoa/J6bjl6fih3970RJ9J6bRLG9CeLCYyUljI/2nptosbHecxOMdSZ4z03UMk32Kfw9N8EYV4z33MSqJ/w9N4PbnKiMaO+5idbv4TDzXph4+zyddZo5HlMtO5P9AbLN7HtuUjn2zb7nZrjzysx7brI1d5M5f2c1ubnhhhv029/+Vi0tLXK5XJo/f77Wr1+vL3/5y5Kk6667Tu+++6727t0b2qahoUG33XZb6CV+69evT+olfiOR3AAAgPQaM8lNNpDcAAAw9iRz/h5199wAAAAMB8kNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSSG4AAIClZDW5qaur0/nnn6/i4mJNnTpVK1eu1NGjR+Nus3fvXtlstiGft99+e4RaDQAARrOsJjcNDQ26+eab9eqrr2r37t3q6+vTsmXL1NXVlXDbo0ePqqWlJfSZPXv2CLQYAACMdvZsVv78889H/PzEE09o6tSpOnDggC655JK4206dOlUTJkzIYOsAAMBYNKruuWlvb5ckTZw4MWHsggULVFZWpqVLl2rPnj0x4zwej9xud8QHAABY16hJbgzDUG1trZYsWaKqqqqYcWVlZXrsscdUX1+vbdu2ac6cOVq6dKn27dsXNb6urk4ulyv0qaioyFQXAADAKGAzDMPIdiMk6eabb9auXbv08ssva8aMGUlte+WVV8pms2nnzp1D1nk8Hnk8ntDPbrdbFRUVam9vl9PpHHa7AQBA5rndbrlcLlPn71Fx5eaWW27Rzp07tWfPnqQTG0m68MIL9c4770RdV1BQIKfTGfEBAADWldUbig3D0C233KLt27dr7969mjVrVkrlHDx4UGVlZWluHQAAGIuymtzcfPPN+tWvfqVnn31WxcXFam1tlSS5XC4VFhZKkjZs2KDm5mZt2bJFkrR582adffbZmjt3rrxer7Zu3ar6+nrV19dnrR8AAGD0yGpy8+ijj0qSLr300ojlTzzxhK677jpJUktLi06cOBFa5/V6dfvtt6u5uVmFhYWaO3eudu3apRUrVoxUswEAwCg2am4oHinJ3JAEAABGhzF3QzEAAEC6kNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFiKPZuV19XVadu2bXr77bdVWFioxYsX68EHH9ScOXPibtfQ0KDa2lodPnxY5eXlWrdunWpqakao1ZCk9m6vTnd65e71yVmYp8nj8+Ual5+28k+5eyWfXx5J3oChHq9f3V6/nIV5muYsSFtdJ890yxMw1On1y93jk6swT0UOu2aUjIsan0q/T53plgJGzPWZ7mOmDe7fWO8PkEi0Od0rmf4eGQ2i9SEgyaux1Y9YsprcNDQ06Oabb9b555+vvr4+bdy4UcuWLdNbb72l8ePHR93m+PHjWrFihdasWaOtW7dq//79uummmzRlyhStXr16hHvwyfThRz1aX/+GXnrndGjZJbMna9Pq+SqfUDjs8k+1dUmG1C3pw/Ye/WTPMe0/1hZaf/HsyXowDXV92NYlryFt3NEUUf6Sykl6YNU8zZwUeQym0u9gX2LJdB8zbXD/xnp/gESizekumf8eGQ2i9cGn/sRmLPUjHpthGHG+ekfWqVOnNHXqVDU0NOiSSy6JGrN+/Xrt3LlTR44cCS2rqanR66+/rsbGxoR1uN1uuVwutbe3y+l0pq3tnxTt3V6tfepgxAk+6JLZk/Xjby4Y1m/of3T3yuvzS5JeOnZau5paIiZa0MWzJ+snw6ir+Uy3+gKG7treFLX8JZWTtGn1/NBvLKn0+4Mz3TLiXLGRMtvHTIvWv7HcHyCRWHP6TpPfI6NBvO+l0d6PZM7fWb1yM1h7e7skaeLEiTFjGhsbtWzZsohll19+uR5//HH5fD7l5eVFrPN4PPJ4PKGf3W53Glv8yXO60xv1BC9J+945rdOd3mGdvM50eUO/UJQ6HVEnmiS9NMy63L19khSz/JePtaljIEZKrd/h28eSyT5mWrT+jeX+AInEmtNmv0dGg3jtGUv9SGTUJDeGYai2tlZLlixRVVVVzLjW1laVlpZGLCstLVVfX59Onz6tsrKyiHV1dXW69957M9LmTyJ3ry/u+o4E6xOX36fgxURPXyBjdbl7Em8bXn4q/TZTRyb7mGnR+jeW+wMkYmZODzbajvlU+iCNvn4kMmqSm7Vr1+qNN97Qyy+/nDDWZrNF/Bw8GQ5eLkkbNmxQbW1t6Ge3262KiophtvaTy+nIi7u+OMH6xOXbQ1duOj3xf1MYTl3OwsTbhpefSr/N1JHJPmZatP6N5f4AiZiZ04ONtmM+lT5Io68fiYyKR8FvueUW7dy5U3v27NGMGTPixk6bNk2tra0Ry06ePCm73a5JkyYNiS8oKJDT6Yz4IHWTi/J1yezJUdddMnuyJhcN758cSsbnqyg/V0X5uTrp7tVFlUP3qdR//8Zw6nI67BqXn6slMcpfUjlJxY6Pc/9U+l3ssIf6EuuTyT5mWrT+jeX+AInEmtNmv0dGg3jfS2OpH4lkNbkxDENr167Vtm3b9OKLL2rWrFkJt6murtbu3bsjlr3wwgtatGjRkPttkH6ucfnatHr+kBP9JQNPwwz3fopSp0MOSQ5DWnzOZK29rHLIyfLi2ZP10DDrml4yTnmS7l85b8iEDj4dEH7zXCr9nlEyLtSXWJ9M9jHTovVvLPcHSCTWnDb7PTIaxOpD7hjrRyJZfVrqpptu0q9+9Ss9++yzEe+2cblcKizsf2R0w4YNam5u1pYtWyT1PwpeVVWlG2+8UWvWrFFjY6Nqamr01FNPmXoUnKel0iP4vpeOXp+KHXmaXJTh99z4/Or2+OUstGua05GR99wE+1Js4j03yfTb9HtuMtTHTIv5npsx2h8gkXjvuTHzPTIaJHrPzWjsRzLn76wmN9HukZGkJ554Qtddd50k6brrrtO7776rvXv3htY3NDTotttuC73Eb/369aZf4kdyAwDA2DNmkptsILkBAGDsSeb8PSpuKAYAAEgXkhsAAGApJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSkk5uDMPQe++9p56enky0BwAAYFhSSm5mz56tDz74IBPtAQAAGJakk5ucnBzNnj1bbW1tmWgPAADAsKR0z81DDz2kO+64Q2+++Wa62wMAADAsNsMwjGQ3KikpUXd3t/r6+pSfn6/CwsKI9X/605/S1sB0c7vdcrlcam9vl9PpzHZzAACACcmcv+2pVLB58+ZUNgMAAMi4lJKba6+9Nt3tAAAASIuU33Pzv//7v7r77rv1zW9+UydPnpQkPf/88zp8+HDaGgcAAJCslJKbhoYGzZs3T7/73e+0bds2dXZ2SpLeeOMN3XPPPWltIAAAQDJSSm7uvPNO3X///dq9e7fy8/NDyy+77DI1NjamrXEAAADJSim5aWpq0qpVq4YsnzJlCu+/AQAAWZVScjNhwgS1tLQMWX7w4EFNnz592I0CAABIVUrJzV/91V9p/fr1am1tlc1mUyAQ0P79+3X77bfrr//6r9PdRgAAANNSSm4eeOABnXXWWZo+fbo6Ozt17rnn6pJLLtHixYt19913p7uNAAAApqX0huKgP/zhD3rttdcUCAS0YMECzZ49O51tywjeUAwAwNiTzPk7pSs39913n7q7u/WpT31KX/va1/T1r39ds2fPVk9Pj+67776UGg0AAJAOKV25yc3NVUtLi6ZOnRqxvK2tTVOnTpXf709bA9ONKzcAAIw9Gb9yYxiGbDbbkOWvv/66Jk6cmEqRAAAAaZFUclNSUqKJEyfKZrPp05/+tCZOnBj6uFwuffnLX9bXv/510+Xt27dPV155pcrLy2Wz2bRjx4648Xv37pXNZhvyefvtt5PpBgAAsLCk/nDm5s2bZRiGrr/+et17771yuVyhdfn5+Tr77LNVXV1turyuri6dd955+ta3vqXVq1eb3u7o0aMRl6SmTJlielsAAGBtSSU3wb8GPmvWLF100UWy21P6o+Ihy5cv1/Lly5PeburUqZowYcKw6gYAANaU0j03xcXFOnLkSOjnZ599VitXrtRdd90lr9ebtsbFsmDBApWVlWnp0qXas2dP3FiPxyO32x3xAQAA1pVScnPjjTfqf/7nfyT1v+vmqquu0rhx4/TrX/9a69atS2sDw5WVlemxxx5TfX29tm3bpjlz5mjp0qXat29fzG3q6urkcrlCn4qKioy1DwAAZF9Kj4K7XC699tprOuecc/Tggw/qxRdf1H/+539q//79+sY3vqH3338/+YbYbNq+fbtWrlyZ1HZXXnmlbDabdu7cGXW9x+ORx+MJ/ex2u1VRUcGj4AAAjCEj8ih4IBCQJP3mN7/RihUrJEkVFRU6ffp0KkWm7MILL9Q777wTc31BQYGcTmfEBwAAWFdKyc2iRYt0//3361/+5V/U0NCgr3zlK5Kk48ePq7S0NK0NTOTgwYMqKysb0ToBAMDoldLjTps3b9bVV1+tHTt2aOPGjaqsrJQk/eu//qsWL15supzOzk4dO3Ys9PPx48d16NAhTZw4UWeddZY2bNig5uZmbdmyJVTv2Wefrblz58rr9Wrr1q2qr69XfX19Kt0AAAAWlFJyM3/+fDU1NQ1Z/vDDDys3N9d0Of/93/+tyy67LPRzbW2tpP5Hzn/5y1+qpaVFJ06cCK33er26/fbb1dzcrMLCQs2dO1e7du0K/bMYAADAsP4q+FjE35YCAGDsSeb8ndKVm5ycnKh/WypoNP/hTAAAYG0pJTfbt2+P+Nnn8+ngwYN68sknde+996alYQAAAKlI6z9L/epXv9IzzzyjZ599Nl1Fph3/LAUAwNiT8ffcxHLBBRfoN7/5TTqLBAAASErakpuenh79+Mc/1owZM9JVJAAAQNJSuuempKQk4oZiwzDU0dGhcePGaevWrWlrHAAAQLJSSm7+8R//MSK5ycnJ0ZQpU3TBBReopKQkbY0DAABIVkrJzXXXXZfmZgAAAKSH6eTmjTfeMF3o/PnzU2oMAADAcJlObj73uc/JZrMp0ZPjNpuNl/gBAICsMZ3cHD9+PJPtAAAASAvTyc3MmTND/19XV6fS0lJdf/31ETH//M//rFOnTmn9+vXpayEAAEASUnrPzc9//nN95jOfGbJ87ty5+tnPfjbsRgEAAKQqpeSmtbVVZWVlQ5ZPmTJFLS0tw24UAABAqlJKbioqKrR///4hy/fv36/y8vJhNwoAACBVKb3n5tvf/rZuvfVW+Xw+felLX5Ik/fa3v9W6dev0ve99L60NBAAASEZKyc26dev0pz/9STfddJO8Xq8kyeFwaP369dqwYUNaGwgAAJAMm5HoxTVxdHZ26siRIyosLNTs2bNVUFCQzrZlRDJ/Mh0AAIwOyZy/U7pyE1RUVKTzzz9/OEUAAACkVUo3FAMAAIxWJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBS7NmsfN++fXr44Yd14MABtbS0aPv27Vq5cmXcbRoaGlRbW6vDhw+rvLxc69atU01Nzcg0eASdOtMtBQxJUq+kTq9f7h6fXIV5KnLYNaNkXNR4M7HBeF/AkH9QvLMwT+UTClMu0xsw1Cep2+tXR49PzsI8lYzPV6nTkfbx6RuoK7xtxQ67pg+0rXWgj7HWnzrTrd5B62P1LVTvRz2SP2C6nV5pZMbD3Sv5/KZifVLc/R5RbthxGM2I9W9g3BPVF629Zo7fD850q6O3TwG/T1MLHfKrf5ySOTZS6lcKx2C49m6v3D2+jLczXPOZbrl7+6LOqWTadMrdK4/PL2/AUI/Xr26vX87CPE1zFsg1Lj8U1zLwvRLvGAvuPzP7OFZMy8B3SqfXr16vTzOKoh/DycyfRBLNr1TqM1OmR0o47qm02ey5YiRkNbnp6urSeeedp29961tavXp1wvjjx49rxYoVWrNmjbZu3ar9+/frpptu0pQpU0xtP1acauuSjP4DulfSxh1N2n+sLbR+SeUkPbBqnmZOGh8R32UiNhjfa0h+Gdq4480h8Q+vmie7JMOQupMos8eQvIGA7tl5eEj836+ap7PC4oc7Ph6j/yQXrW3/uGqevJJ8RvT1P1g1TwFJvTHWD+5beL2K/50RoUcjNx5m29Wr2Ps92j6NV+5I9y9efQ+tmqc8KaK9hswdv++1demu7U3y9fn10699Tl6j/4SSzLGRij8OzJlU6zn1UY+6+gIZb2e44FjFqs9sm061danbkD5s79FP9hyLiL149mQ9uHq+yicU6v22Lnn88Y+xRG0y0+4P2rrUZ/TPixNt3aq/4QtRj/1k5k8iZuZtsvWZKbNbicc92TabnWsjyWYYRhJf15ljs9kSXrlZv369du7cqSNHjoSW1dTU6PXXX1djY6Opetxut1wul9rb2+V0Oofb7LT74Ey3jLCs+M5BEzJoSeUkbVo9XzZJgYH4RLEzSsaFyu/09un+XUeixr90x6Wm6w8vs7m9Rz9+8VjM+P/v658b9m/0wbp8AUN/8+ybMdufaL3ZvgV9+FGP/ElcsZE0IuPxR3evvCav2EiKu9+XVE7SQ187T+UTCocch9GMRP/Cxz1efS9+74vKy7ENWZ5oH0vS+vo3tP9Ym/bdcWn/fJKGnAgHbzfc30aD45vMMRiuvdurj3p8GW9nuOYz3Vo3MFax6jPTp7zcHHl9fr107LR2NbVEjb149mTV/eU8fXCmO+4xtmn1/ND+i7VeUsKYjl5faF7sXHuRSgrzoo6B2fmTiJn5lWx9ZstMNO4/+eaCqFdwEpWf6rGcjGTO31m9cpOsxsZGLVu2LGLZ5Zdfrscff1w+n095eUMPSI/HI4/HE/rZ7XZnvJ3D0dHbF/FztINFkl4+1pZSbPC/hmwx4zu9H58skylzfIE9bvyZLu+wT3bhfU7U/lTXRxvb9h5f0m0difE40+VN5mJS3P3+8rE2tff4VD6hcEj/oxmJ/oWPe7z6PH0BeaIsN7OPgzFdSR73wzG47mTrOd3pldcfyHg7w7l7+5Iaz1gxNvX/pl/qdMSMfemd0+ro7Ut4jHWkqU3h88KemxPxHRjO7PxJxOy+SaY+s2UmGvfTnd6oyU2i8kfyWDRjTCU3ra2tKi0tjVhWWlqqvr4+nT59WmVlZUO2qaur07333jtSTRw2dxIn0Y5en8xed+vo9Zku32wbBpeZ6JcGdxoO8HS030wZwb4ls81gIzIevX1K58XXZI6Tkd7f8epLZf8Mnj/JHvfDkcoxGLF9r0/evvhXEtPRzog60zavbDIMQ54E7Xf3+BIfYwnqNPMdObiMjhSOpfD6zEjleE1Un9kyE417rD4Mp83pPhbNGFPJjdT/z1fhgl/sg5cHbdiwQbW1taGf3W63KioqMtfAYXLGuBwaTbEj+dhg+fHmu9k2DC6zLxB/0jgdwz/czLQtUYyZMgaPbTL7JWhExsNhT/LKTXyD92k8I72/49WXyv5JdR8nM+9iSeUYjNjekSdvgn8mTUc7I+pM07wKXrnp9MRPfp2FeYmPsQR1mhkDZ2FexLwoLuxvYzRm54+ZOs1Ipj6zZSYa91h9SGWOJSozk8bUo+DTpk1Ta2trxLKTJ0/Kbrdr0qRJUbcpKCiQ0+mM+IxmxQ67ivJzQ58lldH7taRykooddjnD4hPFhpdvkxEzPpn6w8vs8vTFjS8Zn/hO/ESCdRXYc+K2P9F6s30LchXmRYyLmc9IjEfJ+Pyk2hRvvy+pnCTXwBfY4OMwW/0LH/d49RXYc6K2MdE+LnbYQzHjB7YZl+SxkYrg+KZaz+Si/BFpZzhn2FjFqs9Mn4LH7El3ry6KEXvx7MkqdtgTHmPFJtpkJiZ8XvT5A8OeP4mYmV/J1me2zETjPrko+rxNVP5IHotmjKnkprq6Wrt3745Y9sILL2jRokVR77cZi2aUjJNDksOQ8gzp/pXzhhw0wTvQZ5SM0/Sw+ESx4eUX5dl1/8qqqPF2SQ5JBUmWWe4s1Pf/Ym7U+L9fNS8tjwcH68q32WK2zSGpICf2+gJJeTLXt6DyCYWhcTb7GYnxKHU6kmpXvP3+wKp5oX+/Dz8Os9m/8HGPV58jxzakvWaO3xkl4/TAqv6Y2399SA5Dsps87odjRsk45Sv1elzj8jUuNyfj7Qw3PWysYtXnMNGm4DG7+JzJWntZ5ZAT7cWzJ+uhgRtQp7viH2MzTLTJTExx/sfz4ub/95oKDGNY8ycRM/Mr2frMlplo3GM9Dh6vfLPnipGU1aelOjs7dezYMUnSggUL9IMf/ECXXXaZJk6cqLPOOksbNmxQc3OztmzZIqn/UfCqqirdeOONWrNmjRobG1VTU6OnnnrK9KPgo/1pqaBo77np6PWp2NH/XolE77mJFxuMD3/PTTDeFec9N2bKjHjPzUD8xBF4z02wLmeM99xEWx/+jpFEfQvVO5z33GRyPFJ8z020/R5RbjLvuclk/6K95yZKffHecxNvHwffgWIEfJriiHzPjdljI6V+pXAMhgt/p0wm2xku+J6baHMqmTZFvOfG51e3xy9noV3TnI7Y77mJcYwF95+ZfRwrJvw9Nx6fT9PHJ37PTaL5k0iy77kxU19S77mJM+6ptNnsuSJVyZy/s5rc7N27V5dddtmQ5ddee61++ctf6rrrrtO7776rvXv3htY1NDTotttuC73Eb/369Um9xG+sJDcAAOBjYya5yQaSGwAAxp5kzt9j6p4bAACAREhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsJevJzSOPPKJZs2bJ4XBo4cKFeumll2LG7t27Vzabbcjn7bffHsEWAwCA0Syryc0zzzyjW2+9VRs3btTBgwd18cUXa/ny5Tpx4kTc7Y4ePaqWlpbQZ/bs2SPUYgAAMNplNbn5wQ9+oBtuuEHf/va39dnPflabN29WRUWFHn300bjbTZ06VdOmTQt9cnNzR6jFAABgtMtacuP1enXgwAEtW7YsYvmyZcv0yiuvxN12wYIFKisr09KlS7Vnz564sR6PR263O+IDAACsK2vJzenTp+X3+1VaWhqxvLS0VK2trVG3KSsr02OPPab6+npt27ZNc+bM0dKlS7Vv376Y9dTV1cnlcoU+FRUVae0HAAAYXezZboDNZov42TCMIcuC5syZozlz5oR+rq6u1vvvv69/+Id/0CWXXBJ1mw0bNqi2tjb0s9vtJsEBAMDCsnblZvLkycrNzR1ylebkyZNDrubEc+GFF+qdd96Jub6goEBOpzPiAwAArCtryU1+fr4WLlyo3bt3RyzfvXu3Fi9ebLqcgwcPqqysLN3NAwAAY1RW/1mqtrZW11xzjRYtWqTq6mo99thjOnHihGpqaiT1/5NSc3OztmzZIknavHmzzj77bM2dO1der1dbt25VfX296uvrs9kNAAAwimQ1ubnqqqvU1tam++67Ty0tLaqqqtJzzz2nmTNnSpJaWloi3nnj9Xp1++23q7m5WYWFhZo7d6527dqlFStWZKsLAABglLEZhmFkuxEjye12y+Vyqb29nftvAAAYI5I5f2f9zy8AAACkE8kNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApZDcAAAASyG5AQAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZCcgMAACyF5AYAAFgKyQ0AALAUkhsAAGApJDcAAMBSSG4AAICl2LPdgEceeUQPP/ywWlpaNHfuXG3evFkXX3xxzPiGhgbV1tbq8OHDKi8v17p161RTUzOCLY7u1JluKWAoIMkryRPwy5WTGzPeJ8kvqdPrl9fnU/l4R2hd38Cn0+tXr9en6UUOeSR19/lVkpMjW44toixDkmcgXgGfihyOqOUGeYN1BPzKz8lVp9cvd49P5cV5ctjtUsCQf6CNXT6/CnOlnLC4KcV5Kh6IC+odqN9m+DS+oL/+gN+nqYVD69dA330D29hzfJpgj4wLlufu8am0OE/jw+oLrgv4fXIWOqKOS68kX8CvvIF22wyfJhV8XEdwDHwBvwpyctXl86soVyoYtM/C29nr9WlykSPULldhnpyFeSqfUBi1j+nQ3u2Vt8eXMC58vFyFeSpy2DWjZFzM+FNnutUbMGJuc+pMtzwBQ96AoR6vX91ev5yFeZrmLJBrXP6w+hScK8kI9i9HPk3Mj35Mhc+DYJ+KHXYVFdjjjmGfPv4iDO5vb8AvZ5z5mw7BFuUNowxDki1hVPqYqc8vyczI9UoyAn4VxhlnM/V5JOUFDOXkxI70Sop31Hok5QQM5Q36DklmTpkRfuwnU/7JgfkYL/6Uu1cenz8jcza8jl6fP+Z3YLT1xQ67pg9z3FKR1eTmmWee0a233qpHHnlEF110kX7+859r+fLleuutt3TWWWcNiT9+/LhWrFihNWvWaOvWrdq/f79uuukmTZkyRatXr85CD/qdauuSjIEvRUn/9NL/6rsXn9M/M6PoleSXoY073tQpt0f/768XhWI96v+y3bijSSfauvXMDV9QtyE9+PwRbbx8jmw2W0S5fQPbbNzRpBwZ+ruV83Xn9qYh5Qb1SPIGAvrVq+/prxfP0p3bm7T/WJu+sahc37v005LfkFf9fbnv3w/r/146S46icaG4L5w9QT/92uck/8cFdw3UX2i36e4rqnTn9ib5+vz9cVHGIFj+xh1NqphQ0F/vQFxgoI0bd/TX92efmay6K6pC9QXr8vX59dDXPqe//4+h49Il6anfvadvXjBTd27vb1fdFVWh9cEx+OX+4/r2xefonn87rNuXzlKBfVxEe8PbeaKtW1tu+EJoHIKWVE7SA6vmaeak8dF39jCc+qhH6gvEjRk8Xmba1drWpV4j+jYPrpqnfEndhvRhe49+sudYRMzFsyfrwdXzU07ognPFLL/658vGHU2a4MjV9//83Kjbh8+DYHvH5edqx02LlO+P3VaPpIKB/w/u7y2vHNd3Fs9Kqp3J6pUkGepP05JPTwz1j81IfoGHJ4HRGOofv0Sn0eAx+8LhZq2aOz3mOPep/58W4o1OtyRPX49K7IUxy+mRlGcEJFv0f6joltTt6dHkgv4yUplTZoQf+8HvMTPlt7R1yRNjvgbjT7V1ZWzOBjW3dcln9J+3BrejbtU85UryJmjnSLIZhpHBKRzfBRdcoM9//vN69NFHQ8s++9nPauXKlaqrqxsSv379eu3cuVNHjhwJLaupqdHrr7+uxsZGU3W63W65XC61t7fL6XQOuw8fnOmWEfZb6J3bm/TAyirl2mJPyU5vn+7fdUT7j7Vpd+0lcuR+POl8AUN/82z/wbNz7UUqKczTndubdP1Fs/TpqUVRywuecF+649LQ/w8uN6i5vUc/fvGY6lbN04awE/VLd1waiglIumt7kxacVaKrFs6IOKHvu+PSIV820eqPFje4/OA2sfozuF3h6/bdcak2xBiXO7c3adOqeRHtijYGD6ys0sYdb4b6Ga+dO9depAeffzti0gYtqZykh752Xlqv4LR3e+U2ccVG0pCEK7xdm1bPj/jtLni8xtrmxe99UXk5Nr107LR2NbVEjbl49mT95JsLkv5tcPBcMSvWfowVF7T2S5VR92s4X9hv68H9XbdqXsavhnR6+yRJRflZv3ieVgGZu9chOEeH66Vjp3Vx5eS4Mc3tPZruij03o5WRzJwyo/lMtwKDzhNmyk80X4PxRsDIyJwN+qO7V3/q8oTOW4M9/X8u0NRiR+jcFa2dD66eP+wrOMmcv7M2s7xerw4cOKA777wzYvmyZcv0yiuvRN2msbFRy5Yti1h2+eWX6/HHH5fP51Ne3tALvB6PRx6PJ/Sz2+1OQ+s/1tHbF/Hz/mNt6vHF/23bkC10APT5DXX6/UPKkCR7bo46vX7tP9amO5d/pv+fnaIIxgdjY5UrSeML7Np/rE1dYbHBbQeXef1FsyLKlKSuKG2IVn+0uFjbxFoXq13B8mONy/5jbRFtGbw+OAY9vkBEP+O1056bE3XSStLLx9rU3uNLa3JzutMrrz/+cTS4jdHaNfj4DP4caxtPX0AeSaVOR8yYl945rdOd3qS/KAe3xax4x0q0uKAFFRMSbiP1X70JLyPRsZsOxkD6ZKZ9VhSco8NV6nQkLGd8gT1uTLQykplTZrijnCfMlJ9ovobHZ2LOBp3p8kactwYbX2CXpy8Qt53u3j5NT6n21GQtuTl9+rT8fr9KS0sjlpeWlqq1tTXqNq2trVHj+/r6dPr0aZWVlQ3Zpq6uTvfee2/6Gj5ItN+uzf7GnSi2I2xdZ69fObb4kzi8rFjlBn95GLw+WrynL2AqLpn6422TzPrg8ljjEq8tg8cgWj8H60i0vtf8PjfD3euTN8E/SZkxuF1mx9uToO5U+pvMvEjH9mb2azrqQWrSMc5m9nHAUNzvzmSPk0wf++Hlm9kuk3M2VEdvn+L9I4+Z81O6vyMTyfo1Udugf74xDGPIskTx0ZYHbdiwQbW1taGf3W63KioqUm3uEM7CoVeLoi0LF36IxIstLswLXR4vcuTKnhP/gm94WbHK7QsEoq6PFl9gzzEVl0z98bZJZn1weaxxideWwWMQrZ+DFSda7xjObaFDOR15pq/cxDO4XWbHu9MT/7fTVPpr9phI1/Zm9ms66klF8DtgJG8GHm3SMc6dnr6E5fQFAnG/O82UES7Tx354+Wa2y+ScDdXhsCvet5GZ81O6vyMTyVpyM3nyZOXm5g65SnPy5MkhV2eCpk2bFjXebrdr0qRJUbcpKChQQUFB1HXpUOywR9xHsKRykgrzchLec7OkcpJePtYme65tyD03wXV9/oBKCvO0pHKSTro9Me+5CcYX5efGLDeoud2rJZWTND4sVpKK8j9+YiEwUObB9z/Sp6cWRcSNz88d8oUcrf5ocYPLD24Tqz+D2xW+Ltj+aOOypHJSRFsGlxEcg8K8nIh+xmtnnz8Q0a7B9bnSfEKcXJRv+re9eO0qdkRO8eDxGmubAnuO8nJsOunu1UWVk2L++/3kouQvbw+eK2bFO1aixQXF2q/hBt9zE5wb3HOTGrP33ATn6HCddPcm3MfN7d6499xEKyOZOWWG02GPuOfGbPmJ5msw3ggYGZmzQSXj8/WnLk/MdnR5+jS12BG3nc4Uxm04sn5D8cKFC/XII4+Elp177rn66le/GvOG4n/7t3/TW2+9FVr2ne98R4cOHcraDcXS0KelHn/pf/V/Lz4nZnzwaam7d7ypk8GnmgYEn5a6e0eT3ht4Wsormx56/ojuunyOCgbd8R98SuTuHU2yDTwtdfeOpiHlBgWfFHrq1fd0zeJZuntHk14Of1pKHz818nf/fli3XDpLE4rGheJCT0uF6Rqo3zHwtNTdO5rkDT4tFUWw/Lt3NGlG8GmpAcEnFYL1hZ6WGlSXd+BpqWjj0iXp6d+9p29cMDPUrvAygmPw5P7juuHic/R3/35Y31s6S1MKI292C2/newNPS/3NjjcjJu9oeVoqOF5m2hV8WiraNmaelnpo9XyVjfDTUnfvaJIr+LRUFOHzINin4NNSJfbknpb6l1eOq2bxLPONTAFPS0m7Dzdr5dzYd2EEn5aKlyxFPC0VQ/BpKbuZp6WU2pwyY/DTUmbLDz4tFS8+0dNSw5mzQcGnpe6O8h0Y/rRUusctXDLn76wmN88884yuueYa/exnP1N1dbUee+wx/eIXv9Dhw4c1c+ZMbdiwQc3NzdqyZYuk/kfBq6qqdOONN2rNmjVqbGxUTU2NnnrqKdOPgmciuZGG954bX59PZeOiv+fGM/CuGtPvuTF8Khp4z8zgcoOiveemo9enaUV5KkzwnpuOXp8mFeXJGes9N/JpfH5//UbApykOE++5yfVpQm7099x09Po0pShPRVHec2MEfCp2mHzPjXyalD+899x4fD5NGu8ItavYkSfXKHvPTbBdxUm85ybaNhHvufH51e3xy1lo1zSnI7vvubH5NDEv8Xtugn1y8p6btPokvufG7JwyI9p7bsyUH/6em1jxEe+5SfOcDa8j+B6baN+B0dY70/iemzHxtJQkXXXVVWpra9N9992nlpYWVVVV6bnnntPMmTMlSS0tLTpx4kQoftasWXruued022236ac//anKy8v1ox/9KKvvuAmakoWXFMH6XOPypTR9MYVLdLxm8njOylzJwBgCyUr12J9qYrspzuhJfzolqmMk2mBWVq/cZEOmrtwAAIDMSeb8zd+WAgAAlkJyAwAALIXkBgAAWArJDQAAsBSSGwAAYCkkNwAAwFJIbgAAgKWQ3AAAAEshuQEAAJZirT9Ja0LwhcxutzvLLQEAAGYFz9tm/rDCJy656ejokCRVVFRkuSUAACBZHR0dcrlccWM+cX9bKhAI6MMPP1RxcbFstvT+PV23262Kigq9//77/N2qDGKcRwbjPDIY55HBOI+MTI6zYRjq6OhQeXm5cnLi31Xzibtyk5OToxkzZmS0DqfTyeQZAYzzyGCcRwbjPDIY55GRqXFOdMUmiBuKAQCApZDcAAAASyG5SaOCggLdc889KigoyHZTLI1xHhmM88hgnEcG4zwyRss4f+JuKAYAANbGlRsAAGApJDcAAMBSSG4AAIClkNwAAABLIblJk0ceeUSzZs2Sw+HQwoUL9dJLL2W7SaPavn37dOWVV6q8vFw2m007duyIWG8Yhr7//e+rvLxchYWFuvTSS3X48OGIGI/Ho1tuuUWTJ0/W+PHj9Rd/8Rf64IMPImLOnDmja665Ri6XSy6XS9dcc40++uijDPdudKirq9P555+v4uJiTZ06VStXrtTRo0cjYhjn4Xv00Uc1f/780EvLqqur9R//8R+h9YxxZtTV1clms+nWW28NLWOs0+P73/++bDZbxGfatGmh9WNinA0M29NPP23k5eUZv/jFL4y33nrL+O53v2uMHz/eeO+997LdtFHrueeeMzZu3GjU19cbkozt27dHrN+0aZNRXFxs1NfXG01NTcZVV11llJWVGW63OxRTU1NjTJ8+3di9e7fx2muvGZdddplx3nnnGX19faGYP//zPzeqqqqMV155xXjllVeMqqoq44orrhipbmbV5ZdfbjzxxBPGm2++aRw6dMj4yle+Ypx11llGZ2dnKIZxHr6dO3cau3btMo4ePWocPXrUuOuuu4y8vDzjzTffNAyDMc6E3//+98bZZ59tzJ8/3/jud78bWs5Yp8c999xjzJ0712hpaQl9Tp48GVo/FsaZ5CYNvvCFLxg1NTURyz7zmc8Yd955Z5ZaNLYMTm4CgYAxbdo0Y9OmTaFlvb29hsvlMn72s58ZhmEYH330kZGXl2c8/fTToZjm5mYjJyfHeP755w3DMIy33nrLkGS8+uqroZjGxkZDkvH2229nuFejz8mTJw1JRkNDg2EYjHMmlZSUGP/0T//EGGdAR0eHMXv2bGP37t3GF7/4xVByw1inzz333GOcd955UdeNlXHmn6WGyev16sCBA1q2bFnE8mXLlumVV17JUqvGtuPHj6u1tTViTAsKCvTFL34xNKYHDhyQz+eLiCkvL1dVVVUoprGxUS6XSxdccEEo5sILL5TL5fpE7pv29nZJ0sSJEyUxzpng9/v19NNPq6urS9XV1YxxBtx88836yle+oj/7sz+LWM5Yp9c777yj8vJyzZo1S9/4xjf0hz/8QdLYGedP3B/OTLfTp0/L7/ertLQ0YnlpaalaW1uz1KqxLThu0cb0vffeC8Xk5+erpKRkSExw+9bWVk2dOnVI+VOnTv3E7RvDMFRbW6slS5aoqqpKEuOcTk1NTaqurlZvb6+Kioq0fft2nXvuuaEvacY4PZ5++mm99tpr+q//+q8h6zie0+eCCy7Qli1b9OlPf1p//OMfdf/992vx4sU6fPjwmBlnkps0sdlsET8bhjFkGZKTypgOjokW/0ncN2vXrtUbb7yhl19+ecg6xnn45syZo0OHDumjjz5SfX29rr32WjU0NITWM8bD9/777+u73/2uXnjhBTkcjphxjPXwLV++PPT/8+bNU3V1tc455xw9+eSTuvDCCyWN/nHmn6WGafLkycrNzR2SaZ48eXJIZgtzgnflxxvTadOmyev16syZM3Fj/vjHPw4p/9SpU5+ofXPLLbdo586d2rNnj2bMmBFazjinT35+viorK7Vo0SLV1dXpvPPO0w9/+EPGOI0OHDigkydPauHChbLb7bLb7WpoaNCPfvQj2e320Dgw1uk3fvx4zZs3T++8886YOaZJboYpPz9fCxcu1O7duyOW7969W4sXL85Sq8a2WbNmadq0aRFj6vV61dDQEBrThQsXKi8vLyKmpaVFb775Ziimurpa7e3t+v3vfx+K+d3vfqf29vZPxL4xDENr167Vtm3b9OKLL2rWrFkR6xnnzDEMQx6PhzFOo6VLl6qpqUmHDh0KfRYtWqSrr75ahw4d0qc+9SnGOkM8Ho+OHDmisrKysXNMD/uWZIQeBX/88ceNt956y7j11luN8ePHG++++262mzZqdXR0GAcPHjQOHjxoSDJ+8IMfGAcPHgw9Pr9p0ybD5XIZ27ZtM5qamoxvfvObUR81nDFjhvGb3/zGeO2114wvfelLUR81nD9/vtHY2Gg0NjYa8+bN+8Q80vmd73zHcLlcxt69eyMe6ezu7g7FMM7Dt2HDBmPfvn3G8ePHjTfeeMO46667jJycHOOFF14wDIMxzqTwp6UMg7FOl+9973vG3r17jT/84Q/Gq6++alxxxRVGcXFx6Jw2FsaZ5CZNfvrTnxozZ8408vPzjc9//vOhx20R3Z49ewxJQz7XXnutYRj9jxvec889xrRp04yCggLjkksuMZqamiLK6OnpMdauXWtMnDjRKCwsNK644grjxIkTETFtbW3G1VdfbRQXFxvFxcXG1VdfbZw5c2aEepld0cZXkvHEE0+EYhjn4bv++utDc3/KlCnG0qVLQ4mNYTDGmTQ4uWGs0yP43pq8vDyjvLzc+Mu//Evj8OHDofVjYZxthmEYw7/+AwAAMDpwzw0AALAUkhsAAGApJDcAAMBSSG4AAIClkNwAAABLIbkBAACWQnIDAAAsheQGAABYCskNAACwFJIbAABgKSQ3AADAUkhuAACApfz/N3+TEKi2Xy0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "axs=plt.subplots()\n",
    "axs=sns.scatterplot(X.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.33893896971134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/withmocha/opt/anaconda3/envs/conda/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, Y = make_regression(n_samples=200)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25)\n",
    "model=MLPRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "import numpy as np\n",
    "def RMSE(data,pred):\n",
    "    n=len(data)\n",
    "    return np.sqrt((np.sum((data-pred)**2))/n)\n",
    "print(RMSE(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/withmocha/opt/anaconda3/envs/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2023-07-09 21:27:22,700] A new study created in memory with name: no-name-6e0316f6-13fa-40fd-a689-5e9295fde336\n",
      "[I 2023-07-09 21:27:22,934] Trial 0 finished with value: 106.10911209277282 and parameters: {'hidden_layer_sizes': 183, 'alpha': 0.05080414493038862, 'batch_size': 6, 'learning_rate_init': 0.08897336614565421}. Best is trial 0 with value: 106.10911209277282.\n",
      "[I 2023-07-09 21:27:23,392] Trial 1 finished with value: 128.38840236256567 and parameters: {'hidden_layer_sizes': 338, 'alpha': 0.04579858640916343, 'batch_size': 2, 'learning_rate_init': 0.04181872677182985}. Best is trial 0 with value: 106.10911209277282.\n",
      "[I 2023-07-09 21:27:23,479] Trial 2 finished with value: 97.791978506706 and parameters: {'hidden_layer_sizes': 67, 'alpha': 0.06195437092294183, 'batch_size': 7, 'learning_rate_init': 0.0892144671652392}. Best is trial 2 with value: 97.791978506706.\n",
      "[I 2023-07-09 21:27:23,633] Trial 3 finished with value: 109.80550154192946 and parameters: {'hidden_layer_sizes': 258, 'alpha': 0.054176597339377415, 'batch_size': 8, 'learning_rate_init': 0.012581541398012184}. Best is trial 2 with value: 97.791978506706.\n",
      "[I 2023-07-09 21:27:23,934] Trial 4 finished with value: 97.42014958415724 and parameters: {'hidden_layer_sizes': 479, 'alpha': 0.0051972766838581696, 'batch_size': 10, 'learning_rate_init': 0.0741646437711646}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:24,932] Trial 5 finished with value: 160.75709324770102 and parameters: {'hidden_layer_sizes': 460, 'alpha': 0.016974299474430056, 'batch_size': 1, 'learning_rate_init': 0.037863399556586706}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:25,321] Trial 6 finished with value: 130.0189002085383 and parameters: {'hidden_layer_sizes': 391, 'alpha': 0.02500996945456302, 'batch_size': 4, 'learning_rate_init': 0.05337487482539948}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:25,749] Trial 7 finished with value: 168.26069412553383 and parameters: {'hidden_layer_sizes': 199, 'alpha': 0.05201977781595078, 'batch_size': 1, 'learning_rate_init': 0.09336030838260471}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:25,826] Trial 8 finished with value: 106.42310674216229 and parameters: {'hidden_layer_sizes': 123, 'alpha': 0.09878203264595715, 'batch_size': 10, 'learning_rate_init': 0.05788922685999515}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:27,184] Trial 9 finished with value: 118.09558814520545 and parameters: {'hidden_layer_sizes': 296, 'alpha': 0.010569178107045189, 'batch_size': 1, 'learning_rate_init': 0.08385641609764137}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:27,484] Trial 10 finished with value: 101.51696847385115 and parameters: {'hidden_layer_sizes': 483, 'alpha': 0.0018073972055930123, 'batch_size': 10, 'learning_rate_init': 0.06801450338608356}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:27,640] Trial 11 finished with value: 97.89895249629832 and parameters: {'hidden_layer_sizes': 64, 'alpha': 0.07291851299742975, 'batch_size': 7, 'learning_rate_init': 0.07451423774255538}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:27,698] Trial 12 finished with value: 107.20630925707097 and parameters: {'hidden_layer_sizes': 25, 'alpha': 0.03336571252178854, 'batch_size': 8, 'learning_rate_init': 0.09749361514093355}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:27,896] Trial 13 finished with value: 114.2975518534263 and parameters: {'hidden_layer_sizes': 404, 'alpha': 0.03003848463775964, 'batch_size': 4, 'learning_rate_init': 0.07621709729019528}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:28,024] Trial 14 finished with value: 99.94645362871165 and parameters: {'hidden_layer_sizes': 130, 'alpha': 0.0021829428403580473, 'batch_size': 9, 'learning_rate_init': 0.0966813379001891}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:28,315] Trial 15 finished with value: 111.20297582893171 and parameters: {'hidden_layer_sizes': 337, 'alpha': 0.06816908794864912, 'batch_size': 5, 'learning_rate_init': 0.08033334763321198}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:28,497] Trial 16 finished with value: 102.77796334998146 and parameters: {'hidden_layer_sizes': 203, 'alpha': 0.03935229734593159, 'batch_size': 7, 'learning_rate_init': 0.06395957088604962}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:28,589] Trial 17 finished with value: 107.19045183520898 and parameters: {'hidden_layer_sizes': 90, 'alpha': 0.020474280880241145, 'batch_size': 9, 'learning_rate_init': 0.09985940067052052}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:28,805] Trial 18 finished with value: 111.69773386485922 and parameters: {'hidden_layer_sizes': 410, 'alpha': 0.012054323122585075, 'batch_size': 6, 'learning_rate_init': 0.08373276646044213}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:28,960] Trial 19 finished with value: 101.86523645023482 and parameters: {'hidden_layer_sizes': 258, 'alpha': 0.034696068087194026, 'batch_size': 9, 'learning_rate_init': 0.0710569387362407}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:29,111] Trial 20 finished with value: 100.26193971431708 and parameters: {'hidden_layer_sizes': 11, 'alpha': 0.025858553628172163, 'batch_size': 3, 'learning_rate_init': 0.08600465161186573}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:29,211] Trial 21 finished with value: 106.31576320454727 and parameters: {'hidden_layer_sizes': 68, 'alpha': 0.06682484067866287, 'batch_size': 7, 'learning_rate_init': 0.07500216437721124}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:29,377] Trial 22 finished with value: 109.94878722280504 and parameters: {'hidden_layer_sizes': 153, 'alpha': 0.06953412819412949, 'batch_size': 7, 'learning_rate_init': 0.06425995309426462}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:29,461] Trial 23 finished with value: 104.37520548624433 and parameters: {'hidden_layer_sizes': 65, 'alpha': 0.0814303702385531, 'batch_size': 8, 'learning_rate_init': 0.07739398906563717}. Best is trial 4 with value: 97.42014958415724.\n",
      "[I 2023-07-09 21:27:29,566] Trial 24 finished with value: 96.87344324809821 and parameters: {'hidden_layer_sizes': 96, 'alpha': 0.05981416493000209, 'batch_size': 5, 'learning_rate_init': 0.08971906817847033}. Best is trial 24 with value: 96.87344324809821.\n",
      "[I 2023-07-09 21:27:29,722] Trial 25 finished with value: 103.13311111022162 and parameters: {'hidden_layer_sizes': 114, 'alpha': 0.058601976644538895, 'batch_size': 5, 'learning_rate_init': 0.08751127395782694}. Best is trial 24 with value: 96.87344324809821.\n",
      "[I 2023-07-09 21:27:30,084] Trial 26 finished with value: 101.60795445793569 and parameters: {'hidden_layer_sizes': 170, 'alpha': 0.04302392849163338, 'batch_size': 4, 'learning_rate_init': 0.09164870647875079}. Best is trial 24 with value: 96.87344324809821.\n",
      "[I 2023-07-09 21:27:30,285] Trial 27 finished with value: 157.2901137190485 and parameters: {'hidden_layer_sizes': 216, 'alpha': 0.03810738481726067, 'batch_size': 6, 'learning_rate_init': 0.08250711436879503}. Best is trial 24 with value: 96.87344324809821.\n",
      "[I 2023-07-09 21:27:30,425] Trial 28 finished with value: 102.48670670048344 and parameters: {'hidden_layer_sizes': 34, 'alpha': 0.0610212443982365, 'batch_size': 3, 'learning_rate_init': 0.09175729402771059}. Best is trial 24 with value: 96.87344324809821.\n",
      "[I 2023-07-09 21:27:30,878] Trial 29 finished with value: 102.67151035116258 and parameters: {'hidden_layer_sizes': 338, 'alpha': 0.047898010402602054, 'batch_size': 5, 'learning_rate_init': 0.09213755887251895}. Best is trial 24 with value: 96.87344324809821.\n",
      "[I 2023-07-09 21:27:31,078] Trial 30 finished with value: 117.86444480529086 and parameters: {'hidden_layer_sizes': 296, 'alpha': 0.04667949761073409, 'batch_size': 10, 'learning_rate_init': 0.08589438685059449}. Best is trial 24 with value: 96.87344324809821.\n",
      "[I 2023-07-09 21:27:31,231] Trial 31 finished with value: 95.81422664093932 and parameters: {'hidden_layer_sizes': 68, 'alpha': 0.07511297057225387, 'batch_size': 7, 'learning_rate_init': 0.0730020024640954}. Best is trial 31 with value: 95.81422664093932.\n",
      "[I 2023-07-09 21:27:31,375] Trial 32 finished with value: 93.88314411787765 and parameters: {'hidden_layer_sizes': 96, 'alpha': 0.0554911141489352, 'batch_size': 6, 'learning_rate_init': 0.07984911625210198}. Best is trial 32 with value: 93.88314411787765.\n",
      "[I 2023-07-09 21:27:31,506] Trial 33 finished with value: 103.31077680044297 and parameters: {'hidden_layer_sizes': 150, 'alpha': 0.054544951380891604, 'batch_size': 5, 'learning_rate_init': 0.07036753671385149}. Best is trial 32 with value: 93.88314411787765.\n",
      "[I 2023-07-09 21:27:31,601] Trial 34 finished with value: 93.20524862316373 and parameters: {'hidden_layer_sizes': 97, 'alpha': 0.04247953332524518, 'batch_size': 6, 'learning_rate_init': 0.08051299839630595}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:31,774] Trial 35 finished with value: 98.88696281340128 and parameters: {'hidden_layer_sizes': 79, 'alpha': 0.04875343143547085, 'batch_size': 6, 'learning_rate_init': 0.07973864986143903}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:31,894] Trial 36 finished with value: 106.62288607747763 and parameters: {'hidden_layer_sizes': 90, 'alpha': 0.05657470652805593, 'batch_size': 6, 'learning_rate_init': 0.08856280239619416}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:31,972] Trial 37 finished with value: 102.93909676378557 and parameters: {'hidden_layer_sizes': 41, 'alpha': 0.06247049576489531, 'batch_size': 6, 'learning_rate_init': 0.07985463962422407}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:32,070] Trial 38 finished with value: 112.15896819656629 and parameters: {'hidden_layer_sizes': 104, 'alpha': 0.05169412386254352, 'batch_size': 8, 'learning_rate_init': 0.06487004803380977}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:32,276] Trial 39 finished with value: 102.16497922556856 and parameters: {'hidden_layer_sizes': 232, 'alpha': 0.04501678351084121, 'batch_size': 3, 'learning_rate_init': 0.04627124210347189}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:32,509] Trial 40 finished with value: 105.8635846799885 and parameters: {'hidden_layer_sizes': 167, 'alpha': 0.07562150045536185, 'batch_size': 5, 'learning_rate_init': 0.05994979214610857}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:32,657] Trial 41 finished with value: 101.60846295900548 and parameters: {'hidden_layer_sizes': 134, 'alpha': 0.05655630694387829, 'batch_size': 4, 'learning_rate_init': 0.07376854411595792}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:32,750] Trial 42 finished with value: 103.31891672666504 and parameters: {'hidden_layer_sizes': 50, 'alpha': 0.04124912621453426, 'batch_size': 7, 'learning_rate_init': 0.06836887338841058}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:33,009] Trial 43 finished with value: 105.8676123393502 and parameters: {'hidden_layer_sizes': 457, 'alpha': 0.050097930879958105, 'batch_size': 8, 'learning_rate_init': 0.08178681940167826}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:33,125] Trial 44 finished with value: 110.43392669639199 and parameters: {'hidden_layer_sizes': 108, 'alpha': 0.06404523963400183, 'batch_size': 4, 'learning_rate_init': 0.09532869350165084}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:33,811] Trial 45 finished with value: 103.36474456165821 and parameters: {'hidden_layer_sizes': 190, 'alpha': 0.02763772050025605, 'batch_size': 2, 'learning_rate_init': 0.07358779602733537}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:34,163] Trial 46 finished with value: 99.47578091875388 and parameters: {'hidden_layer_sizes': 376, 'alpha': 0.019423356182072173, 'batch_size': 6, 'learning_rate_init': 0.08934190637700683}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:34,221] Trial 47 finished with value: 100.75409583674306 and parameters: {'hidden_layer_sizes': 13, 'alpha': 0.0332145791339042, 'batch_size': 10, 'learning_rate_init': 0.07858613048974562}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:34,310] Trial 48 finished with value: 106.57983264041289 and parameters: {'hidden_layer_sizes': 136, 'alpha': 0.005892340214625928, 'batch_size': 9, 'learning_rate_init': 0.0541913466496943}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:34,530] Trial 49 finished with value: 105.54820925728608 and parameters: {'hidden_layer_sizes': 305, 'alpha': 0.013998320303442377, 'batch_size': 7, 'learning_rate_init': 0.08326772270632865}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,038] Trial 50 finished with value: 114.97960817453638 and parameters: {'hidden_layer_sizes': 493, 'alpha': 0.0079032166826324, 'batch_size': 5, 'learning_rate_init': 0.09480411711072304}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,143] Trial 51 finished with value: 103.37708670714534 and parameters: {'hidden_layer_sizes': 54, 'alpha': 0.05336244620339703, 'batch_size': 7, 'learning_rate_init': 0.08778727875909871}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,260] Trial 52 finished with value: 114.04176283076373 and parameters: {'hidden_layer_sizes': 91, 'alpha': 0.02311481016162485, 'batch_size': 6, 'learning_rate_init': 0.07718048094567895}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,379] Trial 53 finished with value: 101.15334324188515 and parameters: {'hidden_layer_sizes': 75, 'alpha': 0.06056444158423181, 'batch_size': 8, 'learning_rate_init': 0.09747467079110003}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,508] Trial 54 finished with value: 102.34824203595466 and parameters: {'hidden_layer_sizes': 121, 'alpha': 0.06515282362060595, 'batch_size': 7, 'learning_rate_init': 0.08441995697219953}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,573] Trial 55 finished with value: 109.83815024259084 and parameters: {'hidden_layer_sizes': 35, 'alpha': 0.07031157383688151, 'batch_size': 8, 'learning_rate_init': 0.07131699424245888}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,706] Trial 56 finished with value: 110.64510513480698 and parameters: {'hidden_layer_sizes': 94, 'alpha': 0.07611960076102131, 'batch_size': 5, 'learning_rate_init': 0.07671059171146036}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:35,798] Trial 57 finished with value: 103.66292257753507 and parameters: {'hidden_layer_sizes': 55, 'alpha': 0.015824543771029074, 'batch_size': 6, 'learning_rate_init': 0.09006743383494065}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:36,097] Trial 58 finished with value: 112.3505221858967 and parameters: {'hidden_layer_sizes': 465, 'alpha': 0.05755135906654371, 'batch_size': 9, 'learning_rate_init': 0.09979326393438018}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:36,211] Trial 59 finished with value: 116.46710011601408 and parameters: {'hidden_layer_sizes': 152, 'alpha': 0.001684147378839932, 'batch_size': 7, 'learning_rate_init': 0.08549275785995694}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:36,324] Trial 60 finished with value: 109.68390458984842 and parameters: {'hidden_layer_sizes': 75, 'alpha': 0.05262560453534264, 'batch_size': 4, 'learning_rate_init': 0.09353493170405433}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:36,391] Trial 61 finished with value: 110.39655150364659 and parameters: {'hidden_layer_sizes': 24, 'alpha': 0.06713914150093905, 'batch_size': 7, 'learning_rate_init': 0.0813498468286517}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:36,474] Trial 62 finished with value: 105.12329624036396 and parameters: {'hidden_layer_sizes': 63, 'alpha': 0.05971063715519395, 'batch_size': 7, 'learning_rate_init': 0.0730836128879486}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:36,670] Trial 63 finished with value: 110.95169358529081 and parameters: {'hidden_layer_sizes': 273, 'alpha': 0.07164912329444492, 'batch_size': 6, 'learning_rate_init': 0.07561790624191495}. Best is trial 34 with value: 93.20524862316373.\n",
      "[I 2023-07-09 21:27:36,964] Trial 64 finished with value: 84.67288745448275 and parameters: {'hidden_layer_sizes': 430, 'alpha': 0.0651809588808832, 'batch_size': 5, 'learning_rate_init': 0.06876744328850001}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:37,607] Trial 65 finished with value: 103.65208324835288 and parameters: {'hidden_layer_sizes': 438, 'alpha': 0.06340083611563654, 'batch_size': 5, 'learning_rate_init': 0.06755203882533967}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:37,798] Trial 66 finished with value: 115.57611989033103 and parameters: {'hidden_layer_sizes': 426, 'alpha': 0.06704385305560753, 'batch_size': 5, 'learning_rate_init': 0.07902676271676037}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:37,987] Trial 67 finished with value: 111.40624596587534 and parameters: {'hidden_layer_sizes': 390, 'alpha': 0.04580939081706317, 'batch_size': 6, 'learning_rate_init': 0.08568602725181473}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:38,277] Trial 68 finished with value: 346.5314800171892 and parameters: {'hidden_layer_sizes': 475, 'alpha': 0.054864688885721574, 'batch_size': 5, 'learning_rate_init': 0.08201277727743246}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:38,861] Trial 69 finished with value: 94.5258165568919 and parameters: {'hidden_layer_sizes': 371, 'alpha': 0.05022129280320849, 'batch_size': 4, 'learning_rate_init': 0.06956115669741181}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:39,058] Trial 70 finished with value: 119.29699201627021 and parameters: {'hidden_layer_sizes': 355, 'alpha': 0.04926116267838354, 'batch_size': 4, 'learning_rate_init': 0.06941437307035284}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:39,338] Trial 71 finished with value: 142.58902984913368 and parameters: {'hidden_layer_sizes': 443, 'alpha': 0.05956854551487615, 'batch_size': 3, 'learning_rate_init': 0.06123001435124023}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:39,934] Trial 72 finished with value: 104.85110632508328 and parameters: {'hidden_layer_sizes': 419, 'alpha': 0.039024147598186676, 'batch_size': 4, 'learning_rate_init': 0.07270540527409923}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:40,325] Trial 73 finished with value: 90.71228107660541 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.06251271498093364, 'batch_size': 6, 'learning_rate_init': 0.06536233952606843}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:40,666] Trial 74 finished with value: 138.72653709970157 and parameters: {'hidden_layer_sizes': 498, 'alpha': 0.04340967980731923, 'batch_size': 5, 'learning_rate_init': 0.06597273663427308}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:40,866] Trial 75 finished with value: 137.69141578477232 and parameters: {'hidden_layer_sizes': 474, 'alpha': 0.05048002328717669, 'batch_size': 6, 'learning_rate_init': 0.0701918921767217}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:41,141] Trial 76 finished with value: 116.74625216635516 and parameters: {'hidden_layer_sizes': 451, 'alpha': 0.05611851852560905, 'batch_size': 3, 'learning_rate_init': 0.0619156466611744}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:41,473] Trial 77 finished with value: 143.54212066134633 and parameters: {'hidden_layer_sizes': 482, 'alpha': 0.06405671599697078, 'batch_size': 5, 'learning_rate_init': 0.06712971092601874}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:41,688] Trial 78 finished with value: 123.23823796314251 and parameters: {'hidden_layer_sizes': 396, 'alpha': 0.061535324289297574, 'batch_size': 4, 'learning_rate_init': 0.07570902701056481}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:42,060] Trial 79 finished with value: 112.82798194860153 and parameters: {'hidden_layer_sizes': 428, 'alpha': 0.054949587911343856, 'batch_size': 6, 'learning_rate_init': 0.06420565765429627}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:42,322] Trial 80 finished with value: 165.60461151494314 and parameters: {'hidden_layer_sizes': 362, 'alpha': 0.035320868252929585, 'batch_size': 4, 'learning_rate_init': 0.05862131655543102}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:42,429] Trial 81 finished with value: 108.05663392458953 and parameters: {'hidden_layer_sizes': 101, 'alpha': 0.058405715660878064, 'batch_size': 6, 'learning_rate_init': 0.07937593083625741}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:42,655] Trial 82 finished with value: 110.12537229827575 and parameters: {'hidden_layer_sizes': 118, 'alpha': 0.05232788111903173, 'batch_size': 2, 'learning_rate_init': 0.07054846472824408}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:42,863] Trial 83 finished with value: 160.953016922153 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.06808600367002297, 'batch_size': 5, 'learning_rate_init': 0.07514852598857577}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:42,986] Trial 84 finished with value: 98.86626902612124 and parameters: {'hidden_layer_sizes': 84, 'alpha': 0.065541588080882, 'batch_size': 6, 'learning_rate_init': 0.07751797813453133}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:43,188] Trial 85 finished with value: 103.62790282266661 and parameters: {'hidden_layer_sizes': 140, 'alpha': 0.06217428101955895, 'batch_size': 7, 'learning_rate_init': 0.0807490345277515}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:43,397] Trial 86 finished with value: 108.27280528515652 and parameters: {'hidden_layer_sizes': 326, 'alpha': 0.05743909828300209, 'batch_size': 10, 'learning_rate_init': 0.07273414483454395}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:43,596] Trial 87 finished with value: 104.72979477736902 and parameters: {'hidden_layer_sizes': 227, 'alpha': 0.04667899374886406, 'batch_size': 8, 'learning_rate_init': 0.09053324240267928}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:43,873] Trial 88 finished with value: 94.74504019743185 and parameters: {'hidden_layer_sizes': 467, 'alpha': 0.03015957315321976, 'batch_size': 9, 'learning_rate_init': 0.08774796069343915}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:44,138] Trial 89 finished with value: 107.15193354136447 and parameters: {'hidden_layer_sizes': 463, 'alpha': 0.04869297394532837, 'batch_size': 10, 'learning_rate_init': 0.0870570460621033}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:44,390] Trial 90 finished with value: 142.97768418555043 and parameters: {'hidden_layer_sizes': 482, 'alpha': 0.028661901455214404, 'batch_size': 9, 'learning_rate_init': 0.08262117121817283}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:44,803] Trial 91 finished with value: 98.99235600438297 and parameters: {'hidden_layer_sizes': 449, 'alpha': 0.024626461049616563, 'batch_size': 9, 'learning_rate_init': 0.08458362640049034}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:45,082] Trial 92 finished with value: 97.67594362816995 and parameters: {'hidden_layer_sizes': 471, 'alpha': 0.031159181960861645, 'batch_size': 10, 'learning_rate_init': 0.08892054679850425}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:45,361] Trial 93 finished with value: 99.60362221532708 and parameters: {'hidden_layer_sizes': 484, 'alpha': 0.0314113314418509, 'batch_size': 10, 'learning_rate_init': 0.08886595225611102}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:45,560] Trial 94 finished with value: 105.01550682387884 and parameters: {'hidden_layer_sizes': 466, 'alpha': 0.031779170025120665, 'batch_size': 10, 'learning_rate_init': 0.09219502459848927}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:45,760] Trial 95 finished with value: 111.1055692275375 and parameters: {'hidden_layer_sizes': 409, 'alpha': 0.03655730391474844, 'batch_size': 10, 'learning_rate_init': 0.0784308531598943}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:45,990] Trial 96 finished with value: 103.81861877357855 and parameters: {'hidden_layer_sizes': 435, 'alpha': 0.0417916344395466, 'batch_size': 9, 'learning_rate_init': 0.06762162254257739}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:46,149] Trial 97 finished with value: 107.92120722463365 and parameters: {'hidden_layer_sizes': 486, 'alpha': 0.02078050711371179, 'batch_size': 10, 'learning_rate_init': 0.08740714428686898}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:46,348] Trial 98 finished with value: 102.70126343567009 and parameters: {'hidden_layer_sizes': 456, 'alpha': 0.04089105121431032, 'batch_size': 9, 'learning_rate_init': 0.08444835688209616}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:46,800] Trial 99 finished with value: 95.75642210093088 and parameters: {'hidden_layer_sizes': 469, 'alpha': 0.027812085679183716, 'batch_size': 6, 'learning_rate_init': 0.07390702436225077}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:46,998] Trial 100 finished with value: 169.13169815818523 and parameters: {'hidden_layer_sizes': 491, 'alpha': 0.026424748484597492, 'batch_size': 6, 'learning_rate_init': 0.07465437351366619}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:47,278] Trial 101 finished with value: 104.5314340752958 and parameters: {'hidden_layer_sizes': 472, 'alpha': 0.030042731247944196, 'batch_size': 5, 'learning_rate_init': 0.07142745288526609}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:47,555] Trial 102 finished with value: 222.89116271606014 and parameters: {'hidden_layer_sizes': 448, 'alpha': 0.036780975374037225, 'batch_size': 6, 'learning_rate_init': 0.06906671774624161}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:47,993] Trial 103 finished with value: 131.82602743951455 and parameters: {'hidden_layer_sizes': 417, 'alpha': 0.018619849542151637, 'batch_size': 6, 'learning_rate_init': 0.0806557835303797}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:48,211] Trial 104 finished with value: 139.6936717974973 and parameters: {'hidden_layer_sizes': 459, 'alpha': 0.034581649745507356, 'batch_size': 5, 'learning_rate_init': 0.07756625817896855}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:48,357] Trial 105 finished with value: 103.30046685531897 and parameters: {'hidden_layer_sizes': 433, 'alpha': 0.02454954329355013, 'batch_size': 10, 'learning_rate_init': 0.06577274911363667}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:48,518] Trial 106 finished with value: 128.5673383577242 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.011593526252474111, 'batch_size': 6, 'learning_rate_init': 0.0740573772313093}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:48,769] Trial 107 finished with value: 106.67137645394858 and parameters: {'hidden_layer_sizes': 474, 'alpha': 0.02252689054044916, 'batch_size': 7, 'learning_rate_init': 0.0824890381086257}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:48,920] Trial 108 finished with value: 104.84974195330565 and parameters: {'hidden_layer_sizes': 45, 'alpha': 0.01535348656355848, 'batch_size': 5, 'learning_rate_init': 0.07223366522132477}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:49,109] Trial 109 finished with value: 98.48585513453025 and parameters: {'hidden_layer_sizes': 63, 'alpha': 0.051559299962105065, 'batch_size': 6, 'learning_rate_init': 0.07598268128008806}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:49,413] Trial 110 finished with value: 137.88630036617218 and parameters: {'hidden_layer_sizes': 441, 'alpha': 0.027531963432097583, 'batch_size': 4, 'learning_rate_init': 0.06892382845660805}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:49,512] Trial 111 finished with value: 108.649214774229 and parameters: {'hidden_layer_sizes': 82, 'alpha': 0.060024872054248606, 'batch_size': 8, 'learning_rate_init': 0.09095695068226754}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:49,609] Trial 112 finished with value: 102.22313581354838 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.04453566135139545, 'batch_size': 7, 'learning_rate_init': 0.09391304454022115}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:49,712] Trial 113 finished with value: 102.96500991031039 and parameters: {'hidden_layer_sizes': 111, 'alpha': 0.05433900714981395, 'batch_size': 7, 'learning_rate_init': 0.08673513426777975}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:49,851] Trial 114 finished with value: 108.86839263324634 and parameters: {'hidden_layer_sizes': 126, 'alpha': 0.033120720749417326, 'batch_size': 5, 'learning_rate_init': 0.0894672846788486}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:50,012] Trial 115 finished with value: 103.83674929803372 and parameters: {'hidden_layer_sizes': 166, 'alpha': 0.062132669614606034, 'batch_size': 6, 'learning_rate_init': 0.08368907106095112}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:50,094] Trial 116 finished with value: 112.33126055145027 and parameters: {'hidden_layer_sizes': 70, 'alpha': 0.008182713537019014, 'batch_size': 9, 'learning_rate_init': 0.08021052984242336}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:50,191] Trial 117 finished with value: 110.14198178838251 and parameters: {'hidden_layer_sizes': 55, 'alpha': 0.0476790573711668, 'batch_size': 8, 'learning_rate_init': 0.09591398998242052}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:50,387] Trial 118 finished with value: 101.52495138418233 and parameters: {'hidden_layer_sizes': 266, 'alpha': 0.0034876484827599044, 'batch_size': 6, 'learning_rate_init': 0.062325475029561414}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:50,799] Trial 119 finished with value: 102.14990662756966 and parameters: {'hidden_layer_sizes': 377, 'alpha': 0.06514578990200415, 'batch_size': 7, 'learning_rate_init': 0.07705761010588529}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:51,137] Trial 120 finished with value: 96.60613831182583 and parameters: {'hidden_layer_sizes': 472, 'alpha': 0.03860244514325842, 'batch_size': 5, 'learning_rate_init': 0.09272610252926837}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:51,815] Trial 121 finished with value: 99.48738820662746 and parameters: {'hidden_layer_sizes': 471, 'alpha': 0.03957114350574372, 'batch_size': 5, 'learning_rate_init': 0.08559114894945952}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:52,004] Trial 122 finished with value: 184.3472080227849 and parameters: {'hidden_layer_sizes': 490, 'alpha': 0.030126596685129, 'batch_size': 5, 'learning_rate_init': 0.09261496730519711}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:52,195] Trial 123 finished with value: 149.96579998747902 and parameters: {'hidden_layer_sizes': 480, 'alpha': 0.03735033140555149, 'batch_size': 6, 'learning_rate_init': 0.0897637548508404}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:52,466] Trial 124 finished with value: 167.653645357736 and parameters: {'hidden_layer_sizes': 463, 'alpha': 1.879270269457365e-05, 'batch_size': 5, 'learning_rate_init': 0.09409072282894876}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:52,766] Trial 125 finished with value: 263.1811236856425 and parameters: {'hidden_layer_sizes': 453, 'alpha': 0.04401503828215452, 'batch_size': 4, 'learning_rate_init': 0.08883453091074484}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:52,876] Trial 126 finished with value: 112.06207597288028 and parameters: {'hidden_layer_sizes': 93, 'alpha': 0.05692708657099366, 'batch_size': 10, 'learning_rate_init': 0.070825517642705}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:53,078] Trial 127 finished with value: 111.83456700689054 and parameters: {'hidden_layer_sizes': 319, 'alpha': 0.05015202589512748, 'batch_size': 6, 'learning_rate_init': 0.06631160673401676}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:53,189] Trial 128 finished with value: 97.79938125625416 and parameters: {'hidden_layer_sizes': 35, 'alpha': 0.058934357648821656, 'batch_size': 5, 'learning_rate_init': 0.09732753252792328}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:54,207] Trial 129 finished with value: 105.51915505611383 and parameters: {'hidden_layer_sizes': 492, 'alpha': 0.04064592678398711, 'batch_size': 3, 'learning_rate_init': 0.07418434835360935}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:54,386] Trial 130 finished with value: 121.00072206480219 and parameters: {'hidden_layer_sizes': 425, 'alpha': 0.04234059537469173, 'batch_size': 6, 'learning_rate_init': 0.09135392731253442}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:54,463] Trial 131 finished with value: 102.8773190143971 and parameters: {'hidden_layer_sizes': 22, 'alpha': 0.060262428907288675, 'batch_size': 5, 'learning_rate_init': 0.09879778627766837}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:54,547] Trial 132 finished with value: 98.93124667106305 and parameters: {'hidden_layer_sizes': 28, 'alpha': 0.053934976614881135, 'batch_size': 5, 'learning_rate_init': 0.09655619778860898}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:54,728] Trial 133 finished with value: 110.35645860227424 and parameters: {'hidden_layer_sizes': 41, 'alpha': 0.05771306204374847, 'batch_size': 4, 'learning_rate_init': 0.09394844517476501}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:54,801] Trial 134 finished with value: 96.02992551975125 and parameters: {'hidden_layer_sizes': 12, 'alpha': 0.06881817751472166, 'batch_size': 5, 'learning_rate_init': 0.09216054525047013}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:54,880] Trial 135 finished with value: 111.77005770047833 and parameters: {'hidden_layer_sizes': 13, 'alpha': 0.06351904659043334, 'batch_size': 5, 'learning_rate_init': 0.08778738913764313}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:55,251] Trial 136 finished with value: 110.81019396940424 and parameters: {'hidden_layer_sizes': 468, 'alpha': 0.06857984664669284, 'batch_size': 9, 'learning_rate_init': 0.0841320168190104}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:55,503] Trial 137 finished with value: 106.7014948446745 and parameters: {'hidden_layer_sizes': 245, 'alpha': 0.07104176617019213, 'batch_size': 6, 'learning_rate_init': 0.07884003815198273}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:55,574] Trial 138 finished with value: 108.03332686019453 and parameters: {'hidden_layer_sizes': 83, 'alpha': 0.03872348502021205, 'batch_size': 10, 'learning_rate_init': 0.08613083766461076}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:55,785] Trial 139 finished with value: 105.76443928145115 and parameters: {'hidden_layer_sizes': 398, 'alpha': 0.03478144842096403, 'batch_size': 6, 'learning_rate_init': 0.08203086621187046}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:55,940] Trial 140 finished with value: 106.07495669942324 and parameters: {'hidden_layer_sizes': 106, 'alpha': 0.07334783185274872, 'batch_size': 4, 'learning_rate_init': 0.09255168969060895}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:56,037] Trial 141 finished with value: 101.59146487271168 and parameters: {'hidden_layer_sizes': 32, 'alpha': 0.02816219197124623, 'batch_size': 5, 'learning_rate_init': 0.09571719270796143}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:56,436] Trial 142 finished with value: 106.64644631016789 and parameters: {'hidden_layer_sizes': 59, 'alpha': 0.05893293085439961, 'batch_size': 1, 'learning_rate_init': 0.09693179598747148}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:56,585] Trial 143 finished with value: 113.46946510282723 and parameters: {'hidden_layer_sizes': 73, 'alpha': 0.017833000316356484, 'batch_size': 5, 'learning_rate_init': 0.09980859753762612}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:56,802] Trial 144 finished with value: 98.06197990144082 and parameters: {'hidden_layer_sizes': 41, 'alpha': 0.06547054745148809, 'batch_size': 5, 'learning_rate_init': 0.0911871180951426}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:56,923] Trial 145 finished with value: 108.38652883600571 and parameters: {'hidden_layer_sizes': 23, 'alpha': 0.06311429691057638, 'batch_size': 5, 'learning_rate_init': 0.0721425667377263}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:57,402] Trial 146 finished with value: 98.17539332441984 and parameters: {'hidden_layer_sizes': 458, 'alpha': 0.06087897450814464, 'batch_size': 6, 'learning_rate_init': 0.06891914731748228}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:57,815] Trial 147 finished with value: 114.13040969090204 and parameters: {'hidden_layer_sizes': 477, 'alpha': 0.05580433549120789, 'batch_size': 7, 'learning_rate_init': 0.08893771646414983}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:57,915] Trial 148 finished with value: 102.92594500337836 and parameters: {'hidden_layer_sizes': 53, 'alpha': 0.013401069337316721, 'batch_size': 5, 'learning_rate_init': 0.06418376376895847}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:58,115] Trial 149 finished with value: 143.60970261615063 and parameters: {'hidden_layer_sizes': 445, 'alpha': 0.03350499062406198, 'batch_size': 5, 'learning_rate_init': 0.07592683443275879}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:58,403] Trial 150 finished with value: 133.23353519894513 and parameters: {'hidden_layer_sizes': 493, 'alpha': 0.04625136845183942, 'batch_size': 6, 'learning_rate_init': 0.09452250757277567}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:58,471] Trial 151 finished with value: 99.3657084324081 and parameters: {'hidden_layer_sizes': 14, 'alpha': 0.07624898702805405, 'batch_size': 7, 'learning_rate_init': 0.07310127894163615}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:58,558] Trial 152 finished with value: 105.9746285885254 and parameters: {'hidden_layer_sizes': 67, 'alpha': 0.05217553174178227, 'batch_size': 7, 'learning_rate_init': 0.07869182119706702}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:58,678] Trial 153 finished with value: 99.23565614559284 and parameters: {'hidden_layer_sizes': 286, 'alpha': 0.06900713382180097, 'batch_size': 8, 'learning_rate_init': 0.07075332192366351}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:58,820] Trial 154 finished with value: 112.55091633508233 and parameters: {'hidden_layer_sizes': 202, 'alpha': 0.06659456233235381, 'batch_size': 8, 'learning_rate_init': 0.07374816852596316}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:58,939] Trial 155 finished with value: 113.9215998710887 and parameters: {'hidden_layer_sizes': 90, 'alpha': 0.029708967707134458, 'batch_size': 6, 'learning_rate_init': 0.07605013111621188}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:59,022] Trial 156 finished with value: 99.75607829766348 and parameters: {'hidden_layer_sizes': 49, 'alpha': 0.019961980419685294, 'batch_size': 7, 'learning_rate_init': 0.08093523400856348}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:59,222] Trial 157 finished with value: 108.33774050506642 and parameters: {'hidden_layer_sizes': 482, 'alpha': 0.026545856873670007, 'batch_size': 10, 'learning_rate_init': 0.06772292629663626}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:59,351] Trial 158 finished with value: 103.60930540659429 and parameters: {'hidden_layer_sizes': 41, 'alpha': 0.036463641718064176, 'batch_size': 4, 'learning_rate_init': 0.08624511063018789}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:59,466] Trial 159 finished with value: 108.22382440076147 and parameters: {'hidden_layer_sizes': 78, 'alpha': 0.023299020194175984, 'batch_size': 5, 'learning_rate_init': 0.09802022908085424}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:59,688] Trial 160 finished with value: 112.16636411992539 and parameters: {'hidden_layer_sizes': 64, 'alpha': 0.03142305570802592, 'batch_size': 6, 'learning_rate_init': 0.08982187317485507}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:27:59,915] Trial 161 finished with value: 106.76343722463828 and parameters: {'hidden_layer_sizes': 37, 'alpha': 0.06520645537061034, 'batch_size': 5, 'learning_rate_init': 0.09240110049311095}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:00,132] Trial 162 finished with value: 107.65004545654503 and parameters: {'hidden_layer_sizes': 51, 'alpha': 0.06624290370239094, 'batch_size': 5, 'learning_rate_init': 0.09089546868214986}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:00,417] Trial 163 finished with value: 324.0408109747171 and parameters: {'hidden_layer_sizes': 469, 'alpha': 0.06257559578912165, 'batch_size': 5, 'learning_rate_init': 0.09502021733160393}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:00,509] Trial 164 finished with value: 130.15040625094804 and parameters: {'hidden_layer_sizes': 31, 'alpha': 0.05912924881709206, 'batch_size': 5, 'learning_rate_init': 0.0915558703830312}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:00,627] Trial 165 finished with value: 105.79497388994086 and parameters: {'hidden_layer_sizes': 42, 'alpha': 0.06799860407319877, 'batch_size': 6, 'learning_rate_init': 0.08371980755332728}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:00,775] Trial 166 finished with value: 105.1633890294292 and parameters: {'hidden_layer_sizes': 98, 'alpha': 0.04873727049994192, 'batch_size': 7, 'learning_rate_init': 0.08767598961276885}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:00,967] Trial 167 finished with value: 101.05842172814984 and parameters: {'hidden_layer_sizes': 73, 'alpha': 0.010125184597398858, 'batch_size': 4, 'learning_rate_init': 0.0700334436446357}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:01,468] Trial 168 finished with value: 93.45826972582223 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.017045048155554514, 'batch_size': 9, 'learning_rate_init': 0.07756480076104598}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:01,950] Trial 169 finished with value: 97.00667346300266 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.0726290580648925, 'batch_size': 9, 'learning_rate_init': 0.07761791238188087}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:02,216] Trial 170 finished with value: 108.7884790294738 and parameters: {'hidden_layer_sizes': 494, 'alpha': 0.020528156791553467, 'batch_size': 9, 'learning_rate_init': 0.07993848525272132}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:02,518] Trial 171 finished with value: 110.8082776950671 and parameters: {'hidden_layer_sizes': 498, 'alpha': 0.07353831160032875, 'batch_size': 9, 'learning_rate_init': 0.07698128380367995}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:02,772] Trial 172 finished with value: 104.2517403351784 and parameters: {'hidden_layer_sizes': 499, 'alpha': 0.07103872285093471, 'batch_size': 9, 'learning_rate_init': 0.0756311684639781}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:03,008] Trial 173 finished with value: 157.23929948149498 and parameters: {'hidden_layer_sizes': 485, 'alpha': 0.0256775428521725, 'batch_size': 9, 'learning_rate_init': 0.07376077315443202}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:03,234] Trial 174 finished with value: 97.30629558240732 and parameters: {'hidden_layer_sizes': 482, 'alpha': 0.06957590406667231, 'batch_size': 10, 'learning_rate_init': 0.07786704627330795}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:03,432] Trial 175 finished with value: 114.21117186743162 and parameters: {'hidden_layer_sizes': 480, 'alpha': 0.013903586131049337, 'batch_size': 10, 'learning_rate_init': 0.07775628696961254}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:03,597] Trial 176 finished with value: 128.89568972124025 and parameters: {'hidden_layer_sizes': 488, 'alpha': 0.0038562013436309397, 'batch_size': 10, 'learning_rate_init': 0.0820194025820733}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:04,059] Trial 177 finished with value: 103.5547344446867 and parameters: {'hidden_layer_sizes': 473, 'alpha': 0.07003533743214017, 'batch_size': 10, 'learning_rate_init': 0.07200562971424275}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:04,274] Trial 178 finished with value: 118.7028328196221 and parameters: {'hidden_layer_sizes': 461, 'alpha': 0.0611588499448378, 'batch_size': 10, 'learning_rate_init': 0.0789604461397478}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:04,505] Trial 179 finished with value: 110.32804361593011 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.017100702665878834, 'batch_size': 10, 'learning_rate_init': 0.07489581026421645}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:04,751] Trial 180 finished with value: 111.36324681573646 and parameters: {'hidden_layer_sizes': 486, 'alpha': 0.007335882292544281, 'batch_size': 9, 'learning_rate_init': 0.08542771720559512}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:05,160] Trial 181 finished with value: 107.2969863179273 and parameters: {'hidden_layer_sizes': 115, 'alpha': 0.077299361990473, 'batch_size': 2, 'learning_rate_init': 0.07777233124693243}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:05,501] Trial 182 finished with value: 126.15791976712893 and parameters: {'hidden_layer_sizes': 468, 'alpha': 0.07267319176337007, 'batch_size': 8, 'learning_rate_init': 0.07254390533928975}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:05,738] Trial 183 finished with value: 101.49505625707889 and parameters: {'hidden_layer_sizes': 475, 'alpha': 0.033054257979629645, 'batch_size': 10, 'learning_rate_init': 0.0807837495221593}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:05,985] Trial 184 finished with value: 105.79579407308613 and parameters: {'hidden_layer_sizes': 459, 'alpha': 0.0749576584702553, 'batch_size': 9, 'learning_rate_init': 0.07525534463082315}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:06,164] Trial 185 finished with value: 111.02869602982193 and parameters: {'hidden_layer_sizes': 382, 'alpha': 0.06950372001742763, 'batch_size': 10, 'learning_rate_init': 0.06914281180231636}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:06,232] Trial 186 finished with value: 107.80118121451467 and parameters: {'hidden_layer_sizes': 10, 'alpha': 0.0289130385777858, 'batch_size': 8, 'learning_rate_init': 0.06559454828024136}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:06,398] Trial 187 finished with value: 105.23486865665467 and parameters: {'hidden_layer_sizes': 349, 'alpha': 0.010287215572621152, 'batch_size': 6, 'learning_rate_init': 0.07177676125610725}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:06,695] Trial 188 finished with value: 104.47339868102468 and parameters: {'hidden_layer_sizes': 450, 'alpha': 0.07188395483452281, 'batch_size': 9, 'learning_rate_init': 0.08254876894761123}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:06,983] Trial 189 finished with value: 105.69171546343318 and parameters: {'hidden_layer_sizes': 486, 'alpha': 0.022811387677756173, 'batch_size': 7, 'learning_rate_init': 0.05497009169801239}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:07,171] Trial 190 finished with value: 148.0065132516938 and parameters: {'hidden_layer_sizes': 479, 'alpha': 0.06418427551098807, 'batch_size': 6, 'learning_rate_init': 0.07924139563460865}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:07,248] Trial 191 finished with value: 104.3743119305311 and parameters: {'hidden_layer_sizes': 21, 'alpha': 0.06581571302706053, 'batch_size': 5, 'learning_rate_init': 0.09286748807937925}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:07,363] Trial 192 finished with value: 113.10704817191267 and parameters: {'hidden_layer_sizes': 83, 'alpha': 0.06723983785183235, 'batch_size': 5, 'learning_rate_init': 0.08988927497223735}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:07,511] Trial 193 finished with value: 91.65335781404409 and parameters: {'hidden_layer_sizes': 57, 'alpha': 0.03826947321250446, 'batch_size': 5, 'learning_rate_init': 0.08853822948034726}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:07,658] Trial 194 finished with value: 108.11903721383811 and parameters: {'hidden_layer_sizes': 63, 'alpha': 0.044259046720468494, 'batch_size': 5, 'learning_rate_init': 0.08783623575604914}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:08,193] Trial 195 finished with value: 103.08198764551746 and parameters: {'hidden_layer_sizes': 491, 'alpha': 0.03766272313368526, 'batch_size': 5, 'learning_rate_init': 0.08419454110347019}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:08,307] Trial 196 finished with value: 104.00354415200871 and parameters: {'hidden_layer_sizes': 58, 'alpha': 0.0326828407875132, 'batch_size': 6, 'learning_rate_init': 0.07675769142793562}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:08,447] Trial 197 finished with value: 103.49974019120769 and parameters: {'hidden_layer_sizes': 88, 'alpha': 0.03943648307804642, 'batch_size': 7, 'learning_rate_init': 0.07426075486979103}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:08,659] Trial 198 finished with value: 101.48220125907892 and parameters: {'hidden_layer_sizes': 467, 'alpha': 0.035363066767420695, 'batch_size': 10, 'learning_rate_init': 0.08656219536332092}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:09,051] Trial 199 finished with value: 112.54050945970455 and parameters: {'hidden_layer_sizes': 438, 'alpha': 0.04158605137226999, 'batch_size': 5, 'learning_rate_init': 0.09784942357492243}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:09,450] Trial 200 finished with value: 110.2652585895065 and parameters: {'hidden_layer_sizes': 188, 'alpha': 0.030953042352640243, 'batch_size': 3, 'learning_rate_init': 0.0674472135286877}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:09,615] Trial 201 finished with value: 106.17104725974696 and parameters: {'hidden_layer_sizes': 48, 'alpha': 0.016383715451761763, 'batch_size': 5, 'learning_rate_init': 0.09178189848275553}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:09,733] Trial 202 finished with value: 111.66804119199728 and parameters: {'hidden_layer_sizes': 77, 'alpha': 0.058890682207019686, 'batch_size': 5, 'learning_rate_init': 0.09018609038418053}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:09,843] Trial 203 finished with value: 108.47560843411786 and parameters: {'hidden_layer_sizes': 36, 'alpha': 0.06252491556901897, 'batch_size': 5, 'learning_rate_init': 0.09413880242492949}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:09,975] Trial 204 finished with value: 106.39423720673264 and parameters: {'hidden_layer_sizes': 56, 'alpha': 0.05535492814760584, 'batch_size': 6, 'learning_rate_init': 0.08799244587834351}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:10,060] Trial 205 finished with value: 105.79984071135192 and parameters: {'hidden_layer_sizes': 26, 'alpha': 0.028310796383350646, 'batch_size': 5, 'learning_rate_init': 0.09077822514593098}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:10,195] Trial 206 finished with value: 119.03425655872555 and parameters: {'hidden_layer_sizes': 68, 'alpha': 0.06826096449843068, 'batch_size': 4, 'learning_rate_init': 0.09622335161293456}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:10,430] Trial 207 finished with value: 106.7319062583267 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.0786165543081608, 'batch_size': 5, 'learning_rate_init': 0.0701574964326051}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:10,639] Trial 208 finished with value: 101.11275901346546 and parameters: {'hidden_layer_sizes': 476, 'alpha': 0.06484761065864617, 'batch_size': 7, 'learning_rate_init': 0.037360203492791046}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:10,798] Trial 209 finished with value: 137.14128669506937 and parameters: {'hidden_layer_sizes': 485, 'alpha': 0.07368928257232972, 'batch_size': 6, 'learning_rate_init': 0.09380041263470662}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:10,901] Trial 210 finished with value: 99.7252269193518 and parameters: {'hidden_layer_sizes': 99, 'alpha': 0.043093718510407754, 'batch_size': 8, 'learning_rate_init': 0.08880805789226377}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:11,105] Trial 211 finished with value: 120.2643757911198 and parameters: {'hidden_layer_sizes': 455, 'alpha': 0.06019716643826647, 'batch_size': 6, 'learning_rate_init': 0.06858382801058928}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:11,483] Trial 212 finished with value: 108.56441754899652 and parameters: {'hidden_layer_sizes': 461, 'alpha': 0.06079368209231205, 'batch_size': 6, 'learning_rate_init': 0.07315108006899404}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:11,744] Trial 213 finished with value: 95.89559898713487 and parameters: {'hidden_layer_sizes': 477, 'alpha': 0.06165946578279604, 'batch_size': 6, 'learning_rate_init': 0.07688022347860032}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:12,004] Trial 214 finished with value: 143.38437478604487 and parameters: {'hidden_layer_sizes': 489, 'alpha': 0.05724060532811354, 'batch_size': 6, 'learning_rate_init': 0.07718816540565228}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:12,243] Trial 215 finished with value: 118.44879709999837 and parameters: {'hidden_layer_sizes': 480, 'alpha': 0.06350902412172175, 'batch_size': 5, 'learning_rate_init': 0.07978441967700504}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:12,355] Trial 216 finished with value: 105.54820033926133 and parameters: {'hidden_layer_sizes': 45, 'alpha': 0.07016976297279302, 'batch_size': 9, 'learning_rate_init': 0.0752112817840657}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:12,708] Trial 217 finished with value: 112.18017340606235 and parameters: {'hidden_layer_sizes': 471, 'alpha': 0.03877876442410082, 'batch_size': 6, 'learning_rate_init': 0.08236923341477263}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:13,357] Trial 218 finished with value: 102.87242075557165 and parameters: {'hidden_layer_sizes': 492, 'alpha': 0.051519223984803714, 'batch_size': 5, 'learning_rate_init': 0.08528024096997813}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:13,470] Trial 219 finished with value: 110.93818523703267 and parameters: {'hidden_layer_sizes': 218, 'alpha': 0.02475550406898725, 'batch_size': 10, 'learning_rate_init': 0.07802271890148584}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:13,585] Trial 220 finished with value: 105.23922714425343 and parameters: {'hidden_layer_sizes': 130, 'alpha': 0.04615158635407385, 'batch_size': 9, 'learning_rate_init': 0.08081604859505215}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:13,810] Trial 221 finished with value: 117.93697980374796 and parameters: {'hidden_layer_sizes': 455, 'alpha': 0.06088495661965095, 'batch_size': 6, 'learning_rate_init': 0.07157935650471776}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:14,176] Trial 222 finished with value: 109.1804034369746 and parameters: {'hidden_layer_sizes': 467, 'alpha': 0.061971440355662606, 'batch_size': 6, 'learning_rate_init': 0.0741775603113914}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:14,471] Trial 223 finished with value: 140.1574737440836 and parameters: {'hidden_layer_sizes': 477, 'alpha': 0.03631662221340556, 'batch_size': 6, 'learning_rate_init': 0.06937721423209252}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:14,939] Trial 224 finished with value: 109.03109540775745 and parameters: {'hidden_layer_sizes': 443, 'alpha': 0.058709980748596534, 'batch_size': 6, 'learning_rate_init': 0.09142683195853006}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:15,450] Trial 225 finished with value: 103.5925895231024 and parameters: {'hidden_layer_sizes': 463, 'alpha': 0.03433265485082764, 'batch_size': 5, 'learning_rate_init': 0.07563312148315443}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:15,695] Trial 226 finished with value: 107.65717942611937 and parameters: {'hidden_layer_sizes': 484, 'alpha': 0.05350353299774701, 'batch_size': 10, 'learning_rate_init': 0.08794756383359417}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:15,812] Trial 227 finished with value: 106.29850185779303 and parameters: {'hidden_layer_sizes': 67, 'alpha': 0.0661479751305607, 'batch_size': 7, 'learning_rate_init': 0.06670798652615975}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:15,974] Trial 228 finished with value: 132.67132944382084 and parameters: {'hidden_layer_sizes': 368, 'alpha': 0.06432757031481948, 'batch_size': 6, 'learning_rate_init': 0.09556532911972682}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:16,228] Trial 229 finished with value: 148.53581524203267 and parameters: {'hidden_layer_sizes': 499, 'alpha': 0.0564701139899543, 'batch_size': 5, 'learning_rate_init': 0.07082908551326343}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:16,444] Trial 230 finished with value: 129.15271329991097 and parameters: {'hidden_layer_sizes': 451, 'alpha': 0.07170103305480524, 'batch_size': 6, 'learning_rate_init': 0.07755249288466891}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:16,613] Trial 231 finished with value: 103.15340763906104 and parameters: {'hidden_layer_sizes': 67, 'alpha': 0.04844689988772304, 'batch_size': 6, 'learning_rate_init': 0.07594820726718739}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:16,730] Trial 232 finished with value: 110.28202609692156 and parameters: {'hidden_layer_sizes': 47, 'alpha': 0.04986472882910342, 'batch_size': 6, 'learning_rate_init': 0.07358539585203708}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:16,871] Trial 233 finished with value: 97.25739963543026 and parameters: {'hidden_layer_sizes': 56, 'alpha': 0.013270262924018136, 'batch_size': 6, 'learning_rate_init': 0.07614027153987202}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,041] Trial 234 finished with value: 97.92418709765045 and parameters: {'hidden_layer_sizes': 60, 'alpha': 0.012544868566587306, 'batch_size': 6, 'learning_rate_init': 0.07887128059342628}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,186] Trial 235 finished with value: 100.82623268640738 and parameters: {'hidden_layer_sizes': 59, 'alpha': 0.012426067532443638, 'batch_size': 6, 'learning_rate_init': 0.07913200899498588}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,292] Trial 236 finished with value: 104.78546779116203 and parameters: {'hidden_layer_sizes': 36, 'alpha': 0.0127469048507878, 'batch_size': 5, 'learning_rate_init': 0.07715992388133405}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,397] Trial 237 finished with value: 102.10396001457336 and parameters: {'hidden_layer_sizes': 50, 'alpha': 0.019027348705463236, 'batch_size': 7, 'learning_rate_init': 0.08005533649711856}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,544] Trial 238 finished with value: 97.36179167583465 and parameters: {'hidden_layer_sizes': 73, 'alpha': 0.014698131436632022, 'batch_size': 5, 'learning_rate_init': 0.09247517346135592}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,687] Trial 239 finished with value: 110.83229631078508 and parameters: {'hidden_layer_sizes': 79, 'alpha': 0.006806289930369189, 'batch_size': 6, 'learning_rate_init': 0.08328234466261877}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,801] Trial 240 finished with value: 109.10185534909027 and parameters: {'hidden_layer_sizes': 83, 'alpha': 0.015101073350059427, 'batch_size': 10, 'learning_rate_init': 0.09264609998124389}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:17,929] Trial 241 finished with value: 108.54285117565558 and parameters: {'hidden_layer_sizes': 74, 'alpha': 0.009815802585672174, 'batch_size': 5, 'learning_rate_init': 0.09118015110246605}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:18,089] Trial 242 finished with value: 98.15012493682308 and parameters: {'hidden_layer_sizes': 60, 'alpha': 0.015859730121678104, 'batch_size': 4, 'learning_rate_init': 0.08961304991866716}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:18,240] Trial 243 finished with value: 100.82536707060346 and parameters: {'hidden_layer_sizes': 54, 'alpha': 0.014020990228320075, 'batch_size': 5, 'learning_rate_init': 0.09772091999660343}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:18,504] Trial 244 finished with value: 88.23395014733484 and parameters: {'hidden_layer_sizes': 72, 'alpha': 0.010975940354127816, 'batch_size': 5, 'learning_rate_init': 0.09332086030548005}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:18,633] Trial 245 finished with value: 99.89690061947952 and parameters: {'hidden_layer_sizes': 74, 'alpha': 0.011285759626134057, 'batch_size': 5, 'learning_rate_init': 0.09438426503932806}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:18,757] Trial 246 finished with value: 108.76180967171102 and parameters: {'hidden_layer_sizes': 70, 'alpha': 0.011941095036171814, 'batch_size': 5, 'learning_rate_init': 0.07854653416976935}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:18,893] Trial 247 finished with value: 102.76480427489408 and parameters: {'hidden_layer_sizes': 103, 'alpha': 0.015435143061746957, 'batch_size': 5, 'learning_rate_init': 0.07502341162834648}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:19,016] Trial 248 finished with value: 103.98669345718234 and parameters: {'hidden_layer_sizes': 60, 'alpha': 0.017748379652337387, 'batch_size': 6, 'learning_rate_init': 0.07246537823313945}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:19,177] Trial 249 finished with value: 103.32436756840131 and parameters: {'hidden_layer_sizes': 88, 'alpha': 0.008266067715743203, 'batch_size': 8, 'learning_rate_init': 0.09271190072670435}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:19,299] Trial 250 finished with value: 111.83751798762673 and parameters: {'hidden_layer_sizes': 94, 'alpha': 0.009450038913116153, 'batch_size': 9, 'learning_rate_init': 0.08145903915779762}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:19,452] Trial 251 finished with value: 104.55591004289839 and parameters: {'hidden_layer_sizes': 81, 'alpha': 0.006722969255260411, 'batch_size': 6, 'learning_rate_init': 0.0876939718723685}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:19,822] Trial 252 finished with value: 85.5717656044172 and parameters: {'hidden_layer_sizes': 487, 'alpha': 0.014163224307951708, 'batch_size': 7, 'learning_rate_init': 0.07647926264957018}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:20,019] Trial 253 finished with value: 135.96202301790433 and parameters: {'hidden_layer_sizes': 479, 'alpha': 0.04089500951234645, 'batch_size': 7, 'learning_rate_init': 0.07619846891586567}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:20,200] Trial 254 finished with value: 106.13823375862356 and parameters: {'hidden_layer_sizes': 490, 'alpha': 0.03014326108007067, 'batch_size': 7, 'learning_rate_init': 0.07433144648335532}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:20,481] Trial 255 finished with value: 108.29633143983774 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.013595224702782278, 'batch_size': 7, 'learning_rate_init': 0.09637480700589851}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:20,698] Trial 256 finished with value: 233.88868801005552 and parameters: {'hidden_layer_sizes': 475, 'alpha': 0.004169275142490082, 'batch_size': 7, 'learning_rate_init': 0.08951803923449378}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:21,041] Trial 257 finished with value: 132.21590373300592 and parameters: {'hidden_layer_sizes': 483, 'alpha': 0.026828904820487845, 'batch_size': 5, 'learning_rate_init': 0.0721940387554633}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:21,395] Trial 258 finished with value: 95.2918843453332 and parameters: {'hidden_layer_sizes': 490, 'alpha': 0.038074629976148244, 'batch_size': 10, 'learning_rate_init': 0.0857530224716918}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:21,589] Trial 259 finished with value: 102.66022660217027 and parameters: {'hidden_layer_sizes': 488, 'alpha': 0.04042605467955166, 'batch_size': 10, 'learning_rate_init': 0.08542933695185868}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:21,777] Trial 260 finished with value: 119.19736253569786 and parameters: {'hidden_layer_sizes': 492, 'alpha': 0.042741603151459855, 'batch_size': 10, 'learning_rate_init': 0.08686432857632634}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:21,972] Trial 261 finished with value: 108.85397014655895 and parameters: {'hidden_layer_sizes': 409, 'alpha': 0.03567310738806127, 'batch_size': 10, 'learning_rate_init': 0.09355736071277578}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:22,198] Trial 262 finished with value: 119.30628738648473 and parameters: {'hidden_layer_sizes': 467, 'alpha': 0.033608540187419, 'batch_size': 10, 'learning_rate_init': 0.0627313301100508}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:22,680] Trial 263 finished with value: 111.25954625933315 and parameters: {'hidden_layer_sizes': 473, 'alpha': 0.036960747966962304, 'batch_size': 10, 'learning_rate_init': 0.09975886507993355}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:23,255] Trial 264 finished with value: 101.80221530855422 and parameters: {'hidden_layer_sizes': 486, 'alpha': 0.018900994546245636, 'batch_size': 9, 'learning_rate_init': 0.0838707558313137}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:23,483] Trial 265 finished with value: 262.7165556234024 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.038297426647716466, 'batch_size': 4, 'learning_rate_init': 0.090130580019227}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:23,677] Trial 266 finished with value: 132.2826905769045 and parameters: {'hidden_layer_sizes': 490, 'alpha': 0.00514108087826355, 'batch_size': 5, 'learning_rate_init': 0.08887259243632063}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:23,832] Trial 267 finished with value: 110.26249091563957 and parameters: {'hidden_layer_sizes': 314, 'alpha': 0.03151899453753957, 'batch_size': 10, 'learning_rate_init': 0.08540516028950197}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:24,180] Trial 268 finished with value: 297.0320660321458 and parameters: {'hidden_layer_sizes': 477, 'alpha': 0.04494533669307082, 'batch_size': 5, 'learning_rate_init': 0.08086971267380774}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:24,320] Trial 269 finished with value: 107.67831894090645 and parameters: {'hidden_layer_sizes': 113, 'alpha': 0.01711564939690916, 'batch_size': 5, 'learning_rate_init': 0.08708056856767733}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:24,469] Trial 270 finished with value: 101.4411408431676 and parameters: {'hidden_layer_sizes': 466, 'alpha': 0.008830596525551456, 'batch_size': 9, 'learning_rate_init': 0.04909123207171803}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:24,758] Trial 271 finished with value: 105.22569213276962 and parameters: {'hidden_layer_sizes': 500, 'alpha': 0.02119574038059633, 'batch_size': 8, 'learning_rate_init': 0.07747865638877696}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:24,932] Trial 272 finished with value: 118.58561334269974 and parameters: {'hidden_layer_sizes': 476, 'alpha': 0.03910704978750858, 'batch_size': 10, 'learning_rate_init': 0.09420838331678281}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:25,158] Trial 273 finished with value: 105.92730380212514 and parameters: {'hidden_layer_sizes': 284, 'alpha': 0.002173665925149868, 'batch_size': 5, 'learning_rate_init': 0.09175460157415272}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:25,450] Trial 274 finished with value: 170.06962607016848 and parameters: {'hidden_layer_sizes': 485, 'alpha': 0.014711961289820967, 'batch_size': 5, 'learning_rate_init': 0.08263923369630163}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:25,650] Trial 275 finished with value: 103.04851367096084 and parameters: {'hidden_layer_sizes': 141, 'alpha': 0.010144164290039392, 'batch_size': 4, 'learning_rate_init': 0.07589443747941199}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:25,708] Trial 276 finished with value: 105.36921391869748 and parameters: {'hidden_layer_sizes': 21, 'alpha': 0.022487346431311235, 'batch_size': 10, 'learning_rate_init': 0.07936567317969168}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:25,851] Trial 277 finished with value: 140.76179121625154 and parameters: {'hidden_layer_sizes': 91, 'alpha': 0.029172846512340634, 'batch_size': 5, 'learning_rate_init': 0.07056197608219406}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:26,283] Trial 278 finished with value: 96.11007399164116 and parameters: {'hidden_layer_sizes': 492, 'alpha': 0.03459201191126852, 'batch_size': 6, 'learning_rate_init': 0.08951528479608759}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:27,502] Trial 279 finished with value: 112.20159179871435 and parameters: {'hidden_layer_sizes': 493, 'alpha': 0.03486192263036033, 'batch_size': 6, 'learning_rate_init': 0.0023148839804994006}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:27,672] Trial 280 finished with value: 116.37816975268703 and parameters: {'hidden_layer_sizes': 484, 'alpha': 0.03181834583300943, 'batch_size': 6, 'learning_rate_init': 0.08834125067754449}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:27,884] Trial 281 finished with value: 115.88112947737649 and parameters: {'hidden_layer_sizes': 422, 'alpha': 0.07482313346305802, 'batch_size': 6, 'learning_rate_init': 0.06509645688482531}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:28,007] Trial 282 finished with value: 108.55315691097002 and parameters: {'hidden_layer_sizes': 107, 'alpha': 0.037506832891833375, 'batch_size': 6, 'learning_rate_init': 0.09038026829421135}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:28,206] Trial 283 finished with value: 106.49333409624349 and parameters: {'hidden_layer_sizes': 252, 'alpha': 0.012093130038810412, 'batch_size': 6, 'learning_rate_init': 0.0601599921634371}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:28,438] Trial 284 finished with value: 101.29668072610306 and parameters: {'hidden_layer_sizes': 470, 'alpha': 0.03248945152842861, 'batch_size': 9, 'learning_rate_init': 0.07344642957459857}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:28,704] Trial 285 finished with value: 505.9821834304157 and parameters: {'hidden_layer_sizes': 492, 'alpha': 0.0004455926183689757, 'batch_size': 6, 'learning_rate_init': 0.08618653834829315}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:28,880] Trial 286 finished with value: 107.3691627818783 and parameters: {'hidden_layer_sizes': 460, 'alpha': 0.016297900388721174, 'batch_size': 10, 'learning_rate_init': 0.05772188110397932}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:29,353] Trial 287 finished with value: 109.39797684343733 and parameters: {'hidden_layer_sizes': 479, 'alpha': 0.0683117935955673, 'batch_size': 8, 'learning_rate_init': 0.08389327727357235}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:29,529] Trial 288 finished with value: 107.56029018691028 and parameters: {'hidden_layer_sizes': 123, 'alpha': 0.09314059325464241, 'batch_size': 6, 'learning_rate_init': 0.07717949865355432}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:29,668] Trial 289 finished with value: 98.95686627532342 and parameters: {'hidden_layer_sizes': 170, 'alpha': 0.040567116408578394, 'batch_size': 9, 'learning_rate_init': 0.09222678859806405}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:30,069] Trial 290 finished with value: 359.95587290041294 and parameters: {'hidden_layer_sizes': 494, 'alpha': 0.03507061055577606, 'batch_size': 2, 'learning_rate_init': 0.0894427699215078}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:30,489] Trial 291 finished with value: 148.7310411539193 and parameters: {'hidden_layer_sizes': 478, 'alpha': 0.006150308432171848, 'batch_size': 7, 'learning_rate_init': 0.06866438362049895}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:30,676] Trial 292 finished with value: 166.2821803104877 and parameters: {'hidden_layer_sizes': 468, 'alpha': 0.027650606084896452, 'batch_size': 6, 'learning_rate_init': 0.0816725441742492}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:31,401] Trial 293 finished with value: 93.42347730005615 and parameters: {'hidden_layer_sizes': 344, 'alpha': 0.05306460023345796, 'batch_size': 3, 'learning_rate_init': 0.07641018601205933}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:31,688] Trial 294 finished with value: 190.319209782778 and parameters: {'hidden_layer_sizes': 332, 'alpha': 0.05242223017932883, 'batch_size': 3, 'learning_rate_init': 0.07531165576655506}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:32,268] Trial 295 finished with value: 97.4563565591465 and parameters: {'hidden_layer_sizes': 387, 'alpha': 0.05444775528510095, 'batch_size': 3, 'learning_rate_init': 0.07790839912862285}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:32,539] Trial 296 finished with value: 106.03818259014908 and parameters: {'hidden_layer_sizes': 345, 'alpha': 0.0524975349866538, 'batch_size': 4, 'learning_rate_init': 0.07963274744172652}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:32,820] Trial 297 finished with value: 126.98851770289797 and parameters: {'hidden_layer_sizes': 361, 'alpha': 0.05576726759452144, 'batch_size': 3, 'learning_rate_init': 0.077212953980784}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:33,447] Trial 298 finished with value: 106.92615048560796 and parameters: {'hidden_layer_sizes': 372, 'alpha': 0.05016977646824239, 'batch_size': 3, 'learning_rate_init': 0.07363032081478624}. Best is trial 64 with value: 84.67288745448275.\n",
      "[I 2023-07-09 21:28:33,757] Trial 299 finished with value: 154.6658146943499 and parameters: {'hidden_layer_sizes': 383, 'alpha': 0.046969902280747704, 'batch_size': 3, 'learning_rate_init': 0.07809717226347417}. Best is trial 64 with value: 84.67288745448275.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': 430, 'alpha': 0.0651809588808832, 'batch_size': 5, 'learning_rate_init': 0.06876744328850001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.67288745448275"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def objective(trial):\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    hidden_layer_sizes=trial.suggest_int(\"hidden_layer_sizes\",10,500)\n",
    "    alpha = trial.suggest_float(\"alpha\",0.00001,0.1)\n",
    "    batch_size = trial.suggest_int(\"batch_size\",1,10)\n",
    "    learning_rate_init = trial.suggest_float(\"learning_rate_init\",0.001,0.1)\n",
    "    model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, alpha=alpha, batch_size=batch_size,learning_rate_init=learning_rate_init)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return mean_squared_error(y_test, y_pred) ** 0.5\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "best_params=study.best_params\n",
    "print(best_params)\n",
    "study.best_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=108, alpha=0.07450377055550288, batch_size=5,learning_rate_init=0.06814569352812619)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.98604044329383\n"
     ]
    }
   ],
   "source": [
    "def RMSE(data,pred):\n",
    "    n=len(data)\n",
    "    return np.sqrt((np.sum((data-pred)**2))/n)\n",
    "print(RMSE(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
